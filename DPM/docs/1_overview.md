D∆∞·ªõi ƒë√¢y l√† **ph√¢n t√≠ch chi ti·∫øt c·∫•u tr√∫c project DPM (Deep Portfolio Management)** ‚Äî ƒë∆∞·ª£c t·ªï ch·ª©c theo d·∫°ng *modular framework*, ph·ª•c v·ª• nghi√™n c·ª©u reinforcement learning (RL) trong portfolio optimization.

---

## üß± **I. T·ªïng quan c·∫•u tr√∫c th∆∞ m·ª•c**

```
DPM/
‚îú‚îÄ‚îÄ main.py               # Entry-point kh·ªüi t·∫°o train/test
‚îú‚îÄ‚îÄ train.sh              # Script ch·∫°y training
‚îú‚îÄ‚îÄ code_summary.txt      # T·ªïng h·ª£p code
‚îú‚îÄ‚îÄ policies/             # C√°c m√¥ h√¨nh policy (ATN, CNN, NRI...)
‚îú‚îÄ‚îÄ pgportfolio/          # Core logic: RL agents, data, train, backtest
‚îÇ   ‚îú‚îÄ‚îÄ learn/            # RL agents v√† trainer (torch/tensorflow)
‚îÇ   ‚îú‚îÄ‚îÄ marketdata/       # Load + x·ª≠ l√Ω d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ tdagent/          # C√°c baseline rule-based / statistical
‚îÇ   ‚îú‚îÄ‚îÄ trade/            # Backtest v√† m√¥ ph·ªèng giao d·ªãch
‚îÇ   ‚îú‚îÄ‚îÄ tools/            # Indicator, x·ª≠ l√Ω config, trade logic
‚îÇ   ‚îú‚îÄ‚îÄ resultprocess/    # Plot k·∫øt qu·∫£ v√† table
‚îÇ   ‚îú‚îÄ‚îÄ autotrain/        # Auto pipeline ch·∫°y train c√°c config
‚îÇ   ‚îî‚îÄ‚îÄ data/             # Dataset (.pkl/.npy)
‚îú‚îÄ‚îÄ docs/summary.sh       # Script t·ªïng h·ª£p code
‚îî‚îÄ‚îÄ README.md
```

---

## üîÅ **II. C√°c Flow ch√≠nh**

### ‚úÖ 1. **Hu·∫•n luy·ªán m√¥ h√¨nh**

```
train.sh
  ‚Üì
main.py
  ‚Üì
pgportfolio.autotrain.generate
  ‚Üì
pgportfolio.learn.[torch/tensorflow].nnagent + rollingtrainer
  ‚Üì
‚Üí Load d·ªØ li·ªáu (marketdata)
‚Üí Tr√≠ch xu·∫•t indicator (tools/indicator)
‚Üí Sinh state
‚Üí Update policy
‚Üí Log k·∫øt qu·∫£
```

### ‚úÖ 2. **Backtest m√¥ h√¨nh**

```
pgportfolio.trade.backtest
  ‚Üì
pgportfolio.trade.trader
  ‚Üì
‚Üí Load policy ƒë√£ train
‚Üí Sinh t√≠n hi·ªáu & giao d·ªãch
‚Üí Ghi l·∫°i l·ªãch s·ª≠ giao d·ªãch
```

### ‚úÖ 3. **So s√°nh v√† visualize**

```
pgportfolio.resultprocess.plot + table
  ‚Üì
‚Üí Sinh bi·ªÉu ƒë·ªì return
‚Üí T·ªïng h·ª£p metric: Sharpe, Drawdown, Mean Return...
```

---

## üîç **III. Chi ti·∫øt c√°c module ch√≠nh**

### üì¶ **1. `policies/` ‚Äî Neural policy**

* Ch·ª©a c√°c network custom:

  * `cnn`, `cnn_sarl`, `cnn_loss`, `nri_conv4`, `atn`, `sarl`, ...
* C√≥ m√¥ h√¨nh **NRI** ri√™ng ·ªü `NRI/` (Neural Relational Inference):

  * `modules.py`: ƒë·ªãnh nghƒ©a encoder/decoder ki·∫øn tr√∫c ƒë·ªì th·ªã.
  * `utils.py`: util gi√∫p t·∫°o adjacency, mask, normalize.

> üî• ƒê√¢y l√† n∆°i quy·∫øt ƒë·ªãnh ‚Äúpolicy‚Äù ‚Äî b·∫£n ch·∫•t m√¥ h√¨nh h·ªçc ƒëi·ªÅu khi·ªÉn ph√¢n b·ªï.

---

### üì¶ **2. `pgportfolio/learn/` ‚Äî RL agent + trainer**

* T·ªï ch·ª©c theo 2 backend:

  * `torch/`: modern backend ch√≠nh (PyTorch).
  * `tensorflow/`: b·∫£n c≈©.

* File ch√≠nh:

  * `nnagent.py`: define policy ‚Üí action.
  * `rollingtrainer.py`: hu·∫•n luy·ªán theo rolling window.
  * `tradertrainer.py`: test policy.

* T√≠nh nƒÉng ƒë·∫∑c bi·ªát:

  * C√≥ c·∫•u tr√∫c rolling training: chia giai ƒëo·∫°n l·ªãch s·ª≠ ‚Üí hu·∫•n luy·ªán l·∫∑p.

---

### üì¶ **3. `pgportfolio/tdagent/` ‚Äî Baseline algorithms**

> T·∫≠p h·ª£p h∆°n 20 thu·∫≠t to√°n rule-based:

* `crp`, `bcrp`, `pamr`, `eg`, `olmar`, `anticor`, `ubahn`, `wmamr`, `ons`,...
* `tdagent.py`: l·ªõp t·ªïng qu√°t qu·∫£n l√Ω agent (t∆∞∆°ng t·ª± `nnagent.py`).

\=> Gi√∫p benchmark c√°c policy RL m·ªõi.

---

### üì¶ **4. `pgportfolio/marketdata/` ‚Äî Load d·ªØ li·ªáu th·ªã tr∆∞·ªùng**

* `datamatrices.py`: load t·∫≠p d·ªØ li·ªáu c·ª• th·ªÉ.
* `poloniex.py`: API l·∫•y d·ªØ li·ªáu t·ª´ s√†n.
* `globaldatamatrix.py`: d·ªØ li·ªáu to√†n c·ª•c cho nhi·ªÅu t√†i s·∫£n.
* `replaybuffer.py`: buffer cho RL training (theo batch).

---

### üì¶ **5. `pgportfolio/tools/` ‚Äî X·ª≠ l√Ω indicator & config**

* `indicator.py`: sinh c√°c technical indicators t·ª´ gi√° (EMA, volatility,...).
* `configprocess.py`: x·ª≠ l√Ω file c·∫•u h√¨nh `net_config.json`.
* `trade.py`, `shortcut.py`: ti·ªán √≠ch t·∫°o order, strategy,...

\=> D√πng trong pipeline ƒë·ªÉ sinh state t·ª´ data.

---

### üì¶ **6. `pgportfolio/autotrain/` ‚Äî T·ª± ƒë·ªông hu·∫•n luy·ªán**

* `generate.py`: sinh c·∫•u h√¨nh t·ª´ template (cho nhi·ªÅu m√¥ h√¨nh).
* `training.py`: ch·∫°y training nhi·ªÅu config (batch train experiment).

\=> D√πng ƒë·ªÉ t·∫°o nhi·ªÅu k·∫øt qu·∫£ hu·∫•n luy·ªán cho so s√°nh ho·∫∑c tuning.

---

### üì¶ **7. `pgportfolio/resultprocess/` ‚Äî Ph√¢n t√≠ch k·∫øt qu·∫£**

* `plot.py`: v·∫Ω bi·ªÉu ƒë·ªì return theo th·ªùi gian.
* `table.py`: xu·∫•t b·∫£ng t·ªïng h·ª£p performance.

---

## üìÇ **IV. D·ªØ li·ªáu**

N·∫±m ·ªü: `pgportfolio/data/`

* D·∫°ng `.pkl`, `.npy` ‚Äî ƒë√£ x·ª≠ l√Ω:

  * `btc.pkl`, `crix_2.pkl`, `stock.npy`...

\=> S·ª≠ d·ª•ng tr·ª±c ti·∫øp trong `datamatrices.py`.

---

## ‚úÖ **V. T·ªïng k·∫øt ki·∫øn tr√∫c**

| Layer               | M·ª•c ƒë√≠ch                   | Module                            |
| ------------------- | -------------------------- | --------------------------------- |
| **Policy**          | Neural network h·ªçc ph√¢n b·ªï | `policies/`                       |
| **Agent**           | Hu·∫•n luy·ªán policy          | `learn/`                          |
| **Baseline**        | So s√°nh ph∆∞∆°ng ph√°p c≈©     | `tdagent/`                        |
| **Data**            | Load d·ªØ li·ªáu + preprocess  | `marketdata/` + `tools/`          |
| **Training Engine** | Rolling trainer            | `rollingtrainer.py`, `autotrain/` |
| **Evaluation**      | Backtest + Plot + Table    | `trade/`, `resultprocess/`        |

---

B·∫°n c√≥ mu·ªën m√¨nh ti·∫øp t·ª•c:

* So s√°nh k·ªπ `SARL`, `ATN`, `NRI` ƒë·ªÉ hi·ªÉu style modeling?
* Vi·∫øt l·∫°i b·∫£n s∆° ƒë·ªì pipeline to√†n b·ªô flow?
* Extract l·∫°i t√™n c√°c baseline + m√¥ t·∫£ + paper g·ªëc?

M√¨nh c√≥ th·ªÉ gi√∫p ti·∫øp.
