==== CODE SUMMARY: Thứ năm, 07 Tháng 8 năm 2025 09:41:16 +07 ====


### FILE: docs/summary.sh
----------------------------------------
#!/bin/bash

# Đường dẫn thư mục gốc repo
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
OUTPUT_FILE="$ROOT_DIR/code_summary.txt"

# Xóa file cũ nếu tồn tại
rm -f "$OUTPUT_FILE"

echo "Generating code summary at $OUTPUT_FILE..."
echo "==== CODE SUMMARY: $(date) ====" >> "$OUTPUT_FILE"

# Tìm tất cả file .py, .sh (loại trừ các thư mục __pycache__ và *.pyc)
find "$ROOT_DIR" -type f \( -name "*.py" -o -name "*.sh" \) ! -path "*/__pycache__/*" ! -name "*.pyc" | sort | while read filepath; do
    echo -e "\n\n### FILE: ${filepath#$ROOT_DIR/}" >> "$OUTPUT_FILE"
    echo "----------------------------------------" >> "$OUTPUT_FILE"
    cat "$filepath" >> "$OUTPUT_FILE"
done

echo "Done."


### FILE: main.py
----------------------------------------
import json
import os
import time
import collections
import argparse
import datetime
import pickle

import numpy as np
import torch
import torch.nn as nn

from pgportfolio.marketdata.datamatrices import DataMatrices
from pgportfolio.tools.configprocess import preprocess_config



import logging
logging.basicConfig(level=logging.INFO)

import math
from utils import *

rolling = True

parser = argparse.ArgumentParser(description='PyTorch PM Args')

parser.add_argument('--lr', type=float, default=0.001, metavar='G',
                    help='learning rate (default: 0.0001)')


parser.add_argument('--alpha', type=float, default=0.2, metavar='G',
                    help='Temperature parameter α determines the relative importance of the entropy\
                            term against the reward (default: 0.2)')

parser.add_argument('--seed', type=int, default=7, metavar='N',
                    help='random seed (default: 7)')
parser.add_argument('--batch_size', type=int, default=256, metavar='N',
                    help='batch size (default: 256)')

parser.add_argument('--n_episode', type=int, default=6, metavar='N',
                    help='number of episode for each batch (default: 5)')
parser.add_argument('--num_steps', type=int, default=10000, metavar='N',
                    help='maximum number of steps (default: 1000000)')
parser.add_argument('--rolling_steps', type=int, default=20, metavar='N',
                    help='maximum number of steps (default: 1000000)')

parser.add_argument('--no_cuda', action="store_true", default=False,
                    help='run on CUDA (default: False)')
parser.add_argument('--cuda_no', type=int, default=0,
                    help='cuda no (default: 2)')
parser.add_argument('--model_name', type=str, default='ours',
                    help='model name [dpm, sarl, ours, sarl_v2, dpm_v2]')

parser.add_argument('--test_portion', type=float, default=0.08,
                    help='test portion (default: 0.08, 0.1605)')
parser.add_argument('--smoothing_days', type=int, default=5,
                    help='smoothing days (default: 5)')

parser.add_argument('--stocks', type=int, default=1,
                    help='smoothing days (default: 1)')
parser.add_argument('--buffer_biased', type=float, default=5e-5,
                    help='buffer_biased for sampling (default: 5e-5)') #stock 2e-4 #btc 5e-5

parser.add_argument('--nri_d', type=int, default=32,
                    help='nri dimension (default: 32)')
parser.add_argument('--cnn_d', type=int, default=10,
                    help='cnn dimension (default: 10)')
parser.add_argument('--cnn_d2', type=int, default=15,
                    help='cnn2 dimension (default: 10)')
parser.add_argument('--nri_shuffle', type=int, default=1,
                    help='nri batch shuffle, shuffle=1 means not shuffle (default: 1)')
parser.add_argument('--nri_lr', type=float, default=0.0005, metavar='G',
                    help='learning rate (default: 0.0005)')
parser.add_argument('--input_shift', action='store_true', default=False,
                    help='model input minus one (default: False)')


parser.add_argument('--L1_w', type=float, default=2,
                    help='L1 weight (default: 2)')
parser.add_argument('--L1_baseline', action='store_true',
                    help='L1 baseline (default: False)')
parser.add_argument('--L3_w', type=float, default=1,
                    help='smoothing weight (default: 1)')
parser.add_argument('--L2_w', type=float, default=1e-6,
                    help='contrastive weight (default: 1e-6)')
parser.add_argument('--L3_baseline', action='store_true',
                    help='L3 baseline (default: False)')
parser.add_argument('--L3_w_const', action='store_true', default=False,
                    help='L3 weight constant (default: False)')

args = parser.parse_args()

if args.seed != -1:
    torch.manual_seed(args.seed)
args.useCuda = not args.no_cuda

device = torch.device("cuda:{}".format(args.cuda_no) if (torch.cuda.is_available() and args.useCuda) else "cpu")

stock = args.stocks
if stock ==0:
    action_n = 10 # stock 10 btc 11
    args.buffer_biased = 2e-4
    args.test_portion = 0.1605
else:
    action_n = 11 # stock 10 btc 11


def main():
    results_dict = {'eval_rewards': [],
                    'eval_actions': [],
                    'eval_returns': [],
                    'l1_losses': [],
                    'l2_losses': [],
                    'l3_losses': [],
                    'l3_losses_w': [],
                    'nri_nll_losses': [],
                    'nri_kl_losses': []
                    }


    base_dir = (os.getcwd() + '/models_0911_sarl/' + '/RT(stock_layer)-NoVAL-stock_'+ str(stock) + '-seed_' + str(args.seed) + '/' +
                                'lr_' + str(args.lr) + '-steps_' + str(args.num_steps) + '-rolling_' + str(args.rolling_steps) +
                                '-smooth_' + str(args.smoothing_days) + '-nri_d_' + str(args.nri_d) + '-cnn_d_' + str(args.cnn_d) +
                                '-cnn_d2_' + str(args.cnn_d2) +
                                '-nri_batch_shuffle_' + str(args.nri_shuffle) + '-input_shift_' + str(args.input_shift) +
                                '-nri_lr_' + str(args.nri_lr)  + '-l2_w'+ str(args.L2_w) + '-l3_w'+ str(args.L3_w) +
                                '-n_episode' + str(args.n_episode)  + '-model' + args.model_name  +'/' )

    run_number = 0
    while os.path.exists(base_dir + str(run_number)):
        run_number += 1
    base_dir = base_dir + str(run_number)
    os.makedirs(base_dir)

    with open(base_dir + '/commandline_args.txt', 'w') as f:
        json.dump(args.__dict__, f, indent=2)


    with open("pgportfolio/" + "net_config.json") as file:
        config = json.load(file)
    config = preprocess_config(config)

    train_config = config["training"]
    input_config = config["input"]

  

    if (args.model_name == 'dpm') or (args.model_name == 'sarl'):
        from policies.policy import CNN_Policy as Policy
        pi = Policy(3, action_n, args, device)

    elif (args.model_name == 'dpm_v2') or (args.model_name == 'sarl_v2') or (args.model_name == 'ours'):
        from policies.policy import Conv4_Policy as Policy
        pi = Policy(3, action_n, args.lr, args.n_episode*train_config['batch_size'], args.nri_d, args.cnn_d, args.nri_shuffle, args.input_shift, args.nri_lr, args.cnn_d2, args, device)


    matrix = DataMatrices.create_from_config(config, stock, args)


    test_set = matrix.get_test_set()
    training_set = matrix.get_training_set()

    if 'sarl' in args.model_name:
        pi.sarl_net.train()
        for n_epi in range(args.num_steps): 
            batch = matrix.next_batch(args.n_episode)

            x = torch.from_numpy(batch["X"]) 
            y = torch.from_numpy(batch["y"]) 
            last_w = torch.from_numpy(batch["last_w"]) 
            setw = batch["setw"]
            y_cont = torch.from_numpy(batch['y_cont'])
            sarl_loss = pi.sarl_net.sarl_train_net(x, y, last_w=last_w,  y_cont=y_cont, device=device)
        pi.sarl_net.eval()

    pi.net.train()
    for n_epi in range(args.num_steps): 

        batch = matrix.next_batch(args.n_episode)

        x = torch.from_numpy(batch["X"]) 
        y = torch.from_numpy(batch["y"]) 
        last_w = torch.from_numpy(batch["last_w"]) 
        setw = batch["setw"]
        y_cont = torch.from_numpy(batch['y_cont'])
        
        
        pv, L1, L2, L3, nll, kl, L3_w = pi.train_net(x, y, last_w=last_w, setw=setw, y_cont=y_cont, device=device, args=args)

        results_dict['l1_losses'].append((n_epi, L1))
        results_dict['l2_losses'].append((n_epi, L2))
        results_dict['l3_losses'].append((n_epi, L3))
        results_dict['l3_losses_w'].append((n_epi, L3_w))
        results_dict['nri_nll_losses'].append((n_epi, nll))
        results_dict['nri_kl_losses'].append((n_epi, kl))


    last_action = np.zeros(action_n)
    last_action[0] = 1

    last_action = torch.from_numpy(last_action).float().to(device).unsqueeze(0)
    portfolio_value = 1

    steps = 0

    for b, i in enumerate(test_set['X']):
        with torch.no_grad():
            i = torch.from_numpy(i).float().to(device).unsqueeze(0)
            pi.net.eval()
            

            if 'sarl' in args.model_name:
                pred, _ = pi.sarl_net(i.to(device).float())
                prob, _ = pi.net(i, last_action[:,1:],  pred.detach().argmax(dim=1))
            else:
                prob, _ = pi.net(i, last_action[:,1:])

            y = torch.from_numpy(test_set["y"][b]).to(device).float().unsqueeze(0)

            ones = torch.ones(1, 1).to(device)
            future_price = torch.cat([ones, y[:, 0, :]], 1)

            w_t = last_action.squeeze(0).cpu().detach().numpy()  # [?, 12]
            w_t1 = prob.squeeze(0).cpu().detach().numpy()
            mu = calculate_pv_after_commission(w_t1, w_t, 0.0025)


            pv_vector = torch.sum(prob * future_price, 1) * mu
            portfolio_value *= pv_vector.item()


            last_action = prob * future_price / torch.sum(prob * future_price, 1)

            results_dict['eval_rewards'].append((b, portfolio_value))
            results_dict['eval_actions'].append((b, prob.detach().cpu().numpy()))
            results_dict['eval_returns'].append((b, pv_vector.detach().cpu().numpy()))

        if b%30 == 0:
            print('n_epi', b, 'pv', portfolio_value)
            with open(base_dir + '/results', 'wb') as f:
                pickle.dump(results_dict, f)


        # rolling

        if rolling:
            matrix.append_experience(None)
            
            if 'sarl' in args.model_name:
                pi.sarl_net.train()
                for i in range(args.rolling_steps): 
                    batch = matrix.next_batch(args.n_episode)

                    x = torch.from_numpy(batch["X"]) 
                    y = torch.from_numpy(batch["y"]) 
                    last_w = torch.from_numpy(batch["last_w"]) 
                    setw = batch["setw"]
                    y_cont = torch.from_numpy(batch['y_cont'])

                    sarl_loss = pi.sarl_net.sarl_train_net(x, y, last_w=last_w, y_cont=y_cont, device=device)
                pi.sarl_net.eval()

            pi.net.train()
            for i in range(args.rolling_steps): 
                steps += 1
                batch = matrix.next_batch(args.n_episode)

                x = torch.from_numpy(batch["X"]) 
                y = torch.from_numpy(batch["y"]) 
                last_w = torch.from_numpy(batch["last_w"])
                setw = batch["setw"]
                y_cont = torch.from_numpy(batch['y_cont'])
                
                
                pv, L1, L2, L3, nll, kl, L3_w = pi.train_net(x, y, last_w=last_w, setw=setw, y_cont=y_cont, device=device, args=args)

                results_dict['l1_losses'].append((n_epi+steps, L1))
                results_dict['l2_losses'].append((n_epi+steps, L2))
                results_dict['l3_losses'].append((n_epi+steps, L3))
                results_dict['l3_losses_w'].append((n_epi+steps, L3_w))
                results_dict['nri_nll_losses'].append((n_epi+steps, nll))
                results_dict['nri_kl_losses'].append((n_epi+steps, kl))


    print('n_epi', b, 'pv', portfolio_value)

    with open(base_dir + '/results', 'wb') as f:
        pickle.dump(results_dict, f)

if __name__ == '__main__':
    main()

### FILE: pgportfolio/autotrain/generate.py
----------------------------------------
from __future__ import print_function, absolute_import, division
import json
import os
import logging
from os import path


def add_packages(config, repeat=1):
    train_dir = "train_package"
    package_dir = path.realpath(__file__).replace('pgportfolio/autotrain/generate.pyc',train_dir)\
        .replace("pgportfolio\\autotrain\\generate.pyc", train_dir)\
                  .replace('pgportfolio/autotrain/generate.py',train_dir)\
        .replace("pgportfolio\\autotrain\\generate.py", train_dir)
    all_subdir = [int(s) for s in os.listdir(package_dir) if os.path.isdir(package_dir+"/"+s)]
    if all_subdir:
        max_dir_num = max(all_subdir)
    else:
        max_dir_num = 0
    indexes = []

    for i in range(repeat):
        max_dir_num += 1
        directory = package_dir+"/"+str(max_dir_num)
        config["random_seed"] = i
        os.makedirs(directory)
        indexes.append(max_dir_num)
        with open(directory + "/" + "net_config.json", 'w') as outfile:
            json.dump(config, outfile, indent=4, sort_keys=True)
    logging.info("create indexes %s" % indexes)
    return indexes



### FILE: pgportfolio/autotrain/__init__.py
----------------------------------------


### FILE: pgportfolio/autotrain/training.py
----------------------------------------
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import logging
import os
import time
from multiprocessing import Process
from pgportfolio.learn.tradertrainer import TraderTrainer
from pgportfolio.tools.configprocess import load_config


def train_one(save_path, config, log_file_dir, index, logfile_level, console_level, device):
    """
    train an agent
    :param save_path: the path to save the tensorflow model (.ckpt), could be None
    :param config: the json configuration file
    :param log_file_dir: the directory to save the tensorboard logging file, could be None
    :param index: identifier of this train, which is also the sub directory in the train_package,
    if it is 0. nothing would be saved into the summary file.
    :param logfile_level: logging level of the file
    :param console_level: logging level of the console
    :param device: 0 or 1 to show which gpu to use, if 0, means use cpu instead of gpu
    :return : the Result namedtuple
    """
    if log_file_dir:
        logging.basicConfig(filename=log_file_dir.replace("tensorboard","programlog"),
                            level=logfile_level)
        console = logging.StreamHandler()
        console.setLevel(console_level)
        logging.getLogger().addHandler(console)
    print("training at %s started" % index)
    return TraderTrainer(config, save_path=save_path, device=device).train_net(log_file_dir=log_file_dir, index=index)

def train_all(processes=1, device="cpu"):
    """
    train all the agents in the train_package folders

    :param processes: the number of the processes. If equal to 1, the logging level is debug
                      at file and info at console. If greater than 1, the logging level is
                      info at file and warming at console.
    """
    if processes == 1:
        console_level = logging.INFO
        logfile_level = logging.DEBUG
    else:
        console_level = logging.WARNING
        logfile_level = logging.INFO
    train_dir = "train_package"
    if not os.path.exists("./" + train_dir): #if the directory does not exist, creates one
        os.makedirs("./" + train_dir)
    all_subdir = os.listdir("./" + train_dir)
    all_subdir.sort()
    pool = []
    for dir in all_subdir:
        # train only if the log dir does not exist
        if not str.isdigit(dir):
            return
        # NOTE: logfile is for compatibility reason
        if not (os.path.isdir("./"+train_dir+"/"+dir+"/tensorboard") or os.path.isdir("./"+train_dir+"/"+dir+"/logfile")):
            p = Process(target=train_one, args=(
                "./" + train_dir + "/" + dir + "/netfile",
                load_config(dir),
                "./" + train_dir + "/" + dir + "/tensorboard",
                dir, logfile_level, console_level, device))
            p.start()
            pool.append(p)
        else:
            continue

        # suspend if the processes are too many
        wait = True
        while wait:
            time.sleep(5)
            for p in pool:
                alive = p.is_alive()
                if not alive:
                    pool.remove(p)
            if len(pool)<processes:
                wait = False
    print("All the Tasks are Over")


### FILE: pgportfolio/constants.py
----------------------------------------
#!/usr/bin/env python
# -*- coding: utf-8 -*-
from os import path


DATABASE_DIR = path.join(path.dirname(path.realpath(__file__)), '..', 'database', 'Data.db')
CONFIG_FILE_DIR = 'net_config.json'
LAMBDA = 1e-4  # lambda in loss function 5 in training
   # About time
NOW = 0
FIVE_MINUTES = 60 * 5
FIFTEEN_MINUTES = FIVE_MINUTES * 3
HALF_HOUR = FIFTEEN_MINUTES * 2
HOUR = HALF_HOUR * 2
TWO_HOUR = HOUR * 2
FOUR_HOUR = HOUR * 4
DAY = HOUR * 24
YEAR = DAY * 365
   # trading table name
TABLE_NAME = 'test'



### FILE: pgportfolio/__init__.py
----------------------------------------
from __future__ import absolute_import


### FILE: pgportfolio/learn/config.py
----------------------------------------
backend = 'torch'


### FILE: pgportfolio/learn/__init__.py
----------------------------------------


### FILE: pgportfolio/learn/inspect.py
----------------------------------------
import numpy as np


def get_default_initial_weights():
    np.random.seed(87)
    d = {'ConvLayer/W': (3, 3, 1, 2),
         'ConvLayer/b': (3,),
         'EIIE_Dense/W': (10, 3, 1, 30),
         'EIIE_Dense/b': (10,),
         'EIIE_Output_WithW/W': (1, 11, 1, 1),
         'EIIE_Output_WithW/b': (1,),
         'btc_bias': (1,)}
#     w = {name: np.random.randn(*shape)
#          for name, shape in d.items()}
    w = {name: np.ones(shape, dtype=np.float32) / 100000000
         for name, shape in d.items()}
    return w


def get_inputs(B=109, F=3, C=11, W=31):
     np.random.seed(87)
     i = {'x': np.zeros([B, F, C, W], dtype=np.float32) / 100,
          'y': np.zeros([B, F, C], dtype=np.float32) / 100,
          'prev_w': np.zeros([B, C], dtype=np.float32) / 100}
     # i = {'x': np.random.randn(B, F, C, W),
     #      'y': np.random.randn(B, F, C),
     #      'prev_w': np.random.randn(B, C)}
     return i

### FILE: pgportfolio/learn/nnagent.py
----------------------------------------
import pgportfolio.learn.config as config

if config.backend == 'tensorflow':
    from .tensorflow.nnagent import *
elif config.backend == 'torch':
    from .torch.nnagent import *
else:
    raise Exception('expect "tensorflow" or "torch"')


### FILE: pgportfolio/learn/rollingtrainer.py
----------------------------------------
import pgportfolio.learn.config as config

if config.backend == 'tensorflow':
    from .tensorflow.rollingtrainer import *
elif config.backend == 'torch':
    from .torch.rollingtrainer import *
else:
    raise Exception('expect "tensorflow" or "torch"')


### FILE: pgportfolio/learn/tensorflow/__init__.py
----------------------------------------


### FILE: pgportfolio/learn/tensorflow/inspect.py
----------------------------------------
import sys
from IPython import embed
import numpy as np
from .nnagent import NNAgent
from pgportfolio.tools.configprocess import load_config
from pgportfolio.learn.inspect import *
import tensorflow as tf
import os
import warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)


config = load_config()
agent = NNAgent(config, None)

for name, graph_node in agent.net.layers_dict.items():
    print(name, graph_node.name)

ndict = {
    'ConvLayer': agent.layers_dict['ConvLayer_0_activation'],
    'EIIE_Dense': agent.layers_dict['EIIE_Dense_1_activation'],
    'EIIE_Output_WithW': agent.layers_dict['EIIE_Output_WithW_2_activation'],
    'voting': agent.layers_dict['voting_3_activation'],
    'softmax_layer': agent.layers_dict['softmax_layer_4_activation'],
}

vlist = agent.net.session.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
vdict = {v.name.split(':')[0]: v for v in vlist}
vshapedict = {name: tuple(v.shape.as_list()) for name, v in vdict.items()}
{'ConvLayer/W': (1, 2, 3, 3),
 'ConvLayer/b': (3,),
 'EIIE_Dense/W': (1, 30, 3, 10),
 'EIIE_Dense/b': (10,),
 'EIIE_Output_WithW/W': (1, 1, 11, 1),
 'EIIE_Output_WithW/b': (1,),
 'btc_bias': (1, 1)}


def assign_data(vname, np_array):
    v: tf.Variable = vdict[vname]
    assert tuple(v.shape.as_list()) == tuple(np_array.shape)
    agent.session.run(v.assign(np_array))


iw = get_default_initial_weights()
iw = {'ConvLayer/W': iw['ConvLayer/W'].transpose(2, 3, 1, 0),
      'ConvLayer/b': iw['ConvLayer/b'],
      'EIIE_Dense/W': iw['EIIE_Dense/W'].transpose(2, 3, 1, 0),
      'EIIE_Dense/b': iw['EIIE_Dense/b'],
      'EIIE_Output_WithW/W': iw['EIIE_Output_WithW/W'].transpose(2, 3, 1, 0),
      'EIIE_Output_WithW/b': iw['EIIE_Output_WithW/b'],
      'btc_bias': iw['btc_bias'][:, None]}
for name, w in iw.items():
    assign_data(name, w)


output = agent.net.output

i = get_inputs()
x = i['x']
y = i['y']
prev_w = i['prev_w']
setw = lambda *a, **ka: None

# outs = {'ConvLayer/W': iw['ConvLayer/W'].transpose(2, 3, 1, 0),
#       'ConvLayer/b': iw['ConvLayer/b'],
#       'EIIE_Dense/W': iw['EIIE_Dense/W'].transpose(2, 3, 1, 0),
#       'EIIE_Dense/b': iw['EIIE_Dense/b'],
#       'EIIE_Output_WithW/W': iw['EIIE_Output_WithW/W'].transpose(2, 3, 1, 0),
#       'EIIE_Output_WithW/b': iw['EIIE_Output_WithW/b'],
#       'btc_bias': iw['btc_bias'][:, None]}



outs = dict((k, a) for k, a in zip(agent.net.layers_dict.keys(), agent.evaluate_tensors(x, y, prev_w, setw, list(agent.net.layers_dict.values()))))
outs = {
    'ConvLayer': outs['ConvLayer_0_activation'].transpose(0, 3, 1, 2),
    'EIIE_Dense': outs['EIIE_Dense_1_activation'].transpose(0, 3, 1, 2),
    'EIIE_Output_WithW': outs['EIIE_Output_WithW_2_activation'].transpose(0, 3, 1, 2),
    'voting': outs['voting_3_activation'],
    'softmax_layer': outs['softmax_layer_4_activation'],
}

embed()
sys.exit(0)


### FILE: pgportfolio/learn/tensorflow/network.py
----------------------------------------
#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import print_function
from __future__ import absolute_import
from __future__ import division
import tensorflow as tf
import tflearn


class NeuralNetWork:
    def __init__(self, feature_number, rows, columns, layers, device):
        tf_config = tf.ConfigProto()
        self.session = tf.Session(config=tf_config)
        if device == "cpu":
            tf_config.gpu_options.per_process_gpu_memory_fraction = 0
        else:
            tf_config.gpu_options.per_process_gpu_memory_fraction = 0.2
        self.input_num = tf.placeholder(tf.int32, shape=[], name='input_num')
        self.input_tensor = tf.placeholder(tf.float32, shape=[None, feature_number, rows, columns], name='x')
        self.previous_w = tf.placeholder(tf.float32, shape=[None, rows], name='prev_w')
        self._rows = rows
        self._columns = columns

        self.layers_dict = {}
        self.layer_count = 0

        self.output = self._build_network(layers)

    def _build_network(self, layers):
        pass


class CNN(NeuralNetWork):
    # input_shape (features, rows, columns)
    def __init__(self, feature_number, rows, columns, layers, device):
        NeuralNetWork.__init__(self, feature_number, rows, columns, layers, device)

    def add_layer_to_dict(self, layer_type, tensor, weights=True):

        self.layers_dict[layer_type + '_' + str(self.layer_count) + '_activation'] = tensor
        self.layer_count += 1

    # grenrate the operation, the forward computaion
    def _build_network(self, layers):
        network = tf.transpose(self.input_tensor, [0, 2, 3, 1])
        # [batch, assets, window, features]
        network = network / network[:, :, -1, 0, None, None]
        for layer_number, layer in enumerate(layers):
            if layer["type"] == "ConvLayer":
                network = tflearn.layers.conv_2d(network, int(layer["filter_number"]),
                                                 allint(layer["filter_shape"]),
                                                 allint(layer["strides"]),
                                                 layer["padding"],
                                                 layer["activation_function"],
                                                 regularizer=layer["regularizer"],
                                                 weight_decay=layer["weight_decay"],
                                                 name='ConvLayer')
                self.add_layer_to_dict(layer["type"], network)
                
            elif layer["type"] == "EIIE_Dense":
                width = network.get_shape()[2]
                network = tflearn.layers.conv_2d(network, int(layer["filter_number"]),
                                                 [1, width],
                                                 [1, 1],
                                                 "valid",
                                                 layer["activation_function"],
                                                 regularizer=layer["regularizer"],
                                                 weight_decay=layer["weight_decay"],
                                                 name='EIIE_Dense')
                self.add_layer_to_dict(layer["type"], network)
                
            elif layer["type"] == "EIIE_Output_WithW":
                width = network.get_shape()[2]
                height = network.get_shape()[1]
                features = network.get_shape()[3]
                network = tf.reshape(network, [self.input_num, int(height), 1, int(width*features)])
                w = tf.reshape(self.previous_w, [-1, int(height), 1, 1])
                network = tf.concat([network, w], axis=3)
                network = tflearn.layers.conv_2d(network, 1, [1, 1], padding="valid",
                                                 regularizer=layer["regularizer"],
                                                 weight_decay=layer["weight_decay"],
                                                 name='EIIE_Output_WithW')
                self.add_layer_to_dict(layer["type"], network)
                network = network[:, :, 0, 0]
                #btc_bias = tf.zeros((self.input_num, 1))
                btc_bias = tf.get_variable("btc_bias", [1, 1], dtype=tf.float32,
                                       initializer=tf.zeros_initializer)
                # self.add_layer_to_dict(layer["type"], network, weights=False)
                btc_bias = tf.tile(btc_bias, [self.input_num, 1])
                network = tf.concat([btc_bias, network], 1)
                self.voting = network
                self.add_layer_to_dict('voting', network, weights=False)
                network = tflearn.layers.core.activation(network, activation="softmax")
                self.add_layer_to_dict('softmax_layer', network, weights=False)
                
            # elif layer["type"] == "DenseLayer":
            #     network = tflearn.layers.core.fully_connected(network,
            #                                                   int(layer["neuron_number"]),
            #                                                   layer["activation_function"],
            #                                                   regularizer=layer["regularizer"],
            #                                                   weight_decay=layer["weight_decay"] )
            #     self.add_layer_to_dict(layer["type"], network)
            # elif layer["type"] == "DropOut":
            #     network = tflearn.layers.core.dropout(network, layer["keep_probability"])
            # elif layer["type"] == "MaxPooling":
            #     network = tflearn.layers.conv.max_pool_2d(network, layer["strides"])
            # elif layer["type"] == "AveragePooling":
            #     network = tflearn.layers.conv.avg_pool_2d(network, layer["strides"])
            # elif layer["type"] == "LocalResponseNormalization":
            #     network = tflearn.layers.normalization.local_response_normalization(network)
            # elif layer["type"] == "EIIE_Output":
            #     width = network.get_shape()[2]
            #     network = tflearn.layers.conv_2d(network, 1, [1, width], padding="valid",
            #                                      regularizer=layer["regularizer"],
            #                                      weight_decay=layer["weight_decay"])
            #     self.add_layer_to_dict(layer["type"], network)
            #     network = network[:, :, 0, 0]
            #     btc_bias = tf.ones((self.input_num, 1))
            #     self.add_layer_to_dict(layer["type"], network)
            #     network = tf.concat([btc_bias, network], 1)
            #     network = tflearn.layers.core.activation(network, activation="softmax")
            #     self.add_layer_to_dict(layer["type"], network, weights=False)
            # elif layer["type"] == "Output_WithW":
            #     network = tflearn.flatten(network)
            #     network = tf.concat([network,self.previous_w], axis=1)
            #     network = tflearn.fully_connected(network, self._rows+1,
            #                                       activation="softmax",
            #                                       regularizer=layer["regularizer"],
            #                                       weight_decay=layer["weight_decay"])

            # elif layer["type"] == "EIIE_LSTM" or\
            #                 layer["type"] == "EIIE_RNN":
            #     network = tf.transpose(network, [0, 2, 3, 1])
            #     resultlist = []
            #     reuse = False
            #     for i in range(self._rows):
            #         if i > 0:
            #             reuse = True
            #         if layer["type"] == "EIIE_LSTM":
            #             result = tflearn.layers.lstm(network[:, :, :, i],
            #                                          int(layer["neuron_number"]),
            #                                          dropout=layer["dropouts"],
            #                                          scope="lstm"+str(layer_number),
            #                                          reuse=reuse)
            #         else:
            #             result = tflearn.layers.simple_rnn(network[:, :, :, i],
            #                                                int(layer["neuron_number"]),
            #                                                dropout=layer["dropouts"],
            #                                                scope="rnn"+str(layer_number),
            #                                                reuse=reuse)
            #         resultlist.append(result)
            #     network = tf.stack(resultlist)
            #     network = tf.transpose(network, [1, 0, 2])
            #     network = tf.reshape(network, [-1, self._rows, 1, int(layer["neuron_number"])])
            else:
                raise ValueError("the layer {} not supported.".format(layer["type"]))
        return network


def allint(l):
    return [int(i) for i in l]



### FILE: pgportfolio/learn/tensorflow/nnagent.py
----------------------------------------
from __future__ import absolute_import, print_function, division
import tflearn
import tensorflow as tf
import numpy as np
from pgportfolio.constants import *
from .network import CNN

class NNAgent:
    def __init__(self, config, restore_dir=None, device="cpu"):
        self.__config = config
        self.__coin_number = config["input"]["coin_number"]
        self.__net = CNN(config["input"]["feature_number"],
                                 self.__coin_number,
                                 config["input"]["window_size"],
                                 config["layers"],
                                 device=device)
        self.__global_step = tf.Variable(0, trainable=False)
        self.__train_operation = None
        self.__y = tf.placeholder(tf.float32, shape=[None,
                                                     self.__config["input"]["feature_number"],
                                                     self.__coin_number])
        self.__future_price = tf.concat([tf.ones([self.__net.input_num, 1]),
                                       self.__y[:, 0, :]], 1)
        self.__future_omega = (self.__future_price * self.__net.output) /\
                              tf.reduce_sum(self.__future_price * self.__net.output, axis=1)[:, None]
        # tf.assert_equal(tf.reduce_sum(self.__future_omega, axis=1), tf.constant(1.0))
        self.__commission_ratio = self.__config["trading"]["trading_consumption"]
        self.__pv_vector = tf.reduce_sum(self.__net.output * self.__future_price, reduction_indices=[1]) *\
                           (tf.concat([tf.ones(1), self.__pure_pc()], axis=0))
        self.__log_mean_free = tf.reduce_mean(tf.log(tf.reduce_sum(self.__net.output * self.__future_price,
                                                                   reduction_indices=[1])))
        self.__portfolio_value = tf.reduce_prod(self.__pv_vector)
        self.__mean = tf.reduce_mean(self.__pv_vector)
        self.__log_mean = tf.reduce_mean(tf.log(self.__pv_vector))
        self.__standard_deviation = tf.sqrt(tf.reduce_mean((self.__pv_vector - self.__mean) ** 2))
        self.__sharp_ratio = (self.__mean - 1) / self.__standard_deviation
        self.__loss = self.__set_loss_function()
        self.__train_operation = self.init_train(learning_rate=self.__config["training"]["learning_rate"],
                                                 decay_steps=self.__config["training"]["decay_steps"],
                                                 decay_rate=self.__config["training"]["decay_rate"],
                                                 training_method=self.__config["training"]["training_method"])
        self.__saver = tf.train.Saver()
        if restore_dir:
            self.__saver.restore(self.__net.session, restore_dir)
        else:
            self.__net.session.run(tf.global_variables_initializer())

    @property
    def net(self) -> CNN:
        return self.__net

    @property
    def session(self):
        return self.__net.session

    @property
    def pv_vector(self):
        return self.__pv_vector

    @property
    def standard_deviation(self):
        return self.__standard_deviation

    @property
    def portfolio_weights(self):
        return self.__net.output

    @property
    def sharp_ratio(self):
        return self.__sharp_ratio

    @property
    def log_mean(self):
        return self.__log_mean

    @property
    def log_mean_free(self):
        return self.__log_mean_free

    @property
    def portfolio_value(self):
        return self.__portfolio_value

    @property
    def loss(self):
        return self.__loss

    @property
    def layers_dict(self):
        return self.__net.layers_dict

    def recycle(self):
        tf.reset_default_graph()
        self.__net.session.close()

    def __set_loss_function(self):
        def loss_function4():
            return -tf.reduce_mean(tf.log(tf.reduce_sum(self.__net.output[:] * self.__future_price,
                                                        reduction_indices=[1])))

        def loss_function5():
            return -tf.reduce_mean(tf.log(tf.reduce_sum(self.__net.output * self.__future_price, reduction_indices=[1]))) + \
                   LAMBDA * tf.reduce_mean(tf.reduce_sum(-tf.log(1 + 1e-6 - self.__net.output), reduction_indices=[1]))

        def loss_function6():
            return -tf.reduce_mean(tf.log(self.pv_vector))

        def loss_function7():
            return -tf.reduce_mean(tf.log(self.pv_vector)) + \
                   LAMBDA * tf.reduce_mean(tf.reduce_sum(-tf.log(1 + 1e-6 - self.__net.output), reduction_indices=[1]))

        def with_last_w():
            return -tf.reduce_mean(tf.log(tf.reduce_sum(self.__net.output[:] * self.__future_price, reduction_indices=[1])
                                          -tf.reduce_sum(tf.abs(self.__net.output[:, 1:] - self.__net.previous_w)
                                                         *self.__commission_ratio, reduction_indices=[1])))

        loss_function = loss_function5
        if self.__config["training"]["loss_function"] == "loss_function4":
            loss_function = loss_function4
        elif self.__config["training"]["loss_function"] == "loss_function5":
            loss_function = loss_function5
        elif self.__config["training"]["loss_function"] == "loss_function6":
            loss_function = loss_function6
        elif self.__config["training"]["loss_function"] == "loss_function7":
            loss_function = loss_function7
        elif self.__config["training"]["loss_function"] == "loss_function8":
            loss_function = with_last_w

        loss_tensor = loss_function()
        # regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
        # if regularization_losses:
        #     for regularization_loss in regularization_losses:
        #         loss_tensor += regularization_loss
        return loss_tensor

    def init_train(self, learning_rate, decay_steps, decay_rate, training_method):
        print('=== init_train ===')
        print('learning_rate:', learning_rate)
        print('decay_rate:', decay_rate)
        print('decay_steps:', decay_steps)
        print('training_method:', training_method)
        print('==================')
        learning_rate = tf.train.exponential_decay(learning_rate, self.__global_step,
                                                   decay_steps, decay_rate, staircase=True)
        if training_method == 'GradientDescent':
            train_step = tf.train.GradientDescentOptimizer(learning_rate).\
                         minimize(self.__loss, global_step=self.__global_step)
        elif training_method == 'Adam':
            train_step = tf.train.AdamOptimizer(learning_rate).\
                         minimize(self.__loss, global_step=self.__global_step)
        elif training_method == 'RMSProp':
            train_step = tf.train.RMSPropOptimizer(learning_rate).\
                         minimize(self.__loss, global_step=self.__global_step)
        else:
            raise ValueError()
        return train_step

    def train(self, x, y, last_w, setw):
        tflearn.is_training(True, self.__net.session)
        self.evaluate_tensors(x, y, last_w, setw, [self.__train_operation])

    def evaluate_tensors(self, x, y, last_w, setw, tensors):
        """
        :param x:
        :param y:
        :param last_w:
        :param setw: a function, pass the output w to it to fill the PVM
        :param tensors:
        :return:
        """
        tensors = list(tensors)
        tensors.append(self.__net.output)
        assert not np.any(np.isnan(x))
        assert not np.any(np.isnan(y))
        assert not np.any(np.isnan(last_w)),\
            "the last_w is {}".format(last_w)
        results = self.__net.session.run(tensors,
                                         feed_dict={self.__net.input_tensor: x,
                                                    self.__y: y,
                                                    self.__net.previous_w: last_w,
                                                    self.__net.input_num: x.shape[0]})
        setw(results[-1][:, 1:])
        return results[:-1]

    # save the variables path including file name
    def save_model(self, path):
        self.__saver.save(self.__net.session, path)

    # consumption vector (on each periods)
    def __pure_pc(self):
        c = self.__commission_ratio
        w_t = self.__future_omega[:self.__net.input_num-1]  # rebalanced
        w_t1 = self.__net.output[1:self.__net.input_num]
        mu = 1 - tf.reduce_sum(tf.abs(w_t1[:, 1:]-w_t[:, 1:]), axis=1)*c
        """
        mu = 1-3*c+c**2

        def recurse(mu0):
            factor1 = 1/(1 - c*w_t1[:, 0])
            if isinstance(mu0, float):
                mu0 = mu0
            else:
                mu0 = mu0[:, None]
            factor2 = 1 - c*w_t[:, 0] - (2*c - c**2)*tf.reduce_sum(
                tf.nn.relu(w_t[:, 1:] - mu0 * w_t1[:, 1:]), axis=1)
            return factor1*factor2

        for i in range(20):
            mu = recurse(mu)
        """
        return mu

    # the history is a 3d matrix, return a asset vector
    def decide_by_history(self, history, last_w):
        assert isinstance(history, np.ndarray),\
            "the history should be a numpy array, not %s" % type(history)
        assert not np.any(np.isnan(last_w))
        assert not np.any(np.isnan(history))
        tflearn.is_training(False, self.session)
        history = history[np.newaxis, :, :, :]
        return np.squeeze(self.session.run(self.__net.output, feed_dict={self.__net.input_tensor: history,
                                                                         self.__net.previous_w: last_w[np.newaxis, 1:],
                                                                         self.__net.input_num: 1}))


### FILE: pgportfolio/learn/tensorflow/rollingtrainer.py
----------------------------------------
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from pgportfolio.learn.tradertrainer import TraderTrainer
import logging
import tflearn


class RollingTrainer(TraderTrainer):
    def __init__(self, config, restore_dir=None, save_path=None, agent=None, device="cpu"):
        config["training"]["buffer_biased"] = config["trading"]["buffer_biased"]
        config["training"]["learning_rate"] = config["trading"]["learning_rate"]
        TraderTrainer.__init__(self, config, restore_dir=restore_dir, save_path=save_path,
                               agent=agent, device=device)

    @property
    def agent(self):
        return self._agent

    @property
    def coin_list(self):
        return self._matrix.coin_list

    @property
    def data_matrices(self):
        return self._matrix

    @property
    def rolling_training_steps(self):
        return self.config["trading"]["rolling_training_steps"]

    def __rolling_logging(self):
        fast_train = self.train_config["fast_train"]
        if not fast_train:
            tflearn.is_training(False, self._agent.session)

            v_pv, v_log_mean = self._evaluate("validation",
                                              self._agent.portfolio_value,
                                              self._agent.log_mean)
            t_pv, t_log_mean = self._evaluate("test", self._agent.portfolio_value, self._agent.log_mean)
            loss_value = self._evaluate("training", self._agent.loss)

            logging.info('training loss is %s\n' % loss_value)
            logging.info('the portfolio value on validation asset is %s\nlog_mean is %s\n' %
                         (v_pv,v_log_mean))
            logging.info('the portfolio value on test asset is %s\n mean is %s' % (t_pv,t_log_mean))

    def decide_by_history(self, history, last_w):
        result = self._agent.decide_by_history(history, last_w)
        return result

    def rolling_train(self, online_w=None):
        steps = self.rolling_training_steps
        if steps > 0:
            self._matrix.append_experience(online_w)
            for i in range(steps):
                x, y, last_w, w = self.next_batch()
                self._agent.train(x, y, last_w, w)
            self.__rolling_logging()


### FILE: pgportfolio/learn/tensorflow/tradertrainer.py
----------------------------------------
#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import json
import os
import time
import collections
import tflearn
import numpy as np
import pandas as pd
import tensorflow as tf
from .nnagent import NNAgent
from pgportfolio.marketdata.datamatrices import DataMatrices
import logging
Result = collections.namedtuple("Result",
                                [
                                 "test_pv",
                                 "test_log_mean",
                                 "test_log_mean_free",
                                 "test_history",
                                 "config",
                                 "net_dir",
                                 "backtest_test_pv",
                                 "backtest_test_history",
                                 "backtest_test_log_mean",
                                 "training_time"])

class TraderTrainer:
    def __init__(self, config, fake_data=False, restore_dir=None, save_path=None, device="cpu",
                 agent=None):
        """
        :param config: config dictionary
        :param fake_data: if True will use data generated randomly
        :param restore_dir: path to the model trained before
        :param save_path: path to save the model
        :param device: the device used to train the network
        :param agent: the nnagent object. If this is provides, the trainer will not
        create a new agent by itself. Therefore the restore_dir will not affect anything.
        """
        self.config = config
        self.train_config = config["training"]
        self.input_config = config["input"]
        self.save_path = save_path
        self.best_metric = 0
        np.random.seed(config["random_seed"])

        self.__window_size = self.input_config["window_size"]
        self.__coin_number = self.input_config["coin_number"]
        self.__batch_size = self.train_config["batch_size"]
        self.__snap_shot = self.train_config["snap_shot"]
        config["input"]["fake_data"] = fake_data

        self._matrix = DataMatrices.create_from_config(config)

        self.test_set = self._matrix.get_test_set()
        if not config["training"]["fast_train"]:
            self.training_set = self._matrix.get_training_set()
        self.upperbound_validation = 1
        self.upperbound_test = 1
        tf.set_random_seed(self.config["random_seed"])
        self.device = device
        if agent:
            self._agent = agent
        else:
            if device == "cpu":
                os.environ["CUDA_VISIBLE_DEVICES"] = ""
                with tf.device("/cpu:0"):
                    self._agent = NNAgent(config, restore_dir, device)
            else:
                self._agent = NNAgent(config, restore_dir, device)

    def _evaluate(self, set_name, *tensors):
        if set_name == "test":
            feed = self.test_set
        elif set_name == "training":
            feed = self.training_set
        else:
            raise ValueError()
        result = self._agent.evaluate_tensors(feed["X"],feed["y"],last_w=feed["last_w"],
                                              setw=feed["setw"], tensors=tensors)
        return result

    @staticmethod
    def calculate_upperbound(y):
        array = np.maximum.reduce(y[:, 0, :], 1)
        total = 1.0
        for i in array:
            total = total * i
        return total

    def log_between_steps(self, step):
        fast_train = self.train_config["fast_train"]
        tflearn.is_training(False, self._agent.session)

        summary, v_pv, v_log_mean, v_loss, log_mean_free, weights= \
            self._evaluate("test", self.summary,
                           self._agent.portfolio_value,
                           self._agent.log_mean,
                           self._agent.loss,
                           self._agent.log_mean_free,
                           self._agent.portfolio_weights)
        self.test_writer.add_summary(summary, step)

        if not fast_train:
            summary, loss_value = self._evaluate("training", self.summary, self._agent.loss)
            self.train_writer.add_summary(summary, step)

        # print 'ouput is %s' % out
        logging.info('='*30)
        logging.info('step %d' % step)
        logging.info('-'*30)
        if not fast_train:
            logging.info('training loss is %s\n' % loss_value)
        logging.info('the portfolio value on test set is %s\nlog_mean is %s\n'
                     'loss_value is %3f\nlog mean without commission fee is %3f\n' % \
                     (v_pv, v_log_mean, v_loss, log_mean_free))
        logging.info('='*30+"\n")

        if not self.__snap_shot:
            self._agent.save_model(self.save_path)
        elif v_pv > self.best_metric:
            self.best_metric = v_pv
            logging.info("get better model at %s steps,"
                         " whose test portfolio value is %s" % (step, v_pv))
            if self.save_path:
                self._agent.save_model(self.save_path)
        self.check_abnormal(v_pv, weights)

    def check_abnormal(self, portfolio_value, weigths):
        if portfolio_value == 1.0:
            logging.info("average portfolio weights {}".format(weigths.mean(axis=0)))


    def next_batch(self):
        batch = self._matrix.next_batch()
        batch_input = batch["X"]
        batch_y = batch["y"]
        batch_last_w = batch["last_w"]
        batch_w = batch["setw"]
        return batch_input, batch_y, batch_last_w, batch_w

    def __init_tensor_board(self, log_file_dir):
        tf.summary.scalar('benefit', self._agent.portfolio_value)
        tf.summary.scalar('log_mean', self._agent.log_mean)
        tf.summary.scalar('loss', self._agent.loss)
        tf.summary.scalar("log_mean_free", self._agent.log_mean_free)
        for layer_key in self._agent.layers_dict:
            tf.summary.histogram(layer_key, self._agent.layers_dict[layer_key])
        for var in tf.trainable_variables():
            tf.summary.histogram(var.name, var)
        grads = tf.gradients(self._agent.loss, tf.trainable_variables())
        for grad in grads:
            tf.summary.histogram(grad.name + '/gradient', grad)
        self.summary = tf.summary.merge_all()
        location = log_file_dir
        self.network_writer = tf.summary.FileWriter(location + '/network',
                                                    self._agent.session.graph)
        self.test_writer = tf.summary.FileWriter(location + '/test')
        self.train_writer = tf.summary.FileWriter(location + '/train')

    def __print_upperbound(self):
        upperbound_test = self.calculate_upperbound(self.test_set["y"])
        logging.info("upper bound in test is %s" % upperbound_test)

    def train_net(self, log_file_dir="./tensorboard", index="0"):
        """
        :param log_file_dir: logging of the training process
        :param index: sub-folder name under train_package
        :return: the result named tuple
        """
        self.__print_upperbound()
        if log_file_dir:
            if self.device == "cpu":
                with tf.device("/cpu:0"):
                    self.__init_tensor_board(log_file_dir)
            else:
                self.__init_tensor_board(log_file_dir)
        starttime = time.time()

        total_data_time = 0
        total_training_time = 0
        for i in range(self.train_config["steps"]):
            step_start = time.time()
            x, y, last_w, setw = self.next_batch()
            finish_data = time.time()
            total_data_time += (finish_data - step_start)
            self._agent.train(x, y, last_w=last_w, setw=setw)
            total_training_time += time.time() - finish_data
            if i % 1000 == 0 and log_file_dir:
                logging.info("average time for data accessing is %s"%(total_data_time/1000))
                logging.info("average time for training is %s"%(total_training_time/1000))
                total_training_time = 0
                total_data_time = 0
                self.log_between_steps(i)

        if self.save_path:
            self._agent.recycle()
            best_agent = NNAgent(self.config, restore_dir=self.save_path)
            self._agent = best_agent

        pv, log_mean = self._evaluate("test", self._agent.portfolio_value, self._agent.log_mean)
        logging.warning('the portfolio value train No.%s is %s log_mean is %s,'
                        ' the training time is %d seconds' % (index, pv, log_mean, time.time() - starttime))

        return self.__log_result_csv(index, time.time() - starttime)

    def __log_result_csv(self, index, time):
        from pgportfolio.trade import backtest
        dataframe = None
        csv_dir = './train_package/train_summary.csv'
        tflearn.is_training(False, self._agent.session)
        v_pv, v_log_mean, benefit_array, v_log_mean_free =\
            self._evaluate("test",
                           self._agent.portfolio_value,
                           self._agent.log_mean,
                           self._agent.pv_vector,
                           self._agent.log_mean_free)

        backtest = backtest.BackTest(self.config.copy(),
                                     net_dir=None,
                                     agent=self._agent)

        backtest.start_trading()
        result = Result(test_pv=[v_pv],
                        test_log_mean=[v_log_mean],
                        test_log_mean_free=[v_log_mean_free],
                        test_history=[''.join(str(e)+', ' for e in benefit_array)],
                        config=[json.dumps(self.config)],
                        net_dir=[index],
                        backtest_test_pv=[backtest.test_pv],
                        backtest_test_history=[''.join(str(e)+', ' for e in backtest.test_pc_vector)],
                        backtest_test_log_mean=[np.mean(np.log(backtest.test_pc_vector))],
                        training_time=int(time))
        new_data_frame = pd.DataFrame(result._asdict()).set_index("net_dir")
        if os.path.isfile(csv_dir):
            dataframe = pd.read_csv(csv_dir).set_index("net_dir")
            dataframe = dataframe.append(new_data_frame)
        else:
            dataframe = new_data_frame
        if int(index) > 0:
            dataframe.to_csv(csv_dir)
        return result



### FILE: pgportfolio/learn/torch/__init__.py
----------------------------------------



### FILE: pgportfolio/learn/torch/inspect.py
----------------------------------------
import torch
import torch.nn as nn

from pgportfolio.learn.inspect import *
from pgportfolio.tools.configprocess import load_config

from .nnagent import NNAgent

import numpy as np

config = load_config()
agent = NNAgent(config, None)

agent.network.conv1

vdict = {
    'ConvLayer/W': agent.network.conv1.weight,
    'ConvLayer/b': agent.network.conv1.bias,
    'EIIE_Dense/W': agent.network.conv2.weight,
    'EIIE_Dense/b': agent.network.conv2.bias,
    'EIIE_Output_WithW/W': agent.network.conv3.weight,
    'EIIE_Output_WithW/b': agent.network.conv3.bias,
    'btc_bias': agent.network.bias
}

vshapedict = {name: tuple(v.shape) for name, v in vdict.items()}
{'ConvLayer/W': (3, 3, 1, 2),
 'ConvLayer/b': (3,),
 'EIIE_Dense/W': (10, 3, 1, 30),
 'EIIE_Dense/b': (10,),
 'EIIE_Output_WithW/W': (1, 11, 1, 1),
 'EIIE_Output_WithW/b': (1,),
 'btc_bias': (1,)}

def assign_data(vname, np_array):
    v: torch.autograd.Variable = vdict[vname]
    assert tuple(v.shape) == tuple(np_array.shape)
    with torch.no_grad():
        v.set_(torch.from_numpy(np_array).to(v))

iw = get_default_initial_weights()
for name, np_array in iw.items():
    assign_data(name, np_array)




i = get_inputs()
x = i['x']
y = i['y']
prev_w = i['prev_w']
setw = lambda *a, **ka: None

agent.network.recording = True
agent.evaluate_tensors(x, y, prev_w, setw, ['output'])
agent.network.recording = False
outs = dict((k, v.cpu().numpy()) for k, v in agent.network.recorded.items())


from IPython import embed; import sys; embed(); sys.exit(0)


### FILE: pgportfolio/learn/torch/network.py
----------------------------------------
import math

import torch
import torch.nn as nn
import torch.nn.functional as F

def ContrastiveLoss(emb, y, temperature=0.5):
    y = y[:, 0, :]
    B = y.shape[0]
    C = y.shape[1]

    emb = emb.transpose(1,2)
    emb = emb.reshape(B*C, -1)
    y = y.reshape(B*C, -1)
    y = y/y.sum(1).view(B*C,1)

    similarity = F.cosine_similarity(emb.unsqueeze(1), emb.unsqueeze(0), dim=2)

    def each_loss(i, j):
        numerator = torch.exp(similarity[i, j] / temperature)

        mask = torch.ones((B*C, )).to(emb.device).scatter_(0, torch.tensor([i]).to(emb.device), 0.0)
        denominator = torch.sum(mask*torch.exp(similarity[i, :]/temperature))

        return -torch.log(numerator / denominator).squeeze(0)

    loss = 0

    for k in range(0, B*C):
        y_k = torch.ones((B*C,y.shape[1])).to(emb.device)*y[k,:]
        criterion = nn.KLDivLoss(reduction='none')
        #print(criterion(y , y_k).sum(1).squeeze().data.shape)

        _, neighbor = torch.topk(criterion(y , y_k).sum(1).squeeze(), 2, dim=-1, largest=False, sorted=True)

        #print(neighbor.shape)
        #print(neighbor[1])

        loss += each_loss(k, neighbor[1])
    return loss


class MultiHeadAttention(nn.Module):
    def __init__(self, heads, d_model, dropout = 0.1):
        super().__init__()

        self.d_model = d_model
        self.d_k = d_model // heads
        self.h = heads

        self.q_linear = nn.Linear(d_model, d_model)
        self.v_linear = nn.Linear(d_model, d_model)
        self.k_linear = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout)
        self.out = nn.Linear(d_model, d_model)

    def attention(self,q, k, v, d_k, mask=None, dropout=None):

        scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)
        if mask is not None:
                mask = mask.unsqueeze(1)
                scores = scores.masked_fill(mask == 0, -1e9)
        scores = F.softmax(scores, dim=-1)

        if dropout is not None:
            scores = dropout(scores)

        output = torch.matmul(scores, v)
        return output

    def forward(self, x, mask=None):

        bs = x.size(0)

        # perform linear operation and split into h heads

        k = self.k_linear(x).view(bs, -1, self.h, self.d_k)
        q = self.q_linear(x).view(bs, -1, self.h, self.d_k)
        v = self.v_linear(x).view(bs, -1, self.h, self.d_k)

        # transpose to get dimensions bs * h * sl * d_model

        k = k.transpose(1,2)
        q = q.transpose(1,2)
        v = v.transpose(1,2)
        # calculate attention using function we will define next
        scores = self.attention(q, k, v, self.d_k, mask, self.dropout)

        # concatenate heads and put through final linear layer
        concat = scores.transpose(1,2).contiguous()\
        .view(bs, -1, self.d_model)

        output = self.out(concat)

        return output

class Norm(nn.Module):
    def __init__(self, d_model, eps = 1e-6):
        super().__init__()

        self.size = d_model
        # create two learnable parameters to calibrate normalisation
        self.alpha = nn.Parameter(torch.ones(self.size))
        self.eps = eps
    def forward(self, x):
        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \
        / (x.std(dim=-1, keepdim=True) + self.eps)

        if torch.isnan(norm).any():
            print('1', self.alpha)
            print('2', x.mean(dim=-1, keepdim=True))
            print('3', x.std(dim=-1, keepdim=True))
            print('4', (x - x.mean(dim=-1, keepdim=True)))
            print('5', x)
        assert not torch.isnan(norm).any()

        return norm

def tflearn_default_conv2d_init_(conv2d, factor=1.0):
    shape = [*conv2d.kernel_size, conv2d.in_channels, conv2d.out_channels]

    input_size = 1.0
    for dim in shape[:-1]:
        input_size *= float(dim)

    max_val = math.sqrt(3 / input_size) * factor
    conv2d.weight.data.uniform_(-max_val, max_val)
    conv2d.bias.data.zero_()

class Network(nn.Module):
    def __init__(self, config):
        super().__init__()

        self.F = config["input"]["feature_number"]
        self.C = config["input"]["coin_number"]
        self.W = config["input"]["window_size"]

        D1 = 3
        D2 = 10


        self.conv1 = nn.Conv2d(self.F, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.W-1))

        #self.head1 = MultiHeadAttention(4, self.hidden_dim1)

        self.conv3 = nn.Conv2d(D2+1, 1, kernel_size=(1, 1))
        self.bias = nn.Parameter(torch.zeros(1))


        self.recorded = {}
        self.recording = True

        #self.reset_parameters()

    #def reset_parameters(self):
    #    for m in self.modules():
    #        if isinstance(m, nn.Conv2d):
    #            tflearn_default_conv2d_init_(m)
    #    self.bias.data.zero_()

    def forward(self, *a, **ka):
        self.recorded.clear()
        if self.recording:
            for name, output in self.nodeiter(*a, **ka):
                self.recorded[name] = output.detach()
        else:
            for _, output in self.nodeiter(*a, **ka):
                pass
        return output

    def nodeiter(self, x, prev_w):
        # x: (B, F, C, W)
        # prev_w: (B, C)

        assert isinstance(x, torch.Tensor)
        assert isinstance(prev_w, torch.Tensor)
        assert x.shape[1:] == (self.F, self.C, self.W)
        assert prev_w.shape[1:] == (self.C,)
        assert prev_w.shape[:1] == x.shape[:1]

        B = x.shape[0]

        # x.shape == (B, F, C, W)
        # x[:, 0, :, -1].shape == (B, C)
        # x[:, 0, None, :, -1, None].shape == (B, 1, C, 1)
        x = x / x[:, 0, None, :, -1, None] # normalize???

        x = self.conv1(x)  # (B, 3, C, W-1)
        x = torch.relu(x)
        yield 'ConvLayer', x
        #print('1.', x.sahpe)

        x = self.conv2(x)  # (B, 10, C, 1)
        x = torch.relu(x)
        yield 'EIIE_Dense', x
        #print('2.', x.sahpe)

        prev_w = prev_w.view(B, 1, self.C, 1)  # (B, 1, C, 1)
        x = torch.cat([x, prev_w], 1)  # (B, 11, C, 1)
        x = self.conv3(x)  # (B, 1, C, 1)
        yield 'EIIE_Output_WithW', x
        #print('3.', x.sahpe)

        x = torch.cat([
            self.bias.repeat(B, 1),  # (B, 1)
            x[:, 0, :, 0]  # (B, C)
        ], 1)  # (B, 1+C)
        yield 'voting', x

        x = torch.softmax(x, -1)  # (B, 1+C)
        yield 'softmax_layer', x


### FILE: pgportfolio/learn/torch/nnagent.py
----------------------------------------
from __future__ import absolute_import, print_function, division
import numpy as np
from pgportfolio.constants import *
from .network import Network, ContrastiveLoss

import torch
import torch.nn as nn
import torch.optim as optim

import os
import math
import inspect


class NNAgent:
    def __init__(self, config, restore_dir=None, device="cpu"):
        self.config = config
        self.device = device

        # Model
        self.network = Network(config).to(device)

        # Optimizer
        #self.optimizer = optim.AdamW([
        #    dict(params=[*self.network.conv1.parameters(),
        #                 self.network.bias]),
        #    dict(params=self.network.conv2.parameters(),
        #         weight_decay=5e-9), # L2 reg
        #    dict(params=self.network.conv3.parameters(),
        #         weight_decay=5e-8), # L2 reg
        #], lr=config['training']['learning_rate'])

        self.optimizer = optim.AdamW(self.network.parameters(), lr=config['training']['learning_rate'])

        # Exponential LR Scheduler
        r = config['training']['decay_rate']
        s = config['training']['decay_steps']
        gamma = math.exp(math.log(r) / s)
        self.lr_scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma)

        if restore_dir is not None and os.path.isfile(restore_dir):
            print('restore model from', restore_dir)
            self.load_model(restore_dir)

        self.num_assets = config['input']['coin_number']

        def _generate_graph_outputs_dict():
            def future_price(input_num, y):
                # shape: [B, C+1]
                ones = torch.ones(input_num, 1).to(device)
                return torch.cat([ones, y[:, 0, :]], 1)

            def future_omega(future_price, output):
                # shape: [B, C+1]
                val = future_price * output
                return val / val.sum(-1, keepdim=True)

            def pure_pc(future_omega, output, commission_ratio, input_num):
                c = commission_ratio  # float
                w_t = future_omega[:input_num-1]  # [?, 12]
                w_t1 = output[1:input_num]
                mu = 1 - torch.sum(torch.abs(w_t1[:, 1:] - w_t[:, 1:]), 1) * c
                return mu

            def pv_vector(output, future_price, pure_pc):
                ones = torch.ones(1).to(device)
                return torch.sum(output * future_price, 1) * torch.cat([ones, pure_pc], 0)

            def log_mean_free(output, future_price):
                return torch.mean(torch.log(torch.sum(output * future_price, 1)))

            def portfolio_value(pv_vector):
                return torch.prod(pv_vector)

            def portfolio_weights(output):
                return output

            def mean(pv_vector):
                return torch.mean(pv_vector)

            def log_mean(pv_vector):
                return torch.mean(torch.log(pv_vector))

            def standard_deviation(pv_vector, mean):
                return torch.sqrt(torch.mean((pv_vector - mean) ** 2))

            def sharp_ratio(mean, standard_deviation):
                return (mean - 1) / standard_deviation

            def pv_future(output, y_cont):
                #print(output.shape)
                #print(y_cont.shape)
                return torch.sum(torch.bmm(output[:, 1:].unsqueeze(1) , 0.25*(y_cont[:, 0,:, :]-1)), -1).squeeze()

            #def contrastive_loss(representation, y_cont):
                #print('representation.shape', representation.shape)
                #print('y_cont.shape', y_cont.shape)
            #    return ContrastiveLoss(representation, y_cont)

            def loss(pv_vector, pv_future):
                #print(pv_future)
                #print(torch.log(pv_vector), pv_future)

                #print('contrastive', contrastive_loss) #6757.7402
                #print('pv_future', pv_future.shape)
                #return -torch.mean(torch.log(pv_vector) + torch.sigmoid(-torch.log(pv_vector).detach())*pv_future) + contrastive_loss
                return -torch.mean(torch.log(pv_vector))

            return locals()

        self._graph_nodes = {}
        self._graph_nodes.update(_generate_graph_outputs_dict())
        self._graph_nodes.update({
            'commission_ratio': lambda: config['trading']['trading_consumption'],
            'output': lambda x, prev_w: self.network(x, prev_w),
            'representation':lambda output: self.network.recorded['ConvLayer']
        })

    def evaluate(self, feed_dict, node_names):
        computed = feed_dict.copy()
        #print(computed.keys())

        def _evaluate(node_name):
            if node_name in computed:
                return computed[node_name]

            if node_name in self._graph_nodes:
                f = self._graph_nodes[node_name]
                input_nodes = inspect.getargspec(f).args
                value = f(*map(_evaluate, input_nodes))
                computed[node_name] = value
                return value

            raise Exception('expect {!r} in feed_dict'.format(node_name))

        return list(map(_evaluate, node_names))

    def train(self, x, y, last_w, setw, y_cont):
        # , log_node=None, log_grad=None, log_out=None
        self.network.train()

        feed_dict = dict(x=self.to_tensor(x),
                         y=self.to_tensor(y),
                         prev_w=self.to_tensor(last_w),
                         input_num=x.shape[0],
                         y_cont=self.to_tensor(y_cont))

        # if callable(log_node):
        #     self.network.recording = True

        loss, output = self.evaluate(feed_dict,
                                     ['loss', 'output'])

        # if callable(log_out):
        #     log_out('loss', loss)

        # if callable(log_node):
        #     for name, tensor in self.network.recorded.items():
        #         log_node(name, tensor)

        self.network.zero_grad()
        loss.backward()

        # if callable(log_grad):
        #     for name, grad in self.network.named_parameters():
        #         log_grad(name, grad)

        self.optimizer.step()
        self.lr_scheduler.step()

        setw(self.from_tensor(output[:, 1:]))

    def evaluate_tensors(self, x, y, last_w, setw, y_cont, tensors):
        """
        :param x:
        :param y:
        :param last_w:
        :param setw: a function, pass the output w to it to fill the PVM
        :param tensors:
        :return:
        """
        tensors = list(tensors)
        tensors.append('output')

        assert not np.any(np.isnan(x))
        assert not np.any(np.isnan(y))
        assert not np.any(np.isnan(last_w)),\
            "the last_w is {}".format(last_w)

        feed_dict = dict(x=self.to_tensor(x),
                         y=self.to_tensor(y),
                         prev_w=self.to_tensor(last_w),
                         input_num=x.shape[0],
                         y_cont=self.to_tensor(y_cont))

        results = self.evaluate(feed_dict, tensors)
        results = [self.from_tensor(result) for result in results]

        setw(results[-1][:, 1:])
        return results[:-1]

    # save the variables path including file name
    def save_model(self, path):
        torch.save({
            'optimizer': self.optimizer.state_dict(),
            'lr_scheduler': self.lr_scheduler.state_dict(),
            'network': self.network.state_dict(),
        }, path)

    def load_model(self, path):
        state = torch.load(path)
        self.network.load_state_dict(state['network'])
        self.optimizer.load_state_dict(state['optimizer'])
        self.lr_scheduler.load_state_dict(state['lr_scheduler'])

    # the history is a 3d matrix, return a asset vector
    def decide_by_history(self, history, last_w):
        assert isinstance(history, np.ndarray),\
            "the history should be a numpy array, not %s" % type(
                history)
        assert not np.any(np.isnan(last_w))
        assert not np.any(np.isnan(history))
        history = history[np.newaxis, :, :, :]

        feed_dict = dict(x=self.to_tensor(history),
                         prev_w=self.to_tensor(last_w[np.newaxis, 1:]),
                         input_num=1)
        node_names = ['output']

        self.network.eval()
        with torch.no_grad():
            output = self.evaluate(feed_dict, node_names)[0]

        output = self.from_tensor(output)
        return np.squeeze(output)

    def to_tensor(self, np_array):
        return torch.from_numpy(np_array).float().to(self.device)

    def from_tensor(self, torch_tensor):
        if not isinstance(torch_tensor, torch.Tensor):
            return torch_tensor
        return torch_tensor.detach().cpu().numpy()

    def recycle(self):
        pass # NO OP


### FILE: pgportfolio/learn/torch/rollingtrainer.py
----------------------------------------

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from .tradertrainer import TraderTrainer
import logging
# import tflearn


class RollingTrainer(TraderTrainer):
    def __init__(self, config, restore_dir=None, save_path=None, agent=None, device="cpu"):
        config["training"]["buffer_biased"] = config["trading"]["buffer_biased"]
        config["training"]["learning_rate"] = config["trading"]["learning_rate"]
        TraderTrainer.__init__(self, config, restore_dir=restore_dir, save_path=save_path,
                               agent=agent, device=device)

    @property
    def agent(self):
        return self._agent

    @property
    def coin_list(self):
        return self._matrix.coin_list

    @property
    def data_matrices(self):
        return self._matrix

    @property
    def rolling_training_steps(self):
        return self.config["trading"]["rolling_training_steps"]

    def __rolling_logging(self):
        fast_train = self.train_config["fast_train"]
        if not fast_train:
            v_pv, v_log_mean = self._evaluate("validation",
                                              'portfolio_value',
                                              'log_mean')
            t_pv, t_log_mean = self._evaluate("test", 'portfolio_value', 'log_mean')
            loss_value = self._evaluate("training", 'loss')
            print(t_pv)

            logging.info('training loss is %s\n' % loss_value)
            logging.info('the portfolio value on validation asset is %s\nlog_mean is %s\n' %
                         (v_pv,v_log_mean))
            logging.info('the portfolio value on test asset is %s\n mean is %s' % (t_pv,t_log_mean))

    def decide_by_history(self, history, last_w):
        result = self._agent.decide_by_history(history, last_w)
        return result

    def rolling_train(self, online_w=None):
        steps = self.rolling_training_steps
        if steps > 0:
            self._matrix.append_experience(online_w)
            for i in range(steps):
                x, y, last_w, w, y_cont = self.next_batch()
                self._agent.train(x, y, last_w, w, y_cont)
            self.__rolling_logging()


### FILE: pgportfolio/learn/torch/tradertrainer.py
----------------------------------------
import json
import os
import time
import collections

import numpy as np
import pandas as pd
import torch

from .nnagent import NNAgent
from pgportfolio.marketdata.datamatrices import DataMatrices

import logging

Result = collections.namedtuple("Result",
                                [
                                 "test_pv",
                                 "test_log_mean",
                                 "test_log_mean_free",
                                 "test_history",
                                 "config",
                                 "net_dir",
                                 "backtest_test_pv",
                                 "backtest_test_history",
                                 "backtest_test_log_mean",
                                 "training_time"])

class TraderTrainer:
    def __init__(self, config, fake_data=False, restore_dir=None, save_path=None, device="cpu",
                 agent=None):
        """
        :param config: config dictionary
        :param fake_data: if True will use data generated randomly
        :param restore_dir: path to the model trained before
        :param save_path: path to save the model
        :param device: the device used to train the network
        :param agent: the nnagent object. If this is provides, the trainer will not
        create a new agent by itself. Therefore the restore_dir will not affect anything.
        """
        self.config = config
        self.train_config = config["training"]
        self.input_config = config["input"]
        self.save_path = save_path
        self.best_metric = 0
        np.random.seed(config["random_seed"])

        self.__window_size = self.input_config["window_size"]
        self.__coin_number = self.input_config["coin_number"]
        self.__batch_size = self.train_config["batch_size"]
        self.__snap_shot = self.train_config["snap_shot"]
        config["input"]["fake_data"] = fake_data

        self._matrix = DataMatrices.create_from_config(config)

        self.test_set = self._matrix.get_test_set()

        if not config["training"]["fast_train"]:
            self.training_set = self._matrix.get_training_set()

        self.upperbound_validation = 1
        self.upperbound_test = 1

        torch.manual_seed(self.config["random_seed"])
        self.device = device

        if agent:
            self._agent = agent
        else:
            self._agent = NNAgent(config, restore_dir, device)

    def _evaluate(self, set_name, *tensors):
        if set_name == "test":
            feed = self.test_set
        elif set_name == "training":
            feed = self.training_set
        else:
            raise ValueError()
        self._agent.network.eval()
        result = self._agent.evaluate_tensors(feed["X"], feed["y"],
            last_w=feed["last_w"], setw=feed["setw"], y_cont=feed['y_cont'], tensors=tensors)
        return result

    @staticmethod
    def calculate_upperbound(y):
        array = np.maximum.reduce(y[:, 0, :], 1)
        # total = 1.0
        # for i in array:
        #     total = total * i
        return np.prod(array)

    def log_between_steps(self, step):
        fast_train = self.train_config["fast_train"]
        self._agent.network.eval()

        # TensorFlow version
        # summary, v_pv, v_log_mean, v_loss, log_mean_free, weights= \
        #     self._evaluate("test", self.summary,
        #                    self._agent.portfolio_value,
        #                    self._agent.log_mean,
        #                    self._agent.loss,
        #                    self._agent.log_mean_free,
        #                    self._agent.portfolio_weights)
        # self.test_writer.add_summary(summary, step)

        v_pv, v_log_mean, v_loss, log_mean_free, weights = \
            self._evaluate("test",
                           'portfolio_value',
                           'log_mean',
                           'loss',
                           'log_mean_free',
                           'portfolio_weights')

        if not fast_train:
            # summary, loss_value = self._evaluate("training", self.summary, self._agent.loss) # TensorFlow version
            loss_value, = self._evaluate("training", 'loss')
            # self.train_writer.add_summary(summary, step) # TODO

        # print 'ouput is %s' % out
        logging.info('='*30)
        logging.info('step %d' % step)
        logging.info('-'*30)

        if not fast_train:
            logging.info('training loss is %s\n' % loss_value)

        logging.info('the portfolio value on test set is %s\nlog_mean is %s\n'
                     'loss_value is %3f\nlog mean without commission fee is %3f\n' % \
                     (v_pv, v_log_mean, v_loss, log_mean_free))

        logging.info('='*30+"\n")

        if not self.__snap_shot:
            self._agent.save_model(self.save_path)

        elif v_pv > self.best_metric:
            self.best_metric = v_pv
            logging.info("get better model at %s steps,"
                         " whose test portfolio value is %s" % (step, v_pv))
            if self.save_path:
                self._agent.save_model(self.save_path)

        self.check_abnormal(v_pv, weights)

    def check_abnormal(self, portfolio_value, weigths):
        if portfolio_value == 1.0:
            logging.info("average portfolio weights {}".format(weigths.mean(axis=0)))

    def next_batch(self):
        batch = self._matrix.next_batch()
        batch_input = batch["X"] # (B, F, C, W)
        batch_y = batch["y"] # (B, F, C)
        batch_last_w = batch["last_w"] # (B, C)
        batch_w = batch["setw"]
        batch_y_cont = batch['y_cont']
        return batch_input, batch_y, batch_last_w, batch_w, batch_y_cont

    def __init_tensor_board(self, log_file_dir):
        pass
        # scalars = ['benefit', 'log_mean', 'loss', 'log_mean_free']
        # histograms = ['layers', ..., 'gradients', ...]

        # TensorFlow version
        # ------------------
        # tf.summary.scalar('benefit', self._agent.portfolio_value)
        # tf.summary.scalar('log_mean', self._agent.log_mean)
        # tf.summary.scalar('loss', self._agent.loss)
        # tf.summary.scalar("log_mean_free", self._agent.log_mean_free)
        # for layer_key in self._agent.layers_dict:
        #     tf.summary.histogram(layer_key, self._agent.layers_dict[layer_key])
        # for var in tf.trainable_variables():
        #     tf.summary.histogram(var.name, var)
        # grads = tf.gradients(self._agent.loss, tf.trainable_variables())
        # for grad in grads:
        #     tf.summary.histogram(grad.name + '/gradient', grad)
        # self.summary = tf.summary.merge_all()
        # location = log_file_dir
        # self.network_writer = tf.summary.FileWriter(location + '/network',
        #                                             self._agent.session.graph)
        # self.test_writer = tf.summary.FileWriter(location + '/test')
        # self.train_writer = tf.summary.FileWriter(location + '/train')

        # self.network_writer = torch.utils.tensorboard.SummaryWriter(log_file_dir + '/network')
        # self.train_writer = torch.utils.tensorboard.SummaryWriter(log_file_dir + '/train')
        # self.test_writer = torch.utils.tensorboard.SummaryWriter(log_file_dir + '/test')

    def __print_upperbound(self):
        upperbound_test = self.calculate_upperbound(self.test_set["y"])
        logging.info("upper bound in test is %s" % upperbound_test)

    def train_net(self, log_file_dir="./tensorboard", index="0"):
        """
        :param log_file_dir: logging of the training process
        :param index: sub-folder name under train_package
        :return: the result named tuple
        """
        self.__print_upperbound()
        # TensorFlow version
        # if log_file_dir:
        #     if self.device == "cpu":
        #         with tf.device("/cpu:0"):
        #             self.__init_tensor_board(log_file_dir)
        #     else:
        #         self.__init_tensor_board(log_file_dir)
        starttime = time.time()

        total_data_time = 0
        total_training_time = 0

        for i in range(self.train_config["steps"]):
            step_start = time.time()
            x, y, last_w, setw, y_cont = self.next_batch()

            # x.shape: (109, 3, n_coins, window_size)
            # y.shape: (109, 3, n_coins)
            # last_w.shape: (109, n_coins)
            # setw is a function to set weights. TODO: verify

            finish_data = time.time()
            total_data_time += (finish_data - step_start)

            self._agent.train(x, y, last_w=last_w, setw=setw, y_cont=y_cont)

            total_training_time += time.time() - finish_data

            if i % 1000 == 0 and log_file_dir:
                logging.info("average time for data accessing is %s"%(total_data_time/1000))
                logging.info("average time for training is %s"%(total_training_time/1000))
                total_training_time = 0
                total_data_time = 0

                self.log_between_steps(i)

        if self.save_path:
            # self._agent.recycle() # TensorFlow version
            best_agent = NNAgent(self.config, restore_dir=self.save_path, device=self._agent.device)
            self._agent = best_agent

        # pv, log_mean = self._evaluate("test", self.portfolio_value, self._agent.log_mean) # TensorFlow version
        pv, log_mean = self._evaluate("test", 'portfolio_value', 'log_mean')

        logging.warning('the portfolio value train No.%s is %s log_mean is %s,'
                        ' the training time is %d seconds' % (index, pv, log_mean, time.time() - starttime))

        return self.__log_result_csv(index, time.time() - starttime)

    def __log_result_csv(self, index, time):
        from pgportfolio.trade import backtest
        dataframe = None
        csv_dir = './train_package/train_summary.csv'
        # tflearn.is_training(False, self._agent.session)
        # v_pv, v_log_mean, benefit_array, v_log_mean_free =\
        #     self._evaluate("test",
        #                    self._agent.portfolio_value,
        #                    self._agent.log_mean,
        #                    self._agent.pv_vector,
        #                    self._agent.log_mean_free) # TensorFlow version
        v_pv, v_log_mean, benefit_array, v_log_mean_free =\
            self._evaluate("test",
                           'portfolio_value',
                           'log_mean',
                           'pv_vector',
                           'log_mean_free')

        backtest = backtest.BackTest(self.config.copy(),
                                     net_dir=None,
                                     agent=self._agent)

        backtest.start_trading()
        result = Result(test_pv=[v_pv],
                        test_log_mean=[v_log_mean],
                        test_log_mean_free=[v_log_mean_free],
                        test_history=[''.join(str(e)+', ' for e in benefit_array)],
                        config=[json.dumps(self.config)],
                        net_dir=[index],
                        backtest_test_pv=[backtest.test_pv],
                        backtest_test_history=[''.join(str(e)+', ' for e in backtest.test_pc_vector)],
                        backtest_test_log_mean=[np.mean(np.log(backtest.test_pc_vector))],
                        training_time=int(time))
        new_data_frame = pd.DataFrame(result._asdict()).set_index("net_dir")
        if os.path.isfile(csv_dir):
            dataframe = pd.read_csv(csv_dir).set_index("net_dir")
            dataframe = dataframe.append(new_data_frame)
        else:
            dataframe = new_data_frame
        if int(index) > 0:
            dataframe.to_csv(csv_dir)
        return result



### FILE: pgportfolio/learn/tradertrainer.py
----------------------------------------
import pgportfolio.learn.config as config

print(config.backend)

if config.backend == 'tensorflow':
    from .tensorflow.tradertrainer import *
elif config.backend == 'torch':
    from .torch.tradertrainer import *
else:
    raise Exception('expect "tensorflow" or "torch"')


### FILE: pgportfolio/marketdata/datamatrices.py
----------------------------------------
from __future__ import print_function
from __future__ import absolute_import
from __future__ import division
from pgportfolio.marketdata.globaldatamatrix import *
import numpy as np
import pandas as pd
import logging
from pgportfolio.tools.configprocess import parse_time
from pgportfolio.tools.data import get_volume_forward, get_type_list
import pgportfolio.marketdata.replaybuffer as rb

MIN_NUM_PERIOD = 3


class DataMatrices:
    def __init__(self, start, end, period, batch_size=50, volume_average_days=30, buffer_bias_ratio=0,
                 market="poloniex", coin_filter=1, window_size=50, feature_number=3, test_portion=0.15,
                 portion_reversed=False, online=False, is_permed=False, stock=False, smoothing_days=5):
        """
        :param start: Unix time
        :param end: Unix time
        :param access_period: the data access period of the input matrix.
        :param trade_period: the trading period of the agent.
        :param global_period: the data access period of the global price matrix.
                              if it is not equal to the access period, there will be inserted observations
        :param coin_filter: number of coins that would be selected
        :param window_size: periods of input data
        :param train_portion: portion of training set
        :param is_permed: if False, the sample inside a mini-batch is in order
        :param validation_portion: portion of cross-validation set
        :param test_portion: portion of test set
        :param portion_reversed: if False, the order to sets are [train, validation, test]
        else the order is [test, validation, train]
        """
        start = int(start)
        self.__end = int(end)
        self.__smoothing_days = smoothing_days

        # assert window_size >= MIN_NUM_PERIOD
        self.__coin_no = coin_filter
        type_list = get_type_list(feature_number)
        self.__features = type_list
        self.feature_number = feature_number
        
        if stock == 0:
            self.__global_data = get_global_panel_stock(start,
                                                        self.__end,
                                                        period=period,
                                                        features=type_list)
        else:
            self.__global_data = get_global_panel_btc(start,
                                                    self.__end,
                                                    period=period,
                                                    features=type_list,
                                                    stocks=stock)
        #else:
        #    raise ValueError("market {} is not valid".format(market))
        self.__period_length = period
        # portfolio vector memory, [time, assets]
        self.__PVM = pd.DataFrame(index=self.__global_data.minor_axis,
                                  columns=self.__global_data.major_axis)
        self.__PVM = self.__PVM.fillna(1.0 / self.__coin_no)

        self._window_size = window_size
        self._num_periods = len(self.__global_data.minor_axis)
        self.__divide_data(test_portion, portion_reversed)

        self._portion_reversed = portion_reversed
        self.__is_permed = is_permed

        self.__batch_size = batch_size
        self.__delta = 0  # the count of global increased
        end_index = self._train_ind[-1]
        self.__replay_buffer = rb.ReplayBuffer(start_index=self._train_ind[0],
                                               end_index=end_index,
                                               sample_bias=buffer_bias_ratio,
                                               batch_size=self.__batch_size,
                                               coin_number=self.__coin_no,
                                               is_permed=self.__is_permed)

        logging.info("the number of training examples is %s"
                     ", of test examples is %s" % (self._num_train_samples, self._num_test_samples))
        logging.debug("the training set is from %s to %s" % (min(self._train_ind), max(self._train_ind)))
        logging.debug("the test set is from %s to %s" % (min(self._test_ind), max(self._test_ind)))

    @property
    def global_weights(self):
        return self.__PVM

    @staticmethod
    def create_from_config(config, stock, args):
        """main method to create the DataMatrices in this project
        @:param config: config dictionary
        @:return: a DataMatrices object
        """
        config = config.copy()
        input_config = config["input"]
        train_config = config["training"]
        start = parse_time(input_config["start_date"])
        end = parse_time(input_config["end_date"])
        return DataMatrices(start=start,
                            end=end,
                            market=input_config["market"],
                            feature_number=input_config["feature_number"],
                            window_size=input_config["window_size"],
                            online=input_config["online"],
                            period=input_config["global_period"],
                            coin_filter=input_config["coin_number"],
                            is_permed=input_config["is_permed"],
                            buffer_bias_ratio=args.buffer_biased,
                            batch_size=train_config["batch_size"],
                            volume_average_days=input_config["volume_average_days"],
                            test_portion=args.test_portion,
                            portion_reversed=input_config["portion_reversed"],
                            stock=stock,
                            smoothing_days=args.smoothing_days
                            )

    @property
    def global_matrix(self):
        return self.__global_data

    @property
    def num_train_samples(self):
        return self._num_train_samples

    @property
    def test_indices(self):
        return self._test_ind[:-(self._window_size+1):]

    @property
    def num_test_samples(self):
        return self._num_test_samples

    def append_experience(self, online_w=None):
        """
        :param online_w: (number of assets + 1, ) numpy array
        Let it be None if in the backtest case.
        """
        self.__delta += 1
        self._train_ind.append(self._train_ind[-1]+1)
        appended_index = self._train_ind[-1]
        self.__replay_buffer.append_experience(appended_index)

    def get_test_set(self):
        return self.__pack_samples(self.test_indices)

    def get_training_set(self):
        #return self.__pack_samples(self._train_ind[:-self._window_size])
        return self.__pack_samples(self._train_ind[:])

    def next_batch(self, n_episode):
        """
        @:return: the next batch of training sample. The sample is a dictionary
        with key "X"(input data); "y"(future relative price); "last_w" a numpy array
        with shape [batch_size, assets]; "w" a list of numpy arrays list length is
        batch_size
        """
        batch = self.__pack_samples([exp.state_index for times in self.__replay_buffer.next_experience_batch(n_episode) for exp in times])
        return batch

    def nearest(self, num_nearest):
        near = self.__pack_samples(self._train_ind[-num_nearest:])
        return near

    def __pack_samples(self, indexs):
        indexs = np.array(indexs)
        last_w = self.__PVM.values[indexs-1, :]
        N_last_w = self.__PVM.values[indexs, :]

        def setw(w):
            self.__PVM.iloc[indexs, :] = w
        #for index in indexs:
        #    print(self.get_submatrix(index).shape)
        M = [self.get_submatrix(index) for index in indexs]
        M = np.array(M)
        X = M[:, :, :, :-self.__smoothing_days]
        y = M[:, :, :, -self.__smoothing_days] / M[:, 0, None, :, -(self.__smoothing_days + 1)]
        y_cont = M[:, :, :, -self.__smoothing_days: ] / M[:, 0, None, :, -(self.__smoothing_days + 1):-1]

        N = [self.get_submatrix(index + 1) for index in indexs]
        N = np.array(N)
        N_X = N[:, :, :, :-self.__smoothing_days]
        N_y = N[:, :, :, -self.__smoothing_days] / N[:, 0, None, :, -(self.__smoothing_days + 1)]
        N_y_cont = N[:, :, :, -self.__smoothing_days: ] / N[:, 0, None, :, -(self.__smoothing_days + 1):-1]
        return {"X": X, "y": y, "last_w": last_w, "setw": setw, "y_cont": y_cont, "N_X": N_X, "N_y": N_y, "N_last_w": N_last_w, "N_y_cont": N_y_cont}

    # volume in y is the volume in next access period
    def get_submatrix(self, ind):
        m = self.__global_data.values[:, :, ind:ind+self._window_size + self.__smoothing_days]
        n = self._window_size + self.__smoothing_days - m.shape[-1]
        if n > 0:
            m = np.concatenate((m, np.zeros(list(m.shape[:-1]) + [n])), -1)
        return m
#         if self.__global_data.values[:, :, ind:ind+self._window_size + 5].shape[-1] < self._window_size + 5:
#             self.__global_data.values[:, :, ind+self._window_size:ind+self._window_size + 5]  = self.__global_data.values[:, :, ind+self._window_size]
#         return self.__global_data.values[:, :, ind:ind+self._window_size + 5]

    def __divide_data(self, test_portion, portion_reversed):
        print('1',test_portion)
        train_portion = 1 - test_portion
        s = float(train_portion + test_portion)
        print('2',s)
        if portion_reversed:
            portions = np.array([test_portion]) / s
            portion_split = (portions * self._num_periods).astype(int)
            indices = np.arange(self._num_periods)
            self._test_ind, self._train_ind = np.split(indices, portion_split)
        else:
            portions = np.array([train_portion]) / s
            portion_split = (portions * self._num_periods).astype(int)
            indices = np.arange(self._num_periods)
            self._train_ind, self._test_ind = np.split(indices, portion_split)

        print('3', len(self._train_ind), len(self._train_ind))
        self._train_ind = self._train_ind[:-(self._window_size + self.__smoothing_days)]
        # NOTE(zhengyao): change the logic here in order to fit both
        # reversed and normal version
        self._train_ind = list(self._train_ind)
        self._num_train_samples = len(self._train_ind)
        self._num_test_samples = len(self.test_indices)
        print('4', self._num_train_samples, self._num_test_samples)



### FILE: pgportfolio/marketdata/globaldatamatrix.py
----------------------------------------
from __future__ import division
from __future__ import absolute_import
from __future__ import print_function


import numpy as np
import pandas as pd
from pgportfolio.tools.data import panel_fillna
from pgportfolio.constants import *
import sqlite3
from datetime import datetime
import logging



def get_global_panel_stock(start, end, period=300, features=('close',)):
    """
    :param start/end: linux timestamp in seconds
    :param period: time interval of each data access point
    :param features: tuple or list of the feature names
    :return a panel, [feature, coin, time]
    """
    stock = np.load('pgportfolio/data/stock.npy', allow_pickle=True)
    coins = ['GOOG', 'NVDA', 'AMZN', 'AMD', 'QCOM', 'INTC', 'MSFT', 'AAPL', 'BIDU']

    logging.info("feature type list is %s" % str(features))

    stock_cols = ['date', 'high', 'low', 'open', 'close', 'volume', 'quoteVolume']

    time_index = pd.to_datetime(stock[0, :, 0])
    print(time_index)
    panel = pd.Panel(items=features, major_axis=coins, minor_axis=time_index, dtype=np.float32)


    for row_number, coin in enumerate(coins):
        chart = stock[row_number, :, :]
        df = pd.DataFrame(chart, columns=['date', 'high', 'low', 'open', 'close', 'volume', 'quoteVolume'])
        df['date'] = pd.to_datetime(df['date'])
        df = df.set_index('date')
        for feature in features:
            panel.loc[feature, coin, :] = df.loc[:,feature].tolist()
            panel = panel_fillna(panel, "both")

    return panel

def get_global_panel_btc(start, end, period=300, features=('close',), stocks=1):
    if stocks == 1:
        panel = pd.read_pickle('pgportfolio/data/btc.pkl')
    elif stocks == 2:
        panel = pd.read_pickle('pgportfolio/data/crix_2.pkl')
    elif stocks == 3:
        panel = pd.read_pickle('pgportfolio/data/crix_3.pkl')
    elif stocks == 4:
        panel = pd.read_pickle('pgportfolio/data/crix_4.pkl')
    else:
        print("no file")
    print(panel.shape)
    return panel


### FILE: pgportfolio/marketdata/__init__.py
----------------------------------------
#from __future__ import absolute_import
#from src import constants

### FILE: pgportfolio/marketdata/poloniex.py
----------------------------------------
import json
import time
import sys
from datetime import datetime

if sys.version_info[0] == 3:
    from urllib.request import Request, urlopen
    from urllib.parse import urlencode
else:
    from urllib2 import Request, urlopen
    from urllib import urlencode

minute = 60
hour = minute*60
day = hour*24
week = day*7
month = day*30
year = day*365

# Possible Commands
PUBLIC_COMMANDS = ['returnTicker', 'return24hVolume', 'returnOrderBook', 'returnTradeHistory', 'returnChartData', 'returnCurrencies', 'returnLoanOrders']

class Poloniex:
    def __init__(self, APIKey='', Secret=''):
        self.APIKey = APIKey.encode()
        self.Secret = Secret.encode()
        # Conversions
        self.timestamp_str = lambda timestamp=time.time(), format="%Y-%m-%d %H:%M:%S": datetime.fromtimestamp(timestamp).strftime(format)
        self.str_timestamp = lambda datestr=self.timestamp_str(), format="%Y-%m-%d %H:%M:%S": int(time.mktime(time.strptime(datestr, format)))
        self.float_roundPercent = lambda floatN, decimalP=2: str(round(float(floatN) * 100, decimalP))+"%"

        # PUBLIC COMMANDS
        self.marketTicker = lambda x=0: self.api('returnTicker')
        self.marketVolume = lambda x=0: self.api('return24hVolume')
        self.marketStatus = lambda x=0: self.api('returnCurrencies')
        self.marketLoans = lambda coin: self.api('returnLoanOrders',{'currency':coin})
        self.marketOrders = lambda pair='all', depth=10:\
            self.api('returnOrderBook', {'currencyPair':pair, 'depth':depth})
        self.marketChart = lambda pair, period=day, start=time.time()-(week*1), end=time.time(): self.api('returnChartData', {'currencyPair':pair, 'period':period, 'start':start, 'end':end})
        self.marketTradeHist = lambda pair: self.api('returnTradeHistory',{'currencyPair':pair}) # NEEDS TO BE FIXED ON Poloniex

    #####################
    # Main Api Function #
    #####################
    def api(self, command, args={}):
        """
        returns 'False' if invalid command or if no APIKey or Secret is specified (if command is "private")
        returns {"error":"<error message>"} if API error
        """
        if command in PUBLIC_COMMANDS:
            url = 'https://poloniex.com/public?'
            args['command'] = command
            ret = urlopen(Request(url + urlencode(args)))
            return json.loads(ret.read().decode(encoding='UTF-8'))
        else:
            return False


### FILE: pgportfolio/marketdata/replaybuffer.py
----------------------------------------
from __future__ import division,absolute_import,print_function
import numpy as np
import logging


class ReplayBuffer:
    def __init__(self, start_index, end_index, batch_size, is_permed, coin_number, sample_bias=1.0):
        """
        :param start_index: start index of the training set on the global data matrices
        :param end_index: end index of the training set on the global data matrices
        """
        self.__coin_number = coin_number
        self.__experiences = [Experience(i) for i in range(start_index, end_index)]
        self.__is_permed = is_permed
        # NOTE: in order to achieve the previous w feature
        self.__batch_size = batch_size
        self.__sample_bias = sample_bias
        logging.debug("buffer_bias is %f" % sample_bias)

    def append_experience(self, state_index):
        self.__experiences.append(Experience(state_index))
        logging.debug("a new experience, indexed by %d, was appended" % state_index)

    def __sample(self, start, end, bias):
        """
        @:param end: is excluded
        @:param bias: value in (0, 1)
        """
        # TODO: deal with the case when bias is 0
        ran = np.random.geometric(bias)
        while ran > end - start:
            ran = np.random.geometric(bias)
        result = end - ran
        return result

    def next_experience_batch(self, n_episode):
        # First get a start point randomly
        batch = []
        if self.__is_permed:
            for i in range(self.__batch_size):
                batch.append(self.__experiences[self.__sample(self.__experiences[0].state_index,
                                                              self.__experiences[-1].state_index,
                                                              self.__sample_bias)])

        else:
            for i in range(n_episode):
                batch_start = self.__sample(0, len(self.__experiences) - self.__batch_size -5,
                                            self.__sample_bias)
                #batch = self.__experiences[batch_start:batch_start+self.__batch_size]
                #print(self.__experiences[batch_start:batch_start+self.__batch_size])
                batch.append(self.__experiences[batch_start:batch_start+self.__batch_size])

        return batch

    def nearest_experience_batch(self, num_nearest):
        self.__experiences[-num_nearest:]



class Experience:
    def __init__(self, state_index):
        self.state_index = int(state_index)


### FILE: pgportfolio/resultprocess/__init__.py
----------------------------------------


### FILE: pgportfolio/resultprocess/plot.py
----------------------------------------
from __future__ import absolute_import, print_function, division
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib import rc
import pandas as pd
import logging
import json
import numpy as np
import datetime
from pgportfolio.tools.indicator import max_drawdown, sharpe, positive_count, negative_count, moving_accumulate
from pgportfolio.tools.configprocess import parse_time, check_input_same
from pgportfolio.tools.shortcut import execute_backtest

# the dictionary of name of indicators mapping to the function of related indicators
# input is portfolio changes
INDICATORS = {"portfolio value": np.prod,
              "sharpe ratio": sharpe,
              "max drawdown": max_drawdown,
              "positive periods": positive_count,
              "negative periods": negative_count,
              "postive day": lambda pcs: positive_count(moving_accumulate(pcs, 48)),
              "negative day": lambda pcs: negative_count(moving_accumulate(pcs, 48)),
              "postive week": lambda pcs: positive_count(moving_accumulate(pcs, 336)),
              "negative week": lambda pcs: negative_count(moving_accumulate(pcs, 336)),
              "average": np.mean}

NAMES = {"best": "Best Stock (Benchmark)",
         "crp": "UCRP (Benchmark)",
         "ubah": "UBAH (Benchmark)",
         "anticor": "ANTICOR",
         "olmar": "OLMAR",
         "pamr": "PAMR",
         "cwmr": "CWMR",
         "rmr": "RMR",
         "ons": "ONS",
         "up": "UP",
         "eg": "EG",
         "bk": "BK",
         "corn": "CORN",
         "m0": "M0",
         "wmamr": "WMAMR"
         }

def plot_backtest(config, algos, labels=None):
    """
    @:param config: config dictionary
    @:param algos: list of strings representing the name of algorithms or index of pgportfolio result
    """
    results = []
    for i, algo in enumerate(algos):
        if algo.isdigit():
            results.append(np.cumprod(_load_from_summary(algo, config)))
            logging.info("load index "+algo+" from csv file")
        else:
            logging.info("start executing "+algo)
            results.append(np.cumprod(execute_backtest(algo, config)))
            logging.info("finish executing "+algo)

    start, end = _extract_test(config)
    timestamps = np.linspace(start, end, len(results[0]))
    dates = [datetime.datetime.fromtimestamp(int(ts)-int(ts)%config["input"]["global_period"])
             for ts in timestamps]

    weeks = mdates.WeekdayLocator()
    days = mdates.DayLocator()

    rc("font", **{"family": "sans-serif", "sans-serif": ["Helvetica"],
                  "size": 8})

    """
    styles = [("-", None), ("--", None), ("", "+"), (":", None),
              ("", "o"), ("", "v"), ("", "*")]
    """
    fig, ax = plt.subplots()
    fig.set_size_inches(9, 5)
    for i, pvs in enumerate(results):
        if len(labels) > i:
            label = labels[i]
        else:
            label = NAMES[algos[i]]
        ax.semilogy(dates, pvs, linewidth=1, label=label)
        #ax.plot(dates, pvs, linewidth=1, label=label)

    plt.ylabel("portfolio value $p_t/p_0$", fontsize=12)
    plt.xlabel("time", fontsize=12)
    xfmt = mdates.DateFormatter("%m-%d %H:%M")
    ax.xaxis.set_major_locator(weeks)
    ax.xaxis.set_minor_locator(days)
    datemin = dates[0]
    datemax = dates[-1]
    ax.set_xlim(datemin, datemax)

    ax.xaxis.set_major_formatter(xfmt)
    plt.grid(True)
    plt.tight_layout()
    ax.legend(loc="upper left", prop={"size":10})
    fig.autofmt_xdate()
    plt.savefig("result.eps", bbox_inches='tight',
                pad_inches=0)
    plt.show()


def table_backtest(config, algos, labels=None, format="raw",
                   indicators=list(INDICATORS.keys())):
    """
    @:param config: config dictionary
    @:param algos: list of strings representing the name of algorithms
    or index of pgportfolio result
    @:param format: "raw", "html", "latex" or "csv". If it is "csv",
    the result will be save in a csv file. otherwise only print it out
    @:return: a string of html or latex code
    """
    results = []
    labels = list(labels)
    for i, algo in enumerate(algos):
        if algo.isdigit():
            portfolio_changes = _load_from_summary(algo, config)
            logging.info("load index " + algo + " from csv file")
        else:
            logging.info("start executing " + algo)
            portfolio_changes = execute_backtest(algo, config)
            logging.info("finish executing " + algo)

        indicator_result = {}
        for indicator in indicators:
            indicator_result[indicator] = INDICATORS[indicator](portfolio_changes)
        results.append(indicator_result)
        if len(labels)<=i:
            labels.append(NAMES[algo])

    dataframe = pd.DataFrame(results, index=labels)

    start, end = _extract_test(config)
    start = datetime.datetime.fromtimestamp(start - start%config["input"]["global_period"])
    end = datetime.datetime.fromtimestamp(end - end%config["input"]["global_period"])

    print("backtest start from "+ str(start) + " to " + str(end))
    if format == "html":
        print(dataframe.to_html())
    elif format == "latex":
        print(dataframe.to_latex())
    elif format == "raw":
        print(dataframe.to_string())
    elif format == "csv":
        dataframe.to_csv("./compare"+end.strftime("%Y-%m-%d")+".csv")
    else:
        raise ValueError("The format " + format + " is not supported")


def _extract_test(config):
    global_start = parse_time(config["input"]["start_date"])
    global_end = parse_time(config["input"]["end_date"])
    span = global_end - global_start
    start = global_end - config["input"]["test_portion"] * span
    end = global_end
    return start, end


def _load_from_summary(index, config):
    """ load the backtest result form train_package/train_summary
    @:param index: index of the training and backtest
    @:return: numpy array of the portfolio changes
    """
    dataframe = pd.DataFrame.from_csv("./train_package/train_summary.csv")
    history_string = dataframe.loc[int(index)]["backtest_test_history"]
    if not check_input_same(config, json.loads(dataframe.loc[int(index)]["config"])):
        raise ValueError("the date of this index is not the same as the default config")
    return np.fromstring(history_string, sep=",")[:-1]



### FILE: pgportfolio/resultprocess/table.py
----------------------------------------
from __future__ import division, print_function, absolute_import
import numpy as np




### FILE: pgportfolio/tdagent/algorithms/anticor1.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import logging

class ANTICOR1(TDAgent):
    '''
    anti-correlation olps
    '''
    def __init__(self, window=30, exp_w=None):
        super(ANTICOR1, self).__init__()
        self.window = window
        self.exp_ret = np.ones((window-1,1))
        self.exp_w = exp_w

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        n, m = self.history.shape
        if self.exp_w is None:
            self.exp_w = np.ones((self.window-1,m)) / m

        for k in np.arange(1,self.window):
            self.exp_w[k-1,:] = self.update(self.history, self.exp_w[k-1,:], k+1)
        numerator = 0
        denominator = 0

        for k in np.arange(1,self.window):
            numerator += self.exp_ret[k-1] * self.exp_w[k-1,:]
            denominator += self.exp_ret[k-1]

        weight = numerator.T / denominator

        for k in np.arange(1, self.window):
            self.exp_ret[k-1] = np.dot(self.exp_ret[k-1]*self.history[-1,:], self.exp_w[k-1,:].T)

        self.exp_ret[:,0] /= np.sum(self.exp_ret[:,0])

        return weight

    def update(self, data,last_b, w):
        T, N = data.shape
        b = last_b

        if T >= 2*w :
            data1 = data[T-2*w:T-w,:]
            data2 = data[T-w:T,:]
            #print data1
            LX1 = np.log(data1)
            LX2 = np.log(data2)

            mu1 = np.mean(LX1, axis=0)
            mu2 = np.mean(LX2, axis=0)

            n_LX1 = LX1 - mu1
            n_LX2 = LX2 - mu2


            sig1 = np.diag(np.dot(n_LX1.T, n_LX1).T) / (w-1)
            sig2 = np.diag(np.dot(n_LX2.T, n_LX2).T) / (w-1)

            sig1 = sig1[:,None]
            sig2 = sig2[:,None]

            sigma = np.dot(sig1,sig2.T) #(N,N)

            mCov = n_LX1.T.dot(n_LX2) / (w-1)
            mCorr = np.zeros((N,N))

            mCorr = np.zeros((N,N))
            new_sigma = np.multiply(sigma, sigma!=0)
            new_sigma_zero_index = new_sigma==0
            new_sigma[new_sigma_zero_index] = 1e-8
            mCorr = np.multiply(mCov, sigma!=0) / np.sqrt(new_sigma)

            claim = np.zeros((N,N))
            w_mu2 = np.tile(mu2[None,...].T, (1,N))
            w_mu1 = np.tile(mu2[None,...], (N,1))

            s12 = np.multiply(w_mu2 >= w_mu1, mCorr>0)
            claim = np.multiply(claim, s12) + np.multiply(mCorr, s12)

            diag_mCorr = np.diag(mCorr)
            cor1 = np.maximum(0, np.tile(-diag_mCorr[...,None], (1,N)))
            cor2 = np.maximum(0, np.tile(-diag_mCorr[...,None].T, (N,1)))
            claim +=  np.multiply(cor1, s12) + np.multiply(cor2, s12)
            claim = np.multiply(claim, s12)

            transfer = np.zeros((N,N))
            s_claim = np.sum(claim, axis=1)
            sum_claim = np.tile(s_claim[...,None],(1,N))


            s1 = np.absolute(sum_claim) > 0

            w_b = np.tile(b[...,None], (1,N))
            mul_bc = np.multiply(w_b, s1) * np.multiply(claim, s1)
            deno = np.multiply(sum_claim, s1)
            deno_zero_index = deno==0
            deno[deno_zero_index] = 1e-8
            transfer = np.divide(mul_bc, deno)
            transfer = np.where(np.isnan(transfer), 0, transfer)

            transfer_ij = transfer.T - transfer
            sum_ij = np.sum(transfer_ij, axis=0)

            b = np.subtract(b, sum_ij.T)

        return b


### FILE: pgportfolio/tdagent/algorithms/anticor2.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import logging

class ANTICOR2(TDAgent):
    '''
    anti-correlation
    equals to anticor-anticor in olps
    '''
    def __init__(self, window=30, exp_w=None, data_day=None):
        super(ANTICOR2, self).__init__()
        self.window = window
        self.exp_ret = np.ones((window-1,1))
        self.exp_w = exp_w
        self.exp_ret2 = np.ones((window-1,1))
        self.exp_w2 = np.ones((window-1, window-1)) / (window-1)
        self.data_day = data_day

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        n, m = self.history.shape

        if self.exp_w is None:
            self.exp_w = np.ones((self.window-1,m)) / m

        if self.data_day is None:
            self.data_day = np.zeros((1,self.window-1))
            mid = np.dot(self.history[-1,:], self.exp_w.T)
            self.data_day = mid[None,...]


        for k in np.arange(1,self.window):
            self.exp_w[k-1,:] = self.update(self.history, self.exp_w[k-1,:], k+1)
            self.exp_w2[k-1,:] = self.update(self.data_day, self.exp_w2[k-1,:],k+1)



        numerator = 0
        denominator = 0

        for k in np.arange(1,self.window):
            numerator += self.exp_ret2[k-1] * self.exp_w2[k-1,:]
            denominator += self.exp_ret2[k-1]

        weight1 = numerator.T / denominator
        weight = self.exp_w.T.dot(weight1)

        if n>0:
            mid = np.dot(self.history[-1,:], self.exp_w.T)
            self.data_day = np.vstack((self.data_day, mid[None,...]))

        for k in np.arange(1, self.window):
            self.exp_w[k-1,:] *= self.history[-1,:] / self.data_day[-1,k-1]
            self.exp_ret2[k-1] *= self.data_day[-1,:].dot(self.exp_w2[k-1,:].T)
            self.exp_w2[k-1,:] *= self.data_day[-1,:] / np.dot(self.data_day[-1,:], self.exp_w2[k-1,:].T)


        return weight

    def update(self, data,last_b, w):
        T, N = data.shape
        b = last_b

        if T >= 2*w :
            data1 = data[T-2*w:T-w,:]
            data2 = data[T-w:T,:]
            LX1 = np.log(data1)
            LX2 = np.log(data2)

            mu1 = np.mean(LX1, axis=0)
            mu2 = np.mean(LX2, axis=0)

            n_LX1 = LX1 - mu1
            n_LX2 = LX2 - mu2


            sig1 = np.diag(np.dot(n_LX1.T, n_LX1).T) / (w-1)
            sig2 = np.diag(np.dot(n_LX2.T, n_LX2).T) / (w-1)

            sig1 = sig1[:,None]
            sig2 = sig2[:,None]

            sigma = np.dot(sig1,sig2.T) #(N,N)

            mCov = n_LX1.T.dot(n_LX2) / (w-1)
            mCorr = np.zeros((N,N))

            mCorr = np.zeros((N,N))
            mCorr = np.multiply(mCov, sigma!=0) / np.sqrt(np.multiply(sigma, sigma!=0))

            claim = np.zeros((N,N))
            w_mu2 = np.tile(mu2[None,...].T, (1,N))
            w_mu1 = np.tile(mu2[None,...], (N,1))

            s12 = np.multiply(w_mu2 >= w_mu1, mCorr>0)
            claim = np.multiply(claim, s12) + np.multiply(mCorr, s12)

            diag_mCorr = np.diag(mCorr)
            cor1 = np.maximum(0, np.tile(-diag_mCorr[...,None], (1,N)))
            cor2 = np.maximum(0, np.tile(-diag_mCorr[...,None].T, (N,1)))
            claim +=  np.multiply(cor1, s12) + np.multiply(cor2, s12)
            claim = np.multiply(claim, s12)

            transfer = np.zeros((N,N))
            s_claim = np.sum(claim, axis=1)
            sum_claim = np.tile(s_claim[...,None],(1,N))


            s1 = np.absolute(sum_claim) > 0

            w_b = np.tile(b[...,None], (1,N))
            mul_bc = np.multiply(w_b, s1) * np.multiply(claim, s1)
            deno = np.multiply(sum_claim, s1)
            transfer = np.divide(mul_bc, deno)
            transfer = np.where(np.isnan(transfer), 0, transfer)

            transfer_ij = transfer.T - transfer
            sum_ij = np.sum(transfer_ij, axis=0)

            b = np.subtract(b, sum_ij.T)

        return b


### FILE: pgportfolio/tdagent/algorithms/anticor_deprecated.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import warnings
import pandas as pd
from pandas.stats.moments import rolling_corr

class ANTICOR(TDAgent):
    """ Anticor (anti-correlation) is a heuristic portfolio selection algorithm.
    It adopts the consistency of positive lagged cross-correlation and negative
    autocorrelation to adjust the portfolio. Eventhough it has no known bounds and
    hence is not considered to be universal, it has very strong empirical results.

    It has implemented C version in scipy.weave to improve performance (around 10x speed up).
    Another option is to use Numba.

    Reference:
        A. Borodin, R. El-Yaniv, and V. Gogan.  Can we learn to beat the best stock, 2005.
        http://www.cs.technion.ac.il/~rani/el-yaniv-papers/BorodinEG03.pdf
    """

    def __init__(self, window=30, c_version=True):
        """
        :param window: Window parameter.
        :param c_version: Use c_version, up to 10x speed-up.
        """
        super(ANTICOR, self).__init__()
        self.window = window
        self.c_version = c_version


    def decide_by_history(self, x, last_b=None):
        self.record_history(x)
        window = self.window
        port = pd.DataFrame(self.history)
        n, m = port.shape
        weights = 1. / m * np.ones(port.shape)

        CORR, EX = rolling_corr(port, port.shift(window))

        if self.c_version:
            try:
                from scipy import weave
            except ImportError:
                warnings.warn('scipy.weave is not available in python3, falling back to python version')
                self.c_version = False

        if self.c_version is False:
            for t in range(n - 1):
                M = CORR[t, :, :]
                mu = EX[t, :]

                # claim[i,j] is claim from stock i to j
                claim = np.zeros((m, m))

                for i in range(m):
                    for j in range(m):
                        if i == j: continue

                        if mu[i] > mu[j] and M[i, j] > 0:
                            claim[i, j] += M[i, j]
                            # autocorrelation
                            if M[i, i] < 0:
                                claim[i, j] += abs(M[i, i])
                            if M[j, j] < 0:
                                claim[i, j] += abs(M[j, j])

                # calculate transfer
                transfer = claim * 0.
                for i in range(m):
                    total_claim = sum(claim[i, :])
                    if total_claim != 0:
                        transfer[i, :] = weights[t, i] * claim[i, :] / total_claim

                # update weights
                weights[t + 1, :] = weights[t, :] + np.sum(transfer, axis=0) - np.sum(transfer, axis=1)

        else:
            def get_weights_c(c, mu, w):
                code = """
                int t,i,j;
                float claim [Nc[1]] [Nc[1]];
                float transfer [Nc[1]] [Nc[1]];

                for (t=0; t<Nc[0]-1; t++) {

                    for (i=0; i<Nc[1]; i++) {
                        for (j=0; j<Nc[1]; j++) {
                            claim[i][j] = 0.;
                            transfer[i][j] = 0.;
                        }
                    }

                    for (i=0; i<Nc[1]; i++) {
                        for (j=0; j<Nc[1]; j++) {
                            if(i != j){
                                if(MU2(t,i) > MU2(t,j)  && C3(t,i,j) > 0){
                                    claim[i][j] += C3(t,i,j);
                                    if(C3(t,i,i) < 0)
                                        claim[i][j] -= C3(t,i,i);
                                    if(C3(t,j,j) < 0)
                                        claim[i][j] -= C3(t,j,j);
                                }
                            }
                        }
                    }

                    for (i=0; i<Nc[1]; i++) {
                        float total_claim=0.;
                        for (j=0; j<Nc[1]; j++) {
                            total_claim += claim[i][j];
                        }
                        if(total_claim != 0){
                            for (j=0; j<Nc[1]; j++) {
                                transfer[i][j] = W2(t,i) * claim[i][j] / total_claim;
                            }
                        }

                    }

                    for (i=0; i<Nc[1]; i++) {
                        W2(t+1,i) = W2(t,i);
                        for (j=0; j<Nc[1]; j++) {
                            W2(t+1,i) += transfer[j][i] - transfer[i][j];
                        }
                    }
                }
                """
                return weave.inline(code, ['c', 'mu', 'w'])

            get_weights_c(CORR, EX, weights)

        return weights[-1,:]

def rolling_corr(x, y):
    '''Rolling correlation between columns from x and y'''
    def rolling(dataframe):
        ret = dataframe.copy()
        for col in ret:
            ret[col] = ret[col].rolling(window=5).mean()
        return ret

    n, k = x.shape

    EX = rolling(x)
    EY = rolling(y)
    EX2 = rolling(x**2)
    EY2 = rolling(y**2)

    RXY = np.zeros((n,k,k))

    for i, col_x in enumerate(x):
        for j, col_y in enumerate(y):
            DX = EX2[col_x] - EX[col_x] ** 2
            DY = EY2[col_y] - EY[col_y] ** 2
            product_xy = x[col_x] * y[col_y]
            RXY[:, i, j] = product_xy.rolling(window=5).mean()- EX[col_x] * EY[col_y]
            RXY[:, i, j] = RXY[:, i, j] / np.sqrt(DX * DY)

    return RXY, EX.values


### FILE: pgportfolio/tdagent/algorithms/bcrp.py
----------------------------------------
from ..tdagent import TDAgent
from pgportfolio.tdagent.algorithms.crp import CRP
import numpy as np
from scipy.optimize import minimize

class BCRP(CRP):
    """ Best Constant Rebalanced Portfolio = Constant Rebalanced Portfolio constructed with hindsight. It is often used as benchmark.

    Reference:
        T. Cover. Universal Portfolios, 1991.
        http://www-isl.stanford.edu/~cover/papers/paper93.pdf
    """

    def __init__(self, last_b=None):
        super(BCRP, self).__init__()
        self.last_b = last_b

    def get_weight(self, data):
        """ Find weights which maximize return on X in hindsight! """
        weights = opt_weights(data)
        return weights

    def decide_by_history(self, x, last_b):
        if self.last_b is None:
            from pgportfolio.tools.trade import get_test_data
            from pgportfolio.tools.configprocess import preprocess_config
            import json
            with open("pgportfolio/net_config.json") as file:
                config = json.load(file)
            config = preprocess_config(config)
            data = get_test_data(config)
            self.last_b = self.get_weight(data.T)

        return self.last_b


def opt_weights(X, max_leverage=1):
    x_0 = max_leverage * np.ones(X.shape[1]) / float(X.shape[1])
    objective = lambda b: -np.prod(X.dot(b))
    cons = ({'type': 'eq', 'fun': lambda b: max_leverage-np.sum(b)},)
    bnds = [(0., max_leverage)]*len(x_0)
    res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp', options={'ftol': 1e-07})
    return res.x


if __name__ == '__main__':
    from pgportfolio.tools.backtest import get_test_data
    from pgportfolio.tools.configprocess import preprocess_config
    import json
    with open("pgportfolio/net_config.json") as file:
        config = json.load(file)
    config = preprocess_config(config)
    data = get_test_data(config)
    bcrp = BCRP()
    result = bcrp.get_weight(data.T)



### FILE: pgportfolio/tdagent/algorithms/best.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class BEST(TDAgent):
    '''Best Stock Strategy
    '''
    def __init__(self, last_b=None):
        super(BEST, self).__init__()
        self.last_b = last_b


    def decide_by_history(self, data, last_b=None):
        if self.last_b is None:
            from pgportfolio.tools.trade import get_test_data
            from pgportfolio.tools.configprocess import preprocess_config
            import json
            with open("pgportfolio/net_config.json") as file:
                config = json.load(file)
            config = preprocess_config(config)
            data = get_test_data(config)
            data = data.T
            n, m = data.shape
            tmp_cumprod_ret = np.cumprod(data, axis=0)
            best_ind = np.argmax(tmp_cumprod_ret[-1,:])
            self.last_b = np.zeros(m)
            self.last_b[best_ind] = 1
        return self.last_b.ravel()


### FILE: pgportfolio/tdagent/algorithms/bk_deprecated.py
----------------------------------------
# -*- coding: utf-8 -*-
from ..tdagent import TDAgent
import numpy as np
import pandas as pd
from scipy.optimize import minimize
import logging


class BK(TDAgent):
    """ Kernel based strategy. It tries to find similar sequences of price in history and then maximize objective function (that is profit) on the days following them.

    Reference:
        L. Gyorfi, G. Lugosi, and F. Udina. Nonparametric kernel based sequential
        investment strategies. Mathematical Finance 16 (2006) 337–357.
    """
    def __init__(self, k=5, l=10):
        """
        :param k: Sequence length.
        :param l: Number of nearest neighbors.
        """

        super(BK, self).__init__()
        self.k = k
        self.l = l

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        history = pd.DataFrame(self.history)
        # find indices of nearest neighbors throughout history
        ixs = self.find_nn(history, self.k, self.l)

        # get returns from the days following NNs
        J = history.iloc[[history.index.get_loc(i) + 1 for i in ixs]]

        # get best weights
        return opt_weights(J)


    def find_nn(self, H, k, l):
        """ Note that nearest neighbors are calculated in a different (more efficient) way than shown
        in the article.

        param H: history
        """
        # calculate distance from current sequence to every other point
        D = H * 0
        for i in range(1, k+1):
            D += (H.shift(i-1) - H.iloc[-i])**2
        D = D.sum(1).iloc[:-1]

        # sort and find nearest neighbors
        D.sort_values(inplace=True)
        return D.index[:l]


def opt_weights(X, max_leverage=1):
    x_0 = max_leverage * np.ones(X.shape[1]) / float(X.shape[1])
    objective = lambda b: -np.sum(np.log(np.maximum(np.dot(X-1, b)+1,1e-4)))
    cons = ({'type': 'eq', 'fun': lambda b: max_leverage-sum(b)},)
    bnds = [(0., max_leverage)]*len(x_0)
    while True:
        res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp')
        eps = 1e-7
        if (res.x < 0-eps).any() or (res.x > max_leverage+eps).any():
            X = X + np.random.randn(1)[0] * 1e-5
            logging.debug('Optimal weights not found, trying again')
            continue
        elif res.success:
            break
        else:
            if np.isnan(res.x).any():
                logging.warning('Solution not found')
                res.x = np.ones(X.shape[1]) / X.shape[1]
            else:
                logging.warning("converged but not successfully")
            break

    return res.x


### FILE: pgportfolio/tdagent/algorithms/bk.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import logging
from scipy.optimize import minimize

class BK(TDAgent):
    '''
    anti-correlation olps
    '''
    def __init__(self, K=5, L=10, c=1, exp_w=None):
        super(BK, self).__init__()
        self.K = K
        self.L = L
        self.c = c
        self.exp_ret = np.ones((K,L+1))
        self.exp_w = exp_w

    def decide_by_history(self, x, last_b):
        self.record_history(x)

        data = self.history

        n, m = data.shape

        if self.exp_w is None:
            self.exp_w = np.ones((self.K*(self.L+1),m)) / m

        self.exp_w[self.K*self.L,:] = self.update(data, 0, 0, self.c)

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                self.exp_w[(k-1)*self.L+l,:] = self.update(data, k, l, self.c)

        p = 1./(self.K*self.L)
        numerator = p * self.exp_ret[0,self.L] * self.exp_w[self.K*self.L,:]
        denominator = p * self.exp_ret[0, self.L]

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                numerator += p*self.exp_ret[k, l] * self.exp_w[(k-1)*self.L+l,:]
                denominator += p*self.exp_ret[k,l]

        weight = numerator.T / denominator

        self.exp_ret[0, self.L] *= np.dot(self.history[-1,:], self.exp_w[self.K*self.L,:].T)

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                self.exp_ret[k,l] *= np.dot(self.history[-1,:], self.exp_w[(k-1)*self.L+l,:])


        return weight

    def update(self, data, k, l, c):
        '''
        :param w: window sze
        :param c: correlation coefficient threshold
        '''
        T, N = data.shape
        m = -1
        histdata = np.zeros((T,N))

        if T <= k+1:
            return np.ones(N) / N

        if k==0 and l==0:
            histdata = data[:T,:]
            m = T
        else:
            for i in np.arange(k+1, T):
                #print 'i is %d k is %d T is %d\n' % (i,k,T)
                data2 = data[i-k-1:i,:] - data[T-k-1:T,:]
                #print data2

                if np.sqrt(np.trace(np.dot(data2,data2.T))) <= c/l:
                    m += 1
                    histdata[m,:] = data[i,:] #minus one to avoid out of bounds issue

        if m==-1:
            return np.ones(N) / N

        b = opt_weights(histdata[:m+1,:])
        #print b
        #print 'w is %d\t T is %d\n' % (w,T)
        return b

def opt_weights(X, max_leverage=1):
    x_0 = max_leverage * np.ones(X.shape[1]) / float(X.shape[1])
    objective = lambda b: -np.sum(np.log(np.maximum(np.dot(X-1, b)+1,1e-4)))
    cons = ({'type': 'eq', 'fun': lambda b: max_leverage-sum(b)},)
    bnds = [(0., max_leverage)]*len(x_0)
    while True:
        res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp')
        eps = 1e-7
        if (res.x < 0-eps).any() or (res.x > max_leverage+eps).any():
            X = X + np.random.randn(1)[0] * 1e-5
            logging.debug('Optimal weights not found, trying again')
            continue
        elif res.success:
            break
        else:
            if np.isnan(res.x).any():
                logging.warning('Solution not found')
                res.x = np.ones(X.shape[1]) / X.shape[1]
            else:
                logging.warning("converged but not successfully")
            break

    return res.x


### FILE: pgportfolio/tdagent/algorithms/bnn.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import logging
from scipy.optimize import minimize

class BNN(TDAgent):
    '''
    Non-parametric
    '''
    def __init__(self, K=5, L=10, exp_w=None):
        super(BNN, self).__init__()
        self.K = K
        self.L = L
        self.exp_ret = np.ones((K,L+1))
        self.exp_w = exp_w

    def get_b(self, x, last_b):
        self.record_history(x)

        data = self.history
        n, m = data.shape

        if self.exp_w is None:
            self.exp_w = np.ones((self.K*(self.L+1),m)) / m

        self.exp_w[self.K*self.L,:] = self.update(data, 0, 0)

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                pl = 0.02+0.5*(l-1)/(self.L-1)
                self.exp_w[(k-1)*self.L+l,:] = self.update(data, k, pl)

        p = 1./(self.K*self.L)
        numerator = p * self.exp_ret[0,self.L] * self.exp_w[self.K*self.L,:]
        denominator = p * self.exp_ret[0, self.L]

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                numerator += p*self.exp_ret[k, l] * self.exp_w[(k-1)*self.L+l,:]
                denominator += p*self.exp_ret[k,l]

        weight = numerator.T / denominator

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                self.exp_ret[k,l] *= np.dot(self.history[-1,:], self.exp_w[(k-1)*self.L+l-1,:])

        return weight

    def update(self, data, k, l):
        T, N = data.shape
        m = 0
        histdata = np.zeros((T,N))

        if T <= k+1:
            return np.ones((1,N)) / N

        if k==0 and l==0:
            histdata = data[:T,:]
            m = T
        else:
            normid = np.zeros((T-k,1))
            histdata = data[:T,:]
            normid[:k] = 0
            for i in np.arange(k+1,T):
                data2 = data[i-k:i-1,:] - data[T-k+1:T,:]
                normid[:i] = np.sqrt(np.trace(data2.dot(data2.T)))
                sortpos = np.sort(normid)
                sortpos = sortpos.astype(int)
                m = int(np.floor(l*T))
                for j in np.arange(m):
                    histdata = np.vstack((histdata,histdata[int(sortpos[j]),:]))
        if m == 0:
            return np.ones((1,N)) / N

        b = opt_weights(histdata)
        return b

def opt_weights(X, max_leverage=1):
    x_0 = max_leverage * np.ones(X.shape[1]) / float(X.shape[1])
    objective = lambda b: -np.sum(np.log(np.maximum(np.dot(X-1, b)+1,1e-4)))
    cons = ({'type': 'eq', 'fun': lambda b: max_leverage-sum(b)},)
    bnds = [(0., max_leverage)]*len(x_0)
    while True:
        res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp')
        eps = 1e-7
        if (res.x < 0-eps).any() or (res.x > max_leverage+eps).any():
            X = X + np.random.randn(1)[0] * 1e-5
            logging.debug('Optimal weights not found, trying again')
            continue
        elif res.success:
            break
        else:
            if np.isnan(res.x).any():
                logging.warning('Solution not found')
                res.x = np.ones(X.shape[1]) / X.shape[1]
            else:
                logging.warning("converged but not successfully")
            break

    return res.x


### FILE: pgportfolio/tdagent/algorithms/corn_deprecated.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
from scipy.stats.stats import pearsonr
from scipy.optimize import minimize
import logging

class CORN(TDAgent):
    """
    Correlation-driven nonparametric learning approach. Similar to anticor but instead
    of distance of return vectors they use correlation.
    In appendix of the article, universal property is proven.

    Two versions are available. Fast which provides around 2x speedup, but uses more memory
    (linear in window) and slow version which is memory efficient. Most efficient would
    be to rewrite it in sweave or numba.

    Reference:
        B. Li, S. C. H. Hoi, and V. Gopalkrishnan.
        Corn: correlation-driven nonparametric learning approach for portfolio selection, 2011.
        http://www.cais.ntu.edu.sg/~chhoi/paper_pdf/TIST-CORN.pdf
    """
    def __init__(self, w=5, rho=0.1):
        """
        :param w: Window parameter.
        :param rho: Correlation coefficient threshold. Recommended is 0.
        """
        # input check
        if not(-1 <= rho <= 1):
            raise ValueError('rho must be between -1 and 1')
        if not(w >= 2):
            raise ValueError('window must be greater than 2')
        super(CORN, self).__init__()
        self.w = w
        self.rho = rho


    def decide_by_history(self, x, last_b):
        self.record_history(x)
        x = self.get_last_rpv(x)

        T, N = self.history.shape
        m = 0
        histdata = np.zeros((T,N))

        if T <= self.w+1:
            '''use uniform portfolio weight vector'''
            return np.ones(x.size) / x.size

        if self.w==0:
            histdata = self.history
            m = T
        else:
            for i in np.arange(self.w+1, T+1):
                d1 = self.history[i-self.w:i-1,:]
                d2 = self.history[T-self.w+1:T,:]

                datacorr = np.corrcoef(d1,d2)[0,1]

                if datacorr >= self.rho:
                    m += 1
                    histdata[m,:] = self.history[i-1,:] #minus one to avoid out of bounds issue

        if m==0:
            return np.ones(x.size) / x.size

        #sqp according to OLPS implementation
        x_0 = np.ones(x.size) / x.size
        objective = lambda b: -np.prod(np.dot(histdata, b))
        cons = ({'type': 'eq', 'fun': lambda b: 1-np.sum(b, axis=0)},)
        bnds = [(0.,1)]*x.size
        while True:
            res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp')
            eps = 1e-7
            if (res.x < 0-eps).any() or (res.x > 1+eps).any():
                x = x + np.random.randn(1)[0] * 1e-5
                logging.debug('Optimal portfolio weight vector not found, trying again...')
                continue
            elif res.success:
                break
            else:
                if np.isnan(res.x).any():
                    logging.warning('Solution does not exist, use uniform pwv')
                    res.x = np.ones(x.size) / x.size
                else:
                    logging.warning('Converged but not successfully.')
                break

        return res.x


### FILE: pgportfolio/tdagent/algorithms/cornk.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import logging
from scipy.optimize import minimize

class CORNK(TDAgent):
    '''
    Correlation driven non parametric Uniform
    '''
    def __init__(self, K=5, L=10, pc=0.1, exp_w=None):
        '''
        :param K: maximum window size
        :param L: splits into L parts, in each K
        '''
        super(CORNK, self).__init__()
        self.K = K
        self.L = L
        self.pc = pc
        self.exp_ret = np.ones((K,L))
        self.exp_w = exp_w


    def decide_by_history(self, X, last_b):
        self.record_history(X)

        n, m = self.history.shape

        if self.exp_w is None:
            self.exp_w = np.ones((self.K*self.L, m)) / m

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                rho = l / self.L
                self.exp_w[(k-1)*self.L+l,:] = self.update(self.history, k+1, rho)

        nc = np.ceil(self.pc*self.K*self.L)
        exp_ret_vec = self.exp_ret.ravel()
        exp_ret_sort = np.sort(exp_ret_vec, kind='heapsort')
        ret_rho = exp_ret_sort[int(self.K*self.L-nc+1)]

        numerator = 0
        denominator = 0

        p = 1./(self.K*self.L)

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                p = 1 if self.exp_ret[k,l] >= ret_rho else 0
                numerator += p * self.exp_ret[k,l] * self.exp_w[(k-1)*self.L+l,:]
                denominator += p * self.exp_ret[k,l]

        b = np.divide(numerator.T , denominator)

        for k in range(self.K):
            for l in range(self.L):
                self.exp_ret[k,l] *= np.dot(self.history[-1,:], self.exp_w[(k-1)*self.L+l,:].T)

        return b

    def update(self, data, w, c):
        '''
        :param w: window sze
        :param c: correlation coefficient threshold
        '''
        T, N = data.shape
        m = -1
        histdata = np.zeros((T,N))

        if T <= w+1:
            return np.ones(N) / N

        if w==0:
            histdata = data[:T,:]
            m = T
        else:
            for i in np.arange(w, T):
                d1 = data[i-w:i,:].ravel()
                d2 = data[T-w:T,:].ravel()

                datacorr = np.corrcoef(d1,d2)[1,0]


                if datacorr >= c:
                    m += 1
                    histdata[m,:] = data[i,:] #minus one to avoid out of bounds issue

        if m==-1:
            return np.ones(N) / N

        b = opt(histdata[:m+1,:])
        return b

def opt(X):
    x_0 = np.ones(X.shape[1]) / X.shape[1]
    objective = lambda b: -np.prod(X.dot(b))
    cons = ({'type': 'eq', 'fun': lambda b: 1-np.sum(b)},)
    bnds = [(0,1)]*len(x_0)
    res = minimize(objective, x0=x_0,  bounds=bnds, constraints=cons, method='slsqp', )
    return res.x


### FILE: pgportfolio/tdagent/algorithms/cornu.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import logging
from scipy.optimize import minimize

class CORNU(TDAgent):
    '''
    Correlation driven non parametric Uniform
    '''
    def __init__(self, K=5, L=1, c=0.1, exp_w=None):
        '''
        :param K: maximum window size
        :param L: splits into L parts, in each K
        '''
        super(CORNU, self).__init__()
        self.K = K
        self.L = L
        self.c = c
        self.exp_ret = np.ones((K,L))
        self.exp_w = exp_w


    def decide_by_history(self, X, last_b):
        self.record_history(X)

        n, m = self.history.shape

        if self.exp_w is None:
            self.exp_w = np.ones((self.K*self.L, m)) / m

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                self.exp_w[(k-1)*self.L+l,:] = self.update(self.history, k+1, self.c)


        numerator = 0
        denominator = 0

        p = 1./(self.K*self.L)

        for k in np.arange(self.K):
            for l in np.arange(self.L):
                numerator += p * self.exp_ret[k,l] * self.exp_w[(k-1)*self.L+l,:]
                denominator += p * self.exp_ret[k,l]

        b = np.divide(numerator.T , denominator)

        self.exp_ret[:,0] *= np.dot(self.history[-1,:], self.exp_w.T)

        return b

    def update(self, data, w, c):
        '''
        :param w: window sze
        :param c: correlation coefficient threshold
        '''
        T, N = data.shape
        m = -1
        histdata = np.zeros((T,N))

        if T <= w+1:
            return np.ones(N) / N

        if w==0:
            histdata = data[:T,:]
            m = T
        else:
            for i in np.arange(w, T):
                d1 = data[i-w:i,:].ravel()
                d2 = data[T-w:T,:].ravel()

                datacorr = np.corrcoef(d1,d2)[1,0]


                if datacorr >= c:
                    m += 1
                    histdata[m,:] = data[i,:] #minus one to avoid out of bounds issue

        if m==-1:
            return np.ones(N) / N

        b = opt(histdata[:m+1,:])
        return b

def opt(X):
    x_0 = np.ones(X.shape[1]) / X.shape[1]
    objective = lambda b: -np.prod(X.dot(b))
    cons = ({'type': 'eq', 'fun': lambda b: 1-np.sum(b)},)
    bnds = [(0,1)]*len(x_0)
    res = minimize(objective, x0=x_0,  bounds=bnds, constraints=cons, method='slsqp', )
    return res.x


### FILE: pgportfolio/tdagent/algorithms/crp.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np


class CRP(TDAgent):
    """ Constant rebalanced portfolio = use fixed weights all the time. Uniform weights are commonly used as a benchmark.

    Reference:
        T. Cover. Universal Portfolios, 1991.
        http://www-isl.stanford.edu/~cover/papers/paper93.pdf
    """

    def __init__(self, b=None):
        """
        :params b: Constant rebalanced portfolio weights. Default is uniform.
        """
        super(CRP, self).__init__()
        self.b = b

    def decide_by_history(self, x, last_b):
        x = self.get_last_rpv(x)

        # init b to default if necessary
        if self.b is None:
            self.b = np.ones(len(x)) / len(x)
        return self.b



### FILE: pgportfolio/tdagent/algorithms/cwmr_std.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import scipy.stats
from numpy.linalg import inv
from numpy import diag, sqrt, log, trace


class CWMR_STD(TDAgent):
    """ Confidence weighted mean reversion.

    Reference:
        B. Li, S. C. H. Hoi, P.L. Zhao, and V. Gopalkrishnan.
        Confidence weighted mean reversion strategy for online portfolio selection, 2013.
        http://jmlr.org/proceedings/papers/v15/li11b/li11b.pdf
    """
    def __init__(self, eps=-0.5, confidence=0.95, sigma=None):
        """
        :param eps: Mean reversion threshold (expected return on current day must be lower
                    than this threshold). Recommended value is -0.5.
        :param confidence: Confidence parameter for profitable mean reversion portfolio. Recommended value is 0.95.
        """
        super(CWMR_STD, self).__init__()
        # input check
        if not (0 <= confidence <= 1):
            raise ValueError('confidence must be from interval [0,1]')

        self.eps = eps
        self.theta = scipy.stats.norm.ppf(confidence)
        self.sigma = sigma

    def init_portfolio(self, X):
        m = X.shape[1]
        self.sigma = np.matrix(np.eye(m) / m**2)


    def decide_by_history(self, x, last_b):
        x = self.get_last_rpv(x)
        x = np.reshape(x, (1,x.size))
        last_b = np.reshape(last_b, (1,last_b.size))
        if self.sigma is None:
            self.init_portfolio(x)
        # initialize
        m = len(x)
        mu = np.matrix(last_b).T
        sigma = self.sigma
        theta = self.theta
        eps = self.eps
        x = np.matrix(x).T    # matrices are easier to manipulate

        # 4. Calculate the following variables
        M = (mu.T * x).mean()
        V = x.T * sigma * x
        x_upper = sum(diag(sigma) * x) / trace(sigma)

        # 5. Update the portfolio distribution
        mu, sigma = self.update(x, x_upper, mu, sigma, M, V, theta, eps)

        # 6. Normalize mu and sigma
        mu = self.simplex_proj(mu)
        sigma = sigma / (m**2 * trace(sigma))
        """
        sigma(sigma < 1e-4*eye(m)) = 1e-4;
        """
        self.sigma = sigma

        return np.ravel(mu)

    def update(self, x, x_upper, mu, sigma, M, V, theta, eps):
        # lambda from equation 7
        foo = (V - x_upper * x.T * np.sum(sigma, axis=1)) / M**2 + V * theta**2 / 2.
        a = foo**2 - V**2 * theta**4 / 4
        b = 2 * (eps - np.log(M)) * foo
        c = (eps - np.log(M))**2 - V * theta**2

        a,b,c = a[0,0], b[0,0], c[0,0]

        lam = np.amax([0,
                  (-b + sqrt(b**2 - 4 * a * c)) / (2. * a),
                  (-b - sqrt(b**2 - 4 * a * c)) / (2. * a)])
        # bound it due to numerical problems
        lam = np.minimum(lam, 1E+7)

        # update mu and sigma
        U_sqroot = 0.5 * (-lam * theta * V + sqrt(lam**2 * theta**2 * V**2 + 4*V))
        mu = mu - lam * sigma * (x - x_upper) / M
        sigma = inv(inv(sigma) + theta * lam / U_sqroot * diag(x)**2)
        """
        tmp_sigma = inv(inv(sigma) + theta*lam/U_sqroot*diag(xt)^2);
        % Don't update sigma if results are badly scaled.
        if all(~isnan(tmp_sigma(:)) & ~isinf(tmp_sigma(:)))
            sigma = tmp_sigma;
        end
        """
        return mu, sigma



### FILE: pgportfolio/tdagent/algorithms/cwmr_var.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
import scipy.stats
from numpy.linalg import inv
from numpy import diag, sqrt, log, trace

class CWMR_VAR(TDAgent):
    """ First variant of a CWMR outlined in original article. It is
    only approximation to the posted problem. """
    def __init__(self, eps=-0.5, confidence=0.95, sigma=None):
        """
        :param eps: Mean reversion threshold (expected return on current day must be lower
                    than this threshold). Recommended value is -0.5.
        :param confidence: Confidence parameter for profitable mean reversion portfolio. Recommended value is 0.95.
        """
        super(CWMR_VAR, self).__init__()
        # input check
        if not (0 <= confidence <= 1):
            raise ValueError('confidence must be from interval [0,1]')

        self.eps = eps
        self.theta = scipy.stats.norm.ppf(confidence)
        self.sigma = sigma

    def init_portfolio(self, X):
        m = X.shape[1]
        self.sigma = np.matrix(np.eye(m) / m**2)


    def decide_by_history(self, x, last_b):
        x = self.get_last_rpv(x)
        x = np.reshape(x, (1,x.size))
        last_b = np.reshape(last_b, (1,last_b.size))
        if self.sigma is None:
            self.init_portfolio(x)
        # initialize
        m = len(x)
        mu = np.matrix(last_b).T
        sigma = self.sigma
        theta = self.theta
        eps = self.eps
        x = np.matrix(x).T    # matrices are easier to manipulate

        # 4. Calculate the following variables
        M = (mu.T * x).mean()
        V = x.T * sigma * x
        x_upper = sum(diag(sigma) * x) / trace(sigma)

        # 5. Update the portfolio distribution
        mu, sigma = self.update(x, x_upper, mu, sigma, M, V, theta, eps)

        # 6. Normalize mu and sigma
        mu = self.simplex_proj(mu)
        sigma = sigma / (m**2 * trace(sigma))
        """
        sigma(sigma < 1e-4*eye(m)) = 1e-4;
        """
        self.sigma = sigma

        return np.ravel(mu)



### FILE: pgportfolio/tdagent/algorithms/eg.py
----------------------------------------
# -*- coding: utf-8 -*-
from ..tdagent import TDAgent
import numpy as np

class EG(TDAgent):
    """ Exponentiated Gradient (EG) algorithm by Helmbold et al.

    Reference:
        Helmbold, David P., et al.
        "On‐Line Portfolio Selection Using Multiplicative Updates."
        Mathematical Finance 8.4 (1998): 325-347.
        http://www.cis.upenn.edu/~mkearns/finread/helmbold98line.pdf
    """

    def __init__(self, eta=0.05, b=None, last_b=None):
        """
        :params eta: Learning rate. Controls volatility of weights.
        """
        super(EG, self).__init__()
        self.eta = eta
        self.b = b
        self.last_b = last_b

    def init_pw(self, x):
        self.b = np.ones(x.size)

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        x = self.history[-1,:].ravel()
        if self.last_b is None:
            self.last_b = np.ones(x.size) / x.size
        if self.b is None:
            self.init_pw(x)
        else:
            self.b = self.last_b * np.exp(self.eta * x.T / np.dot(x,last_b))
        b = self.b / np.sum(self.b)
        self.last_b = b
        return b



### FILE: pgportfolio/tdagent/algorithms/__init__.py
----------------------------------------
from __future__ import absolute_import
from pgportfolio.tdagent import *
# -*- coding: utf-8 -*-


### FILE: pgportfolio/tdagent/algorithms/m0.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np


class M0(TDAgent):
    """ Constant rebalanced portfolio = use fixed weights all the time. Uniform weights are commonly used as a benchmark.

    Reference:
        T. Cover. Universal Portfolios, 1991.
        http://www-isl.stanford.edu/~cover/papers/paper93.pdf
    """

    def __init__(self, beta=0.5, C=None):
        """
        :params b: Constant rebalanced portfolio weights. Default is uniform.
        """
        super(M0, self).__init__()
        self.beta = beta
        self.C = C

    def decide_by_history(self, x, last_b):
        x = self.get_last_rpv(x)
        m = x.size
        if self.C is None:
            self.C = np.zeros((m,1))
        b = (self.C + self.beta) / (m * self.beta + np.ones((1,m)).dot(self.C))
        max_ind = np.argmax(x)
        self.C[max_ind] += 1

        return b.ravel()



### FILE: pgportfolio/tdagent/algorithms/olmar2.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class OLMAR2(TDAgent):
    '''Moving average reversion strategy for on-line portfolio selection

    Reference:
        Bin Li, Steven C.H. Hoi, Doyen Sahoo, Zhi-Yong Liu

    '''

    def __init__(self,  eps=10, alpha=0.5, data_phi=None, b=None):
        '''init
        :param eps: mean reversion threshold
        :param alpha: trade off parameter for moving average
        '''
        super(OLMAR2, self).__init__()
        self.eps = eps
        self.alpha = alpha
        self.data_phi = data_phi
        self.b = b


    def decide_by_history(self, x, last_b):
        self.record_history(x)
        nx = self.get_last_rpv(x)

        if self.b is None:
            self.b = np.ones(nx.size) / nx.size
        last_b = self.b
        if self.data_phi is None:
            self.data_phi = np.ones((1,nx.size))
        else:
            self.data_phi = self.alpha + (1-self.alpha)*self.data_phi/nx

        ell = max(0, self.eps - self.data_phi.dot(last_b))

        x_bar = self.data_phi.mean()
        denominator = np.linalg.norm(self.data_phi - x_bar)**2

        if denominator == 0:
            lam = 0
        else:
            lam = ell / denominator

        self.data_phi = np.squeeze(self.data_phi)
        b = last_b + lam * (self.data_phi - x_bar)

        b = self.euclidean_proj_simplex(b)
        self.b = b
        return self.b


### FILE: pgportfolio/tdagent/algorithms/olmar.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class OLMAR(TDAgent):
    """ On-Line Portfolio Selection with Moving Average Reversion

    Reference:
        B. Li and S. C. H. Hoi.
        On-line portfolio selection with moving average reversion, 2012.
        http://icml.cc/2012/papers/168.pdf
    """

    def __init__(self, window=5, eps=10, cum_ret=1, count=0, b=None):
        """
        :param window: Lookback window.
        :param eps(epsilon): Constraint on return for new weights on last price (average of prices).
            x * w >= eps for new weights w.
        """
        super(OLMAR, self).__init__()
        # input check
        if window < 2:
            raise ValueError('window parameter must be >=3')
        if eps < 1:
            raise ValueError('epsilon parameter must be >=1')

        self.window = window
        self.eps = eps
        self.b = b

        #debugging parameters
        #self.cum_ret=cum_ret
        #self.count = count
        #self.last_b = last_b

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        nx = self.get_last_rpv(x)
        #if self.last_b is None:
        #    self.last_b = np.ones(12)/12
        #if self.history.shape[0] < self.window:
        #    return np.ones(nx.size) /nx.size
        #predict next price relative vector
        if self.b is None:
            self.b = np.ones(nx.size) / nx.size
        last_b = self.b
        if self.history.shape[0] < self.window + 1:
            data_phi=self.history[self.history.shape[0]-1,:]
        else:
            data_phi = np.zeros((1,nx.size))
            tmp_x = np.ones((1,nx.size))
            temp = 1.
            for i in range(self.window):
                data_phi += temp
                tmp_x = np.multiply(tmp_x, self.history[-i-1,:])
                temp = 1. / tmp_x
            data_phi = data_phi * (1./self.window)
        data_phi = np.squeeze(data_phi)
        #update portfolio
        b = self.update(last_b, data_phi, self.eps)
        #self.last_b = b
        #self.cum_ret *= np.dot(last_b, nx)
        #self.count += 1
        #print 'period %d, total return is %f' % (self.count, self.cum_ret)
        b = b.ravel()
        self.b = b
        return self.b


    def update(self, b, x, eps):
        """ Update portfolio weights to satisfy constraint b * x >= eps
        and minimize distance to previous weights. """
        x_mean = x.mean()
        ell = max(0, eps - b.dot(x))
        denominator = np.linalg.norm(x-x_mean)**2
        if denominator == 0:
            #zero valatility
            lam = 0
        else:
            lam = ell / denominator
        # update portfolio
        b = b + lam * (x - x_mean)
        # project it onto simplex
        return self.euclidean_proj_simplex(b)




### FILE: pgportfolio/tdagent/algorithms/ons.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np
from cvxopt import solvers, matrix
solvers.options['show_progress'] = False

class ONS(TDAgent):
    """
    Online newton step algorithm.

    Reference:
        A.Agarwal, E.Hazan, S.Kale, R.E.Schapire.
        Algorithms for Portfolio Management based on the Newton Method, 2006.
        http://machinelearning.wustl.edu/mlpapers/paper_files/icml2006_AgarwalHKS06.pdf
    """
    def __init__(self, delta=0.125, beta=1., eta=0., A = None):
        """
        :param delta, beta, eta: Model parameters. See paper.
        """
        super(ONS, self).__init__()
        self.delta = delta
        self.beta = beta
        self.eta = eta
        self.A = A

    def init_portfolio(self, X):
        m = X.size
        self.A = np.mat(np.eye(m))
        self.b = np.mat(np.zeros(m)).T


    def decide_by_history(self, x, last_b):
        '''
        :param x: input matrix
        :param last_b: last portfolio
        '''
        x = self.get_last_rpv(x)
        if self.A is None:
            self.init_portfolio(x)

        # calculate gradient
        grad = np.mat(x / np.dot(last_b, x)).T
        # update A
        self.A += grad * grad.T
        # update b
        self.b += (1 + 1./self.beta) * grad

        # projection of p induced by norm A
        pp = self.projection_in_norm(self.delta * self.A.I * self.b, self.A)
        return pp * (1 - self.eta) + np.ones(len(x)) / float(len(x)) * self.eta

    def projection_in_norm(self, x, M):
        """ Projection of x to simplex indiced by matrix M. Uses quadratic programming.
        """
        m = M.shape[0]

        P = matrix(2*M)
        q = matrix(-2 * M * x)
        G = matrix(-np.eye(m))
        h = matrix(np.zeros((m,1)))
        A = matrix(np.ones((1,m)))
        b = matrix(1.)

        sol = solvers.qp(P, q, G, h, A, b)
        return np.squeeze(sol['x'])



### FILE: pgportfolio/tdagent/algorithms/pamr.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np


class PAMR(TDAgent):
    """ Passive aggressive mean reversion strategy for portfolio selection.
    There are three variants with different parameters, see original article
    for details.

    Reference:
        B. Li, P. Zhao, S. C.H. Hoi, and V. Gopalkrishnan.
        Pamr: Passive aggressive mean reversion strategy for portfolio selection, 2012.
        http://www.cais.ntu.edu.sg/~chhoi/paper_pdf/PAMR_ML_final.pdf
    """
    def __init__(self, eps=0.5, C=500, variant=2, b=None):
        """
        :param eps: Control parameter for variant 0. Must be >=0, recommended value is
                    between 0.5 and 1.
        :param C: Control parameter for variant 1 and 2. Recommended value is 500.
        :param variant: Variants 0, 1, 2 are available.
        """
        super(PAMR, self).__init__()

        # input check
        if not(eps >= 0):
            raise ValueError('epsilon parameter must be >=0')

        if variant == 0:
            if eps is None:
                raise ValueError('eps parameter is required for variant 0')
        elif variant == 1 or variant == 2:
            if C is None:
                raise ValueError('C parameter is required for variant 1,2')
        else:
            raise ValueError('variant is a number from 0,1,2')

        self.eps = eps
        self.C = C
        self.variant = variant
        self.b = b

    def decide_by_history(self, x, last_b):
        x = self.get_last_rpv(x)
        # calculate return prediction
        if self.b is None:
            self.b = np.ones(x.size) / x.size
        last_b = self.b
        b = self.update(last_b, x, self.eps, self.C)
        b = b.ravel()
        self.b = b
        return self.b


    def update(self, b, x, eps, C):
        """ Update portfolio weights to satisfy constraint b * x <= eps
        and minimize distance to previous weights. """
        x_mean = np.mean(x)

        le = np.maximum(0., np.dot(b, x) - eps)

        denominator = np.square(np.linalg.norm(x-x_mean))

        if self.variant == 0:
            tau = le / denominator
        elif self.variant == 1:
            tau = np.minimum(C, le / denominator)
        elif self.variant == 2:
            tau = le / (denominator + 0.5 / C)

        # limit lambda to avoid numerical problems
        tau = np.minimum(100000, tau)

        # update portfolio
        b = b - tau * (x - x_mean)

        # project it onto simplex
        return self.simplex_proj(b)




### FILE: pgportfolio/tdagent/algorithms/rmr_deprecated.py
----------------------------------------
import numpy as np
import pandas as pd
from pgportfolio.tdagent.algorithms.olmar import OLMAR

class RMR(OLMAR):
    '''universal-portfolio implementation'''
    def __init__(self, window=5, eps=10, tau=1e-3):
        super(RMR, self).__init__(window, eps)
        self.tau = tau

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        close = pd.DataFrame(self.get_close())
        nx = close.iloc[-1,:]
        #print close.shape
        y = close.mean()
        y_last = None
        while y_last is None or norm(y-y_last)/norm(y_last)>self.tau:
            y_last=y
            d=norm(close-y)
            y = close.div(d, axis=0).sum() / (1./d).sum()
        return y/nx

def norm(x):
    if isinstance(x, pd.Series):
        axis=0
    else:
        axis=1
    return np.sqrt((x**2).sum(axis=axis))


### FILE: pgportfolio/tdagent/algorithms/rmr.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class RMR(TDAgent):
    ''' Robust Median Reversion

    Reference:


    '''
    def __init__(self, eps=5, W=5, b=None):
        '''
        :param eps: the parameter control the reversion threshold
        :pram W: the length of window
        '''
        super(RMR, self).__init__()
        self.eps = eps
        self.W = W
        self.b = b

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        data_close = self.get_close()
        b = self.update(data_close, self.history, last_b, self.eps, self.W)
        return b

    def update(self, data_close, data, last_b, eps, W):
        t1 = data.shape[0]
        if t1 < W+2:
            x_t1 = data[t1-1, :]
        else:
            x_t1 = self.l1_median_VaZh(data_close[(t1-W):(t1-1),:]) / data_close[t1-1,:]

        if np.linalg.norm(x_t1 - x_t1.mean())**2 == 0:
            tao = 0
        else:
            tao = min(0, (x_t1.dot(last_b)-eps) / np.linalg.norm(x_t1 - x_t1.mean())**2)
        if self.b is None:
            self.b = np.ones(data.shape[1])/data.shape[1]
        else:
            self.b -= tao * (x_t1 - x_t1.mean() * np.ones(x_t1.shape))
            self.b = self.euclidean_proj_simplex(self.b)
        return self.b


### FILE: pgportfolio/tdagent/algorithms/sp.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class SP(TDAgent):
    '''Switch Portfolio'''
    def __init__(self, gamma=0.25, last_b=None):
        super(SP, self).__init__()
        self.gamma = gamma
        self.last_b = last_b

    def decide_by_history(self, x, last_b):
        self.record_history(x)
        nx = self.history[-1,:].ravel()
        if self.last_b is None:
            self.last_b = np.ones(nx.size) / nx.size
        b = self.last_b * (1-self.gamma-self.gamma/nx.size) + self.gamma/nx.size
        b = b / np.sum(b)
        self.last_b = b
        return b


### FILE: pgportfolio/tdagent/algorithms/ubah.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class UBAH(TDAgent):

    def __init__(self, b = None):
        super(UBAH, self).__init__()
        self.b = b

    def decide_by_history(self, x, last_b):
        '''return new portfolio vector
        :param x: input matrix
        :param last_b: last portfolio weight vector
        '''
        if self.b is None:
            self.b = np.ones(12) / 12
        else:
            self.b = last_b
        return self.b


### FILE: pgportfolio/tdagent/algorithms/up.py
----------------------------------------
from ..tdagent import TDAgent
import numpy as np

class UP(TDAgent):
    """ Universal Portfolio by Thomas Cover enhanced for "leverage" (instead of just
        taking weights from a simplex, leverage allows us to stretch simplex to
        contain negative positions).

    Reference:
        T. Cover. Universal Portfolios, 1991.
        http://www-isl.stanford.edu/~cover/papers/paper93.pdf
    """
    def __init__(self, eval_points=10000, leverage=1., W=None):
        """
        :param eval_points: Number of evaluated points (approximately). Complexity of the
            algorithm is O(time * eval_points * nr_assets**2) because of matrix multiplication.
        :param leverage: Maximum leverage used. leverage == 1 corresponds to simplex,
            leverage == 1/nr_stocks to uniform CRP. leverage > 1 allows negative weights
            in portfolio.
        """
        super(UP, self).__init__()
        self.eval_points = eval_points
        self.leverage = leverage
        self.W = W

    def init_portfolio(self, X):
        """ Create a mesh on simplex and keep wealth of all strategies. """
        m = X.shape[1]
        # create set of CRPs
        self.W = np.matrix(mc_simplex(m - 1, self.eval_points))
        self.S = np.matrix(np.ones(self.W.shape[0])).T

        # stretch simplex based on leverage (simple calculation yields this)
        leverage = max(self.leverage, 1./m)
        stretch = (leverage - 1./m) / (1. - 1./m)
        self.W = (self.W - 1./m) * stretch + 1./m


    def decide_by_history(self, x, last_b):
        # calculate new wealth of all CRPs
        x = self.get_last_rpv(x)
        x = np.reshape(x, (1,x.size))

        if self.W is None:
            self.init_portfolio(x)

        self.S = np.multiply(self.S, self.W * np.matrix(x).T)
        b = self.W.T * self.S
        pv = b / np.sum(b)
        pvn = np.ravel(pv)
        return pvn #squeeze not working there



def mc_simplex(d, points):
    '''Sample random points from a simplex with dimension d
    :param d: Number of dimensions
    :param points: Total number of points.
    '''
    a = np.sort(np.random.random((points,d)))
    a = np.hstack([np.zeros((points,1)), a, np.ones((points,1))])
    return np.diff(a)





### FILE: pgportfolio/tdagent/algorithms/wmamr.py
----------------------------------------
from pgportfolio.tdagent.algorithms.pamr import PAMR
import numpy as np


class WMAMR(PAMR):
    """ Weighted Moving Average Passive Aggressive Algorithm for Online Portfolio Selection.
    It is just a combination of OLMAR and PAMR, where we use mean of past returns to predict
    next day's return.

    Reference:
        Li Gao, Weiguo Zhang
        Weighted Moving Averag Passive Aggressive Algorithm for Online Portfolio Selection, 2013.
        http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6643896
    """

    def __init__(self, window=5):
        """
        :param w: Windows length for moving average.
        """
        super(WMAMR, self).__init__()

        if window < 1:
            raise ValueError('window parameter must be >=1')
        self.window = window


    def decide_by_history(self, x, last_b):
        self.record_history(x)
        xx = np.mean(self.history[-self.window:,], axis=0)
        # calculate return prediction
        b = self.update(last_b, xx, self.eps, self.C)

        return b



### FILE: pgportfolio/tdagent/__init__.py
----------------------------------------
from __future__ import absolute_import
# -*- coding: utf-8 -*-


### FILE: pgportfolio/tdagent/tdagent.py
----------------------------------------
from __future__ import absolute_import
import numpy as np
import logging
from scipy.optimize import minimize
from scipy.spatial.distance import cdist, euclidean

class TDAgent(object):
    '''Traditional Agent.
    parent class for algorithms(new-style)
    '''

    def __init__(self, history=None, cum_ret=None, last_b=None):
        '''init
        :param X: input
        :param history: a history list of relative price vector
        '''
        self.history = history
        self.cum_ret = cum_ret
        self.last_b = last_b

    @property
    def agent(self):
        return self._agent


    def decide_by_history(self, x, last_b):
        '''calculate new portfolio weight vector.
        :param x: input x
        :last_b: last portfolio weight vector
        '''
        raise NotImplementedError('subclass must implement this!')

    def get_last_rpv(self, x):
        '''remove dimension of input. Return last relative price vector.
        :param x: matrix with shape (1, window_size, coin_number+1)
        '''
        if x.ndim == 3:
            #print x.shape
            last_rpv = x[0,:,-1] # output a vector with shape (x.size,)
        else:
            last_rpv = x #if it has already been processed just return x
        return last_rpv

    def get_first_history(self, x):
        '''get history in first period
        :param x: input matrix
        '''
        if x.ndim == 3:
            first = x[0,:,:] # array size (#assets, #periods)

        #return (#periods, #assets) for convention
        return first.T

    def record_history(self, x):
        nx = self.get_last_rpv(x)
        nx = np.reshape(nx, (1,nx.size))
        if self.history is None:
            #self.history = self.get_first_history(x)
            self.history = nx
        else:
            self.history = np.vstack((self.history, nx))

    def get_close(self):
        '''get close data from relative price
        :param x: relative price data
        '''
        close = np.ones(self.history.shape)
        for i in range(1,self.history.shape[0]):
            close[i,:] = close[i-1] * self.history[i,:]
        return close

    def simplex_proj(self, y):
        '''projection of y onto simplex. '''
        m = len(y)
        bget = False

        s = sorted(y, reverse = True)
        tmpsum = 0.

        for ii in range(m-1):
            tmpsum = tmpsum + s[ii]
            tmax = (tmpsum - 1) / (ii + 1)
            if tmax >= s[ii+1]:
                bget = True
                break

        if not bget:
            tmax = (tmpsum + s[m-1] - 1) / m

        return np.maximum(0, y-tmax)

    def get_last_return(self, last_b):
        '''Caulate daily retrun. No need to calculate transaction cost there.
        '''
        last_x = self.history[-1,:]
        self.ret = last_b * last_x #element-wise
        return np.squeeze(self.ret)

    def cal_cum_ret(self, ret):
        '''Calculate the cumulative return.
        :param ret: newest retrun
        '''
        if self.cum_ret is None:
            self.cum_ret = ret
        else:
            self.cum_ret = self.cum_ret * ret #element-wise
        return self.cum_ret

    def find_bcrp(self, X, max_leverage=1):
        x_0 = max_leverage * np.ones(X.shape[1]) / np.float(X.shape[1])
        objective = lambda b: -np.prod(np.dot(X, b))
        cons = ({'type': 'eq', 'fun': lambda b: max_leverage - np.sum(b, axis=0)},)
        bnds = [(0., max_leverage)]*len(x_0)
        while True:
            res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp')
            eps = 1e-7
            if (res.x < 0-eps).any() or (res.x > max_leverage+eps).any():
                X = X + np.random.randn(1)[0] * 1e-5
                logging.debug('Optimal weights not found, trying again...')
                continue
            elif res.success:
                break
            else:
                if np.isnan(res.x).any():
                    logging.warning('Solution does not exist, use uniform portfolio weight vector.')
                    res.x = np.ones(X.shape[1]) / X.shape[1]
                else:
                    logging.warning('Converged but not successfully.')
                break

        return res.x


    def euclidean_proj_simplex(self, v, s=1):
        '''Compute the Euclidean projection on a positive simplex
        :param v: n-dimensional vector to project
        :param s: int, radius of the simple

        return w numpy array, Euclidean projection of v on the simplex

        Original author: John Duchi
        '''
        assert s>0, "Radius s must be positive (%d <= 0)" % s

        n, = v.shape # raise ValueError if v is not 1D
        # check if already on the simplex
        if v.sum() == s and np.alltrue( v>= 0):
            return v

        # get the array of cumulaive sums of a sorted copy of v
        u = np.sort(v)[::-1]
        cssv = np.cumsum(u)
        # get the number of >0 components of the optimal solution
        rho = np.nonzero(u * np.arange(1, n+1) > (cssv - s))[0][-1]
        # compute the Lagrange multiplier associated to the simplex constraint
        theta = (cssv[rho] - s) / (rho + 1.)
        w = (v-theta).clip(min=0)
        return w

    def l1_median_VaZh(self, X, eps=1e-5):
        '''calculate the L1_median of X with the l1median_VaZh method
        '''
        y = np.mean(X, 0)

        while True:
            D = cdist(X, [y])
            nonzeros = (D != 0)[:, 0]

            Dinv = 1 / D[nonzeros]
            Dinvs = np.sum(Dinv)
            W = Dinv / Dinvs
            T = np.sum(W * X[nonzeros], 0)
            num_zeros = len(X) - np.sum(nonzeros)
            if num_zeros == 0:
                y1 = T
            elif num_zeros == len(X):
                return y
            else:
                R = (T - y) * Dinvs
                r = np.linalg.norm(R)
                rinv = 0 if r==0 else num_zeros/r
                y1 = max(0, 1-rinv)*T + min(1, rinv)*y

            if euclidean(y, y1) < eps:
                return y1

            y = y1

    def corn_expert(self, data, w, c):
        '''
        :param w: window sze
        :param c: correlation coefficient threshold
        '''
        T, N = data.shape
        m = 0
        histdata = np.zeros((T,N))

        if T <= w+1:
            '''use uniform portfolio weight vector'''
            return np.ones(N) / N

        if w==0:
            histdata = data[:T,:]
            m = T
        else:
            for i in np.arange(w, T):
                d1 = data[i-w:i,:]
                d2 = data[T-w:T,:]
                datacorr = np.corrcoef(d1,d2)[0,1]

                if datacorr >= c:
                    m += 1
                    histdata[m,:] = data[i-1,:] #minus one to avoid out of bounds issue

        if m==0:
            return np.ones(N) / N

        #sqp according to OLPS implementation
        x_0 = np.ones((1,N)) / N
        objective = lambda b: -np.prod(np.dot(histdata, b))
        cons = ({'type': 'eq', 'fun': lambda b: 1-np.sum(b, axis=0)},)
        bnds = [(0.,1)]*N
        while True:
            res = minimize(objective, x_0, bounds=bnds, constraints=cons, method='slsqp')
            eps = 1e-7
            if (res.x < 0-eps).any() or (res.x > 1+eps).any():
                data += np.random.randn(1)[0] * 1e-5
                logging.debug('Optimal portfolio weight vector not found, trying again...')
                continue
            elif res.success:
                break
            else:
                if np.isnan(res.x).any():
                    logging.warning('Solution does not exist, use uniform pwv')
                    res.x = np.ones(N) / N
                else:
                    logging.warning('Converged but not successfully.')
                break

        return res.x


### FILE: pgportfolio/tools/configprocess.py
----------------------------------------
from __future__ import absolute_import, division, print_function
import sys
import time
from datetime import datetime
import json
import os
rootpath = os.path.dirname(os.path.abspath(__file__)).\
    replace("\\pgportfolio\\tools", "").replace("/pgportfolio/tools","")

try:
    unicode        # Python 2
except NameError:
    unicode = str  # Python 3


def preprocess_config(config):
    fill_default(config)
    if sys.version_info[0] == 2:
        return byteify(config)
    else:
        return config


def fill_default(config):
    set_missing(config, "random_seed", 0)
    set_missing(config, "agent_type", "NNAgent")
    fill_layers_default(config["layers"])
    fill_input_default(config["input"])
    fill_train_config(config["training"])


def fill_train_config(train_config):
    set_missing(train_config, "fast_train", True)
    set_missing(train_config, "decay_rate", 1.0)
    set_missing(train_config, "decay_steps", 50000)


def fill_input_default(input_config):
    set_missing(input_config, "save_memory_mode", False)
    set_missing(input_config, "portion_reversed", False)
    set_missing(input_config, "market", "poloniex")
    set_missing(input_config, "norm_method", "absolute")
    set_missing(input_config, "is_permed", False)
    set_missing(input_config, "fake_ratio", 1)


def fill_layers_default(layers):
    for layer in layers:
        if layer["type"] == "ConvLayer":
            set_missing(layer, "padding", "valid")
            set_missing(layer, "strides", [1, 1])
            set_missing(layer, "activation_function", "relu")
            set_missing(layer, "regularizer", None)
            set_missing(layer, "weight_decay", 0.0)
        elif layer["type"] == "EIIE_Dense":
            set_missing(layer, "activation_function", "relu")
            set_missing(layer, "regularizer", None)
            set_missing(layer, "weight_decay", 0.0)
        elif layer["type"] == "DenseLayer":
            set_missing(layer, "activation_function", "relu")
            set_missing(layer, "regularizer", None)
            set_missing(layer, "weight_decay", 0.0)
        elif layer["type"] == "EIIE_LSTM" or layer["type"] == "EIIE_RNN":
            set_missing(layer, "dropouts", None)
        elif layer["type"] == "EIIE_Output" or\
                layer["type"] == "Output_WithW" or\
                layer["type"] == "EIIE_Output_WithW":
            set_missing(layer, "regularizer", None)
            set_missing(layer, "weight_decay", 0.0)
        elif layer["type"] == "DropOut":
            pass
        else:
            raise ValueError("layer name {} not supported".format(layer["type"]))


def set_missing(config, name, value):
    if name not in config:
        config[name] = value


def byteify(input):
    if isinstance(input, dict):
        return {byteify(key): byteify(value)
                for key, value in input.iteritems()}
    elif isinstance(input, list):
        return [byteify(element) for element in input]
    elif isinstance(input, unicode):
        return str(input)
    else:
        return input


def parse_time(time_string):
    return time.mktime(datetime.strptime(time_string, "%Y/%m/%d").timetuple())


def load_config(index=None):
    """
    @:param index: if None, load the default in pgportfolio;
     if a integer, load the config under train_package
    """
    if index:
        with open(rootpath+"/train_package/" + str(index) + "/net_config.json") as file:
            config = json.load(file)
    else:
        with open(rootpath+"/pgportfolio/" + "net_config.json") as file:
            config = json.load(file)
    return preprocess_config(config)


def check_input_same(config1, config2):
    input1 = config1["input"]
    input2 = config2["input"]
    if input1["start_date"] != input2["start_date"]:
        return False
    elif input1["end_date"] != input2["end_date"]:
        return False
    elif input1["test_portion"] != input2["test_portion"]:
        return False
    else:
        return True



### FILE: pgportfolio/tools/data.py
----------------------------------------
from __future__ import division,absolute_import,print_function
import numpy as np
import pandas as pd


def pricenorm3d(m, features, norm_method, fake_ratio=1.0, with_y=True):
    """normalize the price tensor, whose shape is [features, coins, windowsize]
    @:param m: input tensor, unnormalized and there could be nan in it
    @:param with_y: if the tensor include y (future price)
        logging.debug("price are %s" % (self._latest_price_matrix[0, :, -1]))
    """
    result = m.copy()
    if features[0] != "close":
        raise ValueError("first feature must be close")
    for i, feature in enumerate(features):
        if with_y:
            one_position = 2
        else:
            one_position = 1
        pricenorm2d(result[i], m[0, :, -one_position], norm_method=norm_method,
                    fake_ratio=fake_ratio, one_position=one_position)
    return result


# input m is a 2d matrix, (coinnumber+1) * windowsize
def pricenorm2d(m, reference_column,
                norm_method="absolute", fake_ratio=1.0, one_position=2):
    if norm_method=="absolute":
        output = np.zeros(m.shape)
        for row_number, row in enumerate(m):
            if np.isnan(row[-one_position]) or np.isnan(reference_column[row_number]):
                row[-one_position] = 1.0
                for index in range(row.shape[0] - one_position + 1):
                    if index > 0:
                        row[-one_position - index] = row[-index - one_position + 1] / fake_ratio
                row[-one_position] = 1.0
                row[-1] = fake_ratio
            else:
                row = row / reference_column[row_number]
                for index in range(row.shape[0] - one_position + 1):
                    if index > 0 and np.isnan(row[-one_position - index]):
                        row[-one_position - index] = row[-index - one_position + 1] / fake_ratio
                if np.isnan(row[-1]):
                    row[-1] = fake_ratio
            output[row_number] = row
        m[:] = output[:]
    elif norm_method=="relative":
        output = m[:, 1:]
        divisor = m[:, :-1]
        output = output / divisor
        pad = np.empty((m.shape[0], 1,))
        pad.fill(np.nan)
        m[:] = np.concatenate((pad, output), axis=1)
        m[np.isnan(m)] = fake_ratio
    else:
        raise ValueError("there is no norm morthod called %s" % norm_method)


def get_chart_until_success(polo, pair, start, period, end):
    is_connect_success = False
    chart = {}
    while not is_connect_success:
        try:
            chart = polo.marketChart(pair=pair, start=int(start), period=int(period), end=int(end))
            is_connect_success = True
        except Exception as e:
            print(e)
    return chart


def get_type_list(feature_number):
    """
    :param feature_number: an int indicates the number of features
    :return: a list of features n
    """
    if feature_number == 1:
        type_list = ["close"]
    elif feature_number == 2:
        type_list = ["close", "volume"]
        raise NotImplementedError("the feature volume is not supported currently")
    elif feature_number == 3:
        type_list = ["close", "high", "low"]
    elif feature_number == 4:
        type_list = ["close", "high", "low", "open"]
    else:
        raise ValueError("feature number could not be %s" % feature_number)
    return type_list


def panel2array(panel):
    """convert the panel to datatensor (numpy array) without btc
    """
    without_btc = np.transpose(panel.values, axes=(2, 0, 1))
    return without_btc


def count_periods(start, end, period_length):
    """
    :param start: unix time, excluded
    :param end: unix time, included
    :param period_length: length of the period
    :return: 
    """
    return (int(end)-int(start)) // period_length


def get_volume_forward(time_span, portion, portion_reversed):
    volume_forward = 0
    if not portion_reversed:
        volume_forward = time_span*portion
    return volume_forward


def panel_fillna(panel, type="bfill"):
    """
    fill nan along the 3rd axis
    :param panel: the panel to be filled
    :param type: bfill or ffill
    """
    frames = {}
    for item in panel.items:
        if type == "both":
            frames[item] = panel.loc[item].fillna(axis=1, method="bfill").\
                fillna(axis=1, method="ffill")
        else:
            frames[item] = panel.loc[item].fillna(axis=1, method=type)
    return pd.Panel(frames)



### FILE: pgportfolio/tools/indicator.py
----------------------------------------
from __future__ import division, print_function, absolute_import
import numpy as np


def max_drawdown(pc_array):
    """calculate the max drawdown with the portfolio changes
    @:param pc_array: all the portfolio changes during a trading process
    @:return: max drawdown
    """
    portfolio_values = []
    drawdown_list = []
    max_benefit = 0
    for i in range(pc_array.shape[0]):
        if i > 0:
            portfolio_values.append(portfolio_values[i - 1] * pc_array[i])
        else:
            portfolio_values.append(pc_array[i])
        if portfolio_values[i] > max_benefit:
            max_benefit = portfolio_values[i]
            drawdown_list.append(0.0)
        else:
            drawdown_list.append(1.0 - portfolio_values[i] / max_benefit)
    return max(drawdown_list)


def sharpe(pc_array):
    """calculate sharpe ratio with the portfolio changes
    @:param pc_array: all the portfolio changes during a trading process
    @:return: sharpe ratio
    """
    pc_array = pc_array-1.0
    return np.mean(pc_array)/np.std(pc_array)


def moving_accumulate(pc_array, n=48):
    acc = np.cumprod(pc_array)
    acc[n:] = acc[n:] / acc[:-n]
    return acc


def positive_count(pc_array):
    return np.sum(pc_array>1)


def negative_count(pc_array):
    return np.sum(pc_array<1)


### FILE: pgportfolio/tools/__init__.py
----------------------------------------


### FILE: pgportfolio/tools/shortcut.py
----------------------------------------
from __future__ import division,absolute_import,print_function
from pgportfolio.trade.backtest import BackTest
from pgportfolio.tdagent.algorithms import crp, ons, olmar, up, anticor1, pamr,\
    best, bk, cwmr_std, eg, sp, ubah, wmamr, bcrp, cornk, m0, rmr

# the dictionary of name of algorithms mapping to the constructor of tdagents
ALGOS = {"crp": crp.CRP, "ons": ons.ONS, "olmar": olmar.OLMAR, "up": up.UP,
         "anticor": anticor1.ANTICOR1, "pamr": pamr.PAMR,
         "best": best.BEST, "bk": bk.BK, "bcrp": bcrp.BCRP,
         "corn": cornk.CORNK, "m0": m0.M0, "rmr": rmr.RMR,
         "cwmr": cwmr_std.CWMR_STD, "eg": eg.EG, "sp": sp.SP, "ubah": ubah.UBAH,
         "wmamr": wmamr.WMAMR}

def execute_backtest(algo, config):
    """
    @:param algo: string representing the name the name of algorithms
    @:return: numpy array of portfolio changes
    """
    agent, agent_type, net_dir = _construct_agent(algo)
    backtester = BackTest(config, agent=agent, agent_type=agent_type, net_dir=net_dir)
    backtester.start_trading()
    return backtester.test_pc_vector


def _construct_agent(algo):
    if algo.isdigit():
        agent = None
        agent_type = "nn"
        net_dir = "./train_package/" + algo + "/netfile"
    elif algo in ALGOS:
        agent = ALGOS[algo]()
        agent_type = "traditional"
        net_dir = None
    else:
        message = "The algorithm name "+algo+" is not support. Supported algos " \
                                             "are " + str(list(ALGOS.keys()))
        raise LookupError(message)
    return agent, agent_type, net_dir

### FILE: pgportfolio/tools/trade.py
----------------------------------------
from __future__ import division,absolute_import,print_function
import numpy as np
from pgportfolio.marketdata.datamatrices import DataMatrices
from pgportfolio.marketdata.globaldatamatrix import HistoryManager
from pgportfolio.tools.configprocess import parse_time
from pgportfolio.constants import *
from pgportfolio.tools.data import get_volume_forward
from time import time


def get_coin_name_list(config, online):
    """
    :param online: boolean value to show if connected to internet,
    if False, load data from database.
    :return : list of coin names
    """
    input_config = config["input"]
    if not online:
        start = parse_time(input_config["start_date"])
        end = parse_time(input_config["end_date"])
        volume_forward = get_volume_forward(end - start,
                                            input_config["test_portion"]
                                            + input_config["validation_portion"],
                                            input_config["portion_reversed"])
    else:
        end = time()
        volume_forward = 0
    end = end - (end % input_config["trade_period"])
    start = end - volume_forward - input_config["volume_average_days"] * DAY
    end = end - volume_forward
    coins = HistoryManager(input_config["coin_number"], end,
                           volume_forward=volume_forward,
                           volume_average_days=input_config["volume_average_days"],
                           online=online).\
        select_coins(start, end)
    return coins


def calculate_pv_after_commission(w1, w0, commission_rate):
    """
    @:param w1: target portfolio vector, first element is btc
    @:param w0: rebalanced last period portfolio vector, first element is btc
    @:param commission_rate: rate of commission fee, proportional to the transaction cost
    """
    mu0 = 1
    mu1 = 1 - 2*commission_rate + commission_rate ** 2
    while abs(mu1-mu0) > 1e-10:
        mu0 = mu1
        mu1 = (1 - commission_rate * w0[0] -
            (2 * commission_rate - commission_rate ** 2) *
            np.sum(np.maximum(w0[1:] - mu1*w1[1:], 0))) / \
            (1 - commission_rate * w1[0])
    return mu1


def get_test_data(config):
    """
    :return : a 2d numpy array with shape(coin_number, periods),
     each element the relative price
    """
    config["input"]["feature_number"] = 1
    config["input"]["norm_method"] = "relative"
    config["input"]["global_period"] = config["input"]["global_period"]
    price_matrix = DataMatrices.create_from_config(config)
    test_set = price_matrix.get_test_set()["y"][:, 0, :].T
    test_set = np.concatenate((np.ones((1, test_set.shape[1])), test_set), axis=0)
    return test_set


def asset_vector_to_dict(coin_list, vector, with_BTC=True):
    vector = np.squeeze(vector)
    dict_coin = {}
    if with_BTC:
        dict_coin['BTC'] = vector[0]
    for i, name in enumerate(coin_list):
        if vector[i+1] > 0:
            dict_coin[name] = vector[i + 1]
    return dict_coin


def save_test_data(config, file_name="test_data", output_format="csv"):
    if output_format == "csv":
        matrix = get_test_data(config)
        with open(file_name+"."+output_format, 'wb') as f:
            np.savetxt(f, matrix.T, delimiter=",")



### FILE: pgportfolio/trade/backtest.py
----------------------------------------
from __future__ import absolute_import, division, print_function
import numpy as np
from pgportfolio.trade import trader
from pgportfolio.marketdata.datamatrices import DataMatrices
import logging
from pgportfolio.tools.trade import calculate_pv_after_commission


class BackTest(trader.Trader):
    def __init__(self, config, net_dir=None, agent=None, agent_type="nn"):
        trader.Trader.__init__(self, 0, config, 0, net_dir,
                               initial_BTC=1, agent=agent, agent_type=agent_type)
        if agent_type == "nn":
            data_matrices = self._rolling_trainer.data_matrices # ??
        elif agent_type == "traditional":
            config["input"]["feature_number"] = 1
            data_matrices = DataMatrices.create_from_config(config)
        else:
            raise ValueError()
        self.__test_set = data_matrices.get_test_set()
        self.__test_length = self.__test_set["X"].shape[0]
        self._total_steps = self.__test_length
        self.__test_pv = 1.0
        self.__test_pc_vector = []

    @property
    def test_pv(self):
        return self.__test_pv

    @property
    def test_pc_vector(self):
        return np.array(self.__test_pc_vector, dtype=np.float32)

    def finish_trading(self):
        self.__test_pv = self._total_capital

        """
        fig, ax = plt.subplots()
        ax.bar(np.arange(len(self._rolling_trainer.data_matrices.sample_count)),
               self._rolling_trainer.data_matrices.sample_count)
        fig.tight_layout()
        plt.show()
        """

    def _log_trading_info(self, time, omega):
        pass

    def _initialize_data_base(self):
        pass

    def _write_into_database(self):
        pass

    def __get_matrix_X(self):
        return self.__test_set["X"][self._steps]

    def __get_matrix_y(self):
        return self.__test_set["y"][self._steps, 0, :]

    def rolling_train(self, online_sample=None):
        self._rolling_trainer.rolling_train()

    def generate_history_matrix(self):
        inputs = self.__get_matrix_X()
        if self._agent_type == "traditional":
            inputs = np.concatenate([np.ones([1, 1, inputs.shape[2]]), inputs], axis=1)
            inputs = inputs[:, :, 1:] / inputs[:, :, :-1]
        return inputs

    def trade_by_strategy(self, omega):
        logging.info("the step is {}".format(self._steps))
        logging.debug("the raw omega is {}".format(omega))
        future_price = np.concatenate((np.ones(1), self.__get_matrix_y()))
        pv_after_commission = calculate_pv_after_commission(omega, self._last_omega, self._commission_rate)
        portfolio_change = pv_after_commission * np.dot(omega, future_price)
        self._total_capital *= portfolio_change
        self._last_omega = pv_after_commission * omega * \
                           future_price /\
                           portfolio_change
        logging.debug("the portfolio change this period is : {}".format(portfolio_change))
        self.__test_pc_vector.append(portfolio_change)



### FILE: pgportfolio/trade/__init__.py
----------------------------------------


### FILE: pgportfolio/trade/trader.py
----------------------------------------
from __future__ import absolute_import, division, print_function
import numpy as np
import pandas as pd
from pgportfolio.learn.rollingtrainer import RollingTrainer
import logging
import time


class Trader:
    def __init__(self, waiting_period, config, total_steps, net_dir, agent=None, initial_BTC=1.0, agent_type="nn"):
        """
        @:param agent_type: string, could be nn or traditional
        @:param agent: the traditional agent object, if the agent_type is traditional
        """
        self._steps = 0
        self._total_steps = total_steps
        self._period = waiting_period
        self._agent_type = agent_type

        if agent_type == "traditional":
            config["input"]["feature_number"] = 1
            config["input"]["norm_method"] = "relative"
            self._norm_method = "relative"
        elif agent_type == "nn":
            self._rolling_trainer = RollingTrainer(config, net_dir, agent=agent)
            self._coin_name_list = self._rolling_trainer.coin_list
            self._norm_method = config["input"]["norm_method"]
            if not agent:
                agent = self._rolling_trainer.agent
        else:
            raise ValueError()
        self._agent = agent

        # the total assets is calculated with BTC
        self._total_capital = initial_BTC
        self._window_size = config["input"]["window_size"]
        self._coin_number = config["input"]["coin_number"]
        self._commission_rate = config["trading"]["trading_consumption"]
        self._fake_ratio = config["input"]["fake_ratio"]
        self._asset_vector = np.zeros(self._coin_number+1)

        self._last_omega = np.zeros((self._coin_number+1,))
        self._last_omega[0] = 1.0

        if self.__class__.__name__=="BackTest":
            # self._initialize_logging_data_frame(initial_BTC)
            self._logging_data_frame = None
            # self._disk_engine =  sqlite3.connect('./database/back_time_trading_log.db')
            # self._initialize_data_base()
        self._current_error_state = 'S000'
        self._current_error_info = ''

    def _initialize_logging_data_frame(self, initial_BTC):
        logging_dict = {'Total Asset (BTC)': initial_BTC, 'BTC': 1}
        for coin in self._coin_name_list:
            logging_dict[coin] = 0
        self._logging_data_frame = pd.DataFrame(logging_dict, index=pd.to_datetime([time.time()], unit='s'))

    def generate_history_matrix(self):
        """override this method to generate the input of agent
        """
        pass

    def finish_trading(self):
        pass

    # add trading data into the pandas data frame
    def _log_trading_info(self, time, omega):
        time_index = pd.to_datetime([time], unit='s')
        if self._steps > 0:
            logging_dict = {'Total Asset (BTC)': self._total_capital, 'BTC': omega[0, 0]}
            for i in range(len(self._coin_name_list)):
                logging_dict[self._coin_name_list[i]] = omega[0, i + 1]
            new_data_frame = pd.DataFrame(logging_dict, index=time_index)
            self._logging_data_frame = self._logging_data_frame.append(new_data_frame)

    def trade_by_strategy(self, omega):
        """execute the trading to the position, represented by the portfolio vector w
        """
        pass

    def rolling_train(self):
        """
        execute rolling train
        """
        pass

    def __trade_body(self):
        self._current_error_state = 'S000'
        starttime = time.time()
        omega = self._agent.decide_by_history(self.generate_history_matrix(),
                                              self._last_omega.copy())
        self.trade_by_strategy(omega)
        if self._agent_type == "nn":
            self.rolling_train()
        if not self.__class__.__name__=="BackTest":
            self._last_omega = omega.copy()
        logging.info('total assets are %3f BTC' % self._total_capital)
        logging.debug("="*30)
        trading_time = time.time() - starttime
        if trading_time < self._period:
            logging.info("sleep for %s seconds" % (self._period - trading_time))
        self._steps += 1
        return self._period - trading_time

    def start_trading(self):
        try:
            if not self.__class__.__name__=="BackTest":
                current = int(time.time())
                wait = self._period - (current%self._period)
                logging.info("sleep for %s seconds" % wait)
                time.sleep(wait+2)

                while self._steps < self._total_steps:
                    sleeptime = self.__trade_body()
                    time.sleep(sleeptime)
            else:
                while self._steps < self._total_steps:
                    self.__trade_body()
        finally:
            # if self._agent_type=="nn":
                # self._agent.recycle()
            self.finish_trading()


### FILE: policies/networks.py
----------------------------------------
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.distributions import Categorical
import math

from policies.NRI.utils import *
from policies.NRI.modules import *

from policies.utils import *

import numpy as np

class CNN(nn.Module):
    def __init__(self, num_inputs, num_action, n):
        super(CNN, self).__init__()

        self.window_size = 31
        self.num_inputs = num_inputs
        self.num_action = num_action
        D1 = 3
        D2 = 10
        self.conv1 = nn.Conv2d(self.num_inputs, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.window_size-1))


        self.conv3 = nn.Conv2d(D2+n, 1, kernel_size=(1, 1))
        self.bias = nn.Parameter(torch.zeros(1))
        
        self.optimizer = optim.AdamW([
            dict(params=[*self.conv1.parameters(),
                         self.bias]),
            dict(params=self.conv2.parameters(),
                 weight_decay=5e-9), # L2 reg
           dict(params=self.conv3.parameters(),
                 weight_decay=5e-8), # L2 reg
        ], lr=0.00028)


    def forward(self, x, last_action, pred=None):
        B = x.shape[0]
        x = x / x[:, 0, None, :, -1, None] 
        x = self.conv1(x)  
        x = torch.relu(x)
        x = self.conv2(x)  
        x = torch.relu(x)
        re = x
        prev_w = last_action.view(B, 1, self.num_action-1, 1) 
        if pred is not None:
            pred = pred.view(B, 1, self.num_action-1, 1)
            x = torch.cat([x, prev_w, pred], 1) 
        else:
            x = torch.cat([x, prev_w], 1) 
        x = self.conv3(x) 
        x = torch.cat([
            self.bias.repeat(B, 1),  # (B, 1)
            x[:, 0, :, 0]  # (B, C)
        ], 1)  # (B, 1+C)
        x = torch.softmax(x, -1)  # (B, 1+C)
        return x.squeeze(0), re

class SARL_net(nn.Module):
    def __init__(self, num_inputs, num_action):
        super(SARL_net, self).__init__()
        self.num_inputs = num_inputs
        self.window_size = 31
        self.num_action = num_action
        
        D1 = 3
        D2 = 10

        self.conv1 = nn.Conv2d(self.num_inputs, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.window_size-1))


        self.conv3 = nn.Conv2d(D2, 2, kernel_size=(1, 1))

        self.optimizer = optim.AdamW([
            dict(params=self.conv1.parameters(),
                                    ),
            dict(params=self.conv2.parameters(),
                 weight_decay=5e-9), # L2 reg
           dict(params=self.conv3.parameters(),
                 weight_decay=5e-8), # L2 reg
                ], lr=0.00028)

    def forward(self, x):
        B = x.shape[0]

        x = x / x[:, 0, None, :, -1, None] 

        x = self.conv1(x)  
        x = torch.relu(x)

        x = self.conv2(x) 

        x = torch.relu(x)
        re = x
        x = self.conv3(x)  
        x = x[:,:,:,0]
        x = torch.softmax(x, 1)  
        return x, re

    def sarl_train_net(self, x, y, last_w, y_cont, device):
        x, y, last_w, y_cont = get_tensor(x, y, last_w, y_cont, device)
        pred , _ = self(x)
        targets = (y<=1).float()
        
        self.optimizer.zero_grad()
        loss=0
        loss_fn=nn.BCELoss()
        for i in range(pred.shape[2]):
            loss += loss_fn(pred[:,0,i],targets[:,0,i])
        loss.backward()
        self.optimizer.step()
        return loss.item()

class SARL_net_conv4(nn.Module):
    def __init__(self, num_inputs, num_action):
        super(SARL_net_conv4, self).__init__()
        self.num_inputs = num_inputs
        self.window_size = 31
        self.num_action = num_action
        self.hidden_dim = 64

        self.hidden_dim1 = 32
        D1 = 50
        D2 = 25

        self.conv1 = nn.Conv2d(self.num_inputs, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.window_size-1))
        self.conv2_5 = nn.Conv2d(1, self.num_action-1 , kernel_size=(self.num_action-1, 1))
        self.conv2_5_ = nn.Conv2d(1, self.num_action-1 , kernel_size=(self.num_action-1, 1))
        self.conv3 = nn.Conv2d(D2, 15, kernel_size=(1, 1))
        self.conv4 = nn.Conv2d(15, 2, kernel_size=(1, 1))

        self.bias = nn.Parameter(torch.zeros(1))
        self.leakyrelu = nn.LeakyReLU()
        self.optimizer = optim.AdamW([
                dict(params=[*self.conv1.parameters(),
                                self.bias,
                            ]),
                dict(params=self.conv2.parameters(),
                    weight_decay=5e-9), # L2 reg
                dict(params=self.conv3.parameters(),
                    weight_decay=5e-8), # L2 reg
                dict(params=self.conv2_5.parameters(),
                    weight_decay=5e-9),
                dict(params=self.conv4.parameters(),
                    weight_decay=5e-8),
            ], lr=0.00015)


    def forward(self, x):
        B = x.shape[0]
        x = x / x[:, 0, None, :, -1, None] # normalize???

        x = self.conv1(x)  # (B, 3, C, W-1)
        x = torch.relu(x)

        x = self.conv2(x)  # (B, 10, C, 1)
        x = torch.relu(x)
        re = x
        x = self.conv3(x)  # (B, 1, C, 1)
        x = self.conv4(x)
        x = x[:,:,:,0]
        x = torch.softmax(x, 1)  # (B, 1+C)

        return x, re

    def sarl_train_net(self,x, y, last_w,  y_cont, device):
        x, y, last_w, y_cont = get_tensor(x, y, last_w, y_cont, device)
        pred , _ = self(x)
        targets = (y<=1).float()
        

        self.optimizer.zero_grad()
        loss=0
        loss_fn=nn.BCELoss()
        for i in range(pred.shape[2]):
            loss += loss_fn(pred[:,0,i],targets[:,0,i])
        loss.backward()
        self.optimizer.step()
        return loss.item()

class SARL_net_conv4_stock(nn.Module):
    def __init__(self, num_inputs, num_action):
        super(SARL_net_conv4_stock, self).__init__()
        self.num_inputs = num_inputs
        self.window_size = 31
        self.num_action = num_action
        self.hidden_dim = 64

        self.hidden_dim1 = 32
        D1 = 50
        D2 = 25

        self.conv1 = nn.Conv2d(self.num_inputs, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.window_size-1))
        self.conv2_5 = nn.Conv2d(1, self.num_action-1 , kernel_size=(self.num_action-1, 1))
        self.conv2_5_ = nn.Conv2d(1, self.num_action-1 , kernel_size=(self.num_action-1, 1))
        self.conv3 = nn.Conv2d(D2, 15, kernel_size=(1, 1))
        self.conv4 = nn.Conv2d(15, 2, kernel_size=(1, 1))

        self.bias = nn.Parameter(torch.zeros(1))
        self.leakyrelu = nn.LeakyReLU()
        self.optimizer = optim.AdamW([
                dict(params=[*self.conv1.parameters(),
                                self.bias,
                            ]),
                dict(params=self.conv2.parameters(),
                    weight_decay=5e-9), # L2 reg
                dict(params=self.conv3.parameters(),
                    weight_decay=5e-8), # L2 reg
                dict(params=self.conv2_5.parameters(),
                    weight_decay=5e-9),
                dict(params=self.conv4.parameters(),
                    weight_decay=5e-8),
            ], lr=0.00015)


    def forward(self, x):
        B = x.shape[0]
        x = x / x[:, 0, None, :, -1, None] # normalize???

        x = self.conv1(x)  # (B, 3, C, W-1)
        x = self.leakyrelu(x)

        x = self.conv2(x)  # (B, 10, C, 1)
        

        x = x.transpose(1,3)
        x = self.conv2_5(x)
        x = x.permute(0,3,1,2)

        re = x
        x = self.leakyrelu(x)

        x = self.conv3(x)  # (B, 1, C, 1)
        x = self.conv4(x)
        x = x[:,:,:,0]
        x = torch.softmax(x, 1)  # (B, 1+C)
        return x, re

    def sarl_train_net(self,x, y, last_w,  y_cont, device):
        x, y, last_w, y_cont = get_tensor(x, y, last_w, y_cont, device)
        pred , _ = self(x)
        targets = (y<=1).float()
        
        self.optimizer.zero_grad()
        loss=0
        loss_fn=nn.BCELoss()
        for i in range(pred.shape[2]):
            loss += loss_fn(pred[:,0,i],targets[:,0,i])
        loss.backward()
        self.optimizer.step()
        return loss.item()

class CNN_conv4(nn.Module):
    def __init__(self, num_inputs, action_n, lr=0.001, n_episode_batch=5, nri_d=32, cnn_d=10, shuffle=1, shift=False, nri_lr=0.0005, cnn_d2=15, n=1):
        super(CNN_conv4, self).__init__()
        self.num_inputs = num_inputs
        self.window_size = 31
        self.num_action = action_n
        self.shuffle = shuffle
        self.pre = shift

        D1 = cnn_d
        D2 = cnn_d2 #15

        self.conv1 = nn.Conv2d(self.num_inputs, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.window_size-1))
        self.conv2_5 = nn.Conv2d(1, self.num_action-1 , kernel_size=(self.num_action-1, 1))

        self.conv3 = nn.Conv2d(D2+n, 15, kernel_size=(1, 1))
        self.conv4 = nn.Conv2d(15, 1, kernel_size=(1, 1))

        self.bias = nn.Parameter(torch.zeros(1))
        self.leakyrelu = nn.LeakyReLU()

        self.optimizer = optim.AdamW([
            dict(params=[*self.conv1.parameters(),
                            self.bias,
                         ]),
            dict(params=self.conv2.parameters(),
                 weight_decay=5e-9), # L2 reg
            dict(params=self.conv3.parameters(),
                 weight_decay=5e-8), # L2 reg
            dict(params=self.conv2_5.parameters(),
                 weight_decay=5e-9),
            dict(params=self.conv4.parameters(),
                 weight_decay=5e-8),
        ], lr=lr)
    def forward(self, x, last_action, pred=None):
        B = x.shape[0]
        if self.pre:
            x = (x - x[:, 0, None, :, -1, None])/ x[:, 0, None, :, -1, None] 
        else:
            x = (x )/ x[:, 0, None, :, -1, None] 


        x = self.conv1(x)  
        x = torch.relu(x)
        x = self.conv2(x) 
        re = x
        re[re != re] = 0
        x = torch.relu(x)
        
        prev_w = last_action.view(B, 1, self.num_action-1, 1) 
        if pred is not None:
            pred = pred.view(B, 1, self.num_action-1, 1)
            x = torch.cat([x, prev_w, pred], 1) 
        else:
            x = torch.cat([x, prev_w], 1)  
        x = self.conv3(x)
        x = self.conv4(x)  
        x = torch.cat([
            self.bias.repeat(B, 1),  # (B, 1)
            x[:, 0, :, 0]  # (B, C)
        ], 1)  # (B, 1+C)
    
        x[x != x] = 0
        x = torch.softmax(x, -1)  # (B, 1+C)
        return x, re

class CNN_conv4_stock(nn.Module):
    def __init__(self, num_inputs, action_n, lr=0.001, n_episode_batch=5, nri_d=32, cnn_d=10, shuffle=1, shift=False, nri_lr=0.0005, cnn_d2=15, n=1):
        super(CNN_conv4_stock, self).__init__()
        self.num_inputs = num_inputs
        self.window_size = 31
        self.num_action = action_n
        self.shuffle = shuffle
        self.pre = shift

        D1 = cnn_d
        D2 = cnn_d2 #15

        self.conv1 = nn.Conv2d(self.num_inputs, D1, kernel_size=(1, 2))
        self.conv2 = nn.Conv2d(D1, D2, kernel_size=(1, self.window_size-1))
        self.conv2_5 = nn.Conv2d(1, self.num_action-1 , kernel_size=(self.num_action-1, 1))

        self.conv3 = nn.Conv2d(D2+n, 15, kernel_size=(1, 1))
        self.conv4 = nn.Conv2d(15, self.num_action, kernel_size=(self.num_action-1, 1))
        self.bias = nn.Parameter(torch.zeros(1))
        self.leakyrelu = nn.LeakyReLU()

        self.optimizer = optim.AdamW([
            dict(params=[*self.conv1.parameters(),
                            self.bias,
                         ]),
            dict(params=self.conv2.parameters(),
                 weight_decay=5e-9), # L2 reg
            dict(params=self.conv3.parameters(),
                 weight_decay=5e-8), # L2 reg
            dict(params=self.conv2_5.parameters(),
                 weight_decay=5e-9),
            dict(params=self.conv4.parameters(),
                 weight_decay=5e-8),
        ], lr=lr)
    def forward(self, x, last_action, pred=None):
        B = x.shape[0]
        if self.pre:
            x = (x - x[:, 0, None, :, -1, None])/ x[:, 0, None, :, -1, None] 
        else:
            x = (x )/ x[:, 0, None, :, -1, None] 


        x = self.conv1(x)  
        x = self.leakyrelu(x)
        
        x = self.conv2(x)  
        x = x.transpose(1,3)
        x = self.conv2_5(x)
        x = x.permute(0,3,1,2)
        re = x
        re[re != re] = 0
        x = self.leakyrelu(x)

        prev_w = last_action.view(B, 1, self.num_action-1, 1) 
        if pred is not None:
            pred = pred.view(B, 1, self.num_action-1, 1)
            x = torch.cat([x, prev_w, pred], 1) 
        else:
            x = torch.cat([x, prev_w], 1)  
        
        x = self.conv3(x)
        x = self.conv4(x)  

        x = x[:, :, 0, 0]
        x[x != x] = 0
        x = torch.softmax(x, -1)  
        return x, re

class NRI_net(nn.Module):
    def __init__(self, num_inputs, action_n, lr=0.001, n_episode_batch=5, nri_d=32, cnn_d=10, shuffle=1, shift=False, nri_lr=0.0005, cnn_d2=15):
        super(NRI_net, self).__init__()
        self.num_inputs = num_inputs
        self.window_size = 31
        self.num_action = action_n
        self.shuffle = shuffle

        self.encoder = MLPEncoder(self.window_size * self.num_inputs, nri_d, 2, 0, False)

        self.decoder = MLPDecoder(n_in_node=self.num_inputs,edge_types=2,
                                    msg_hid=nri_d,
                                    msg_out=nri_d,
                                    n_hid=nri_d,
                                    do_prob=0,
                                    skip_first=True)



        self.nri_optimizer = optim.AdamW(list(self.encoder.parameters()) + list(self.decoder.parameters()),
                       weight_decay=5e-8,lr=nri_lr)
        self.nri_scheduler = optim.lr_scheduler.StepLR(self.nri_optimizer, step_size=200,
                                        gamma=0.5)


        self.batch_size = int(n_episode_batch/self.shuffle)

        self.off_diag = np.ones([self.batch_size, self.batch_size]) - np.eye(self.batch_size)


        self.rel_rec = np.array(encode_onehot(np.where(self.off_diag)[0]), dtype=np.float32)
        self.rel_send = np.array(encode_onehot(np.where(self.off_diag)[1]), dtype=np.float32)
        self.rel_rec = torch.FloatTensor(self.rel_rec)
        self.rel_send = torch.FloatTensor(self.rel_send)


        self.triu_indices = get_triu_offdiag_indices(self.batch_size)
        self.tril_indices = get_tril_offdiag_indices(self.batch_size)
        
    def train_nri(self, data):
        self.encoder.train()
        self.decoder.train()
        self.nri_optimizer.zero_grad()

        logits = self.encoder(data, self.rel_rec.to(data.device), self.rel_send.to(data.device))
        edges = gumbel_softmax(logits, tau=0.5, hard=False)
        prob = my_softmax(logits, -1)

        output = self.decoder(data, edges, self.rel_rec.to(data.device), self.rel_send.to(data.device), 1)

        target = data[:, :, 1:, :]

        loss_nll = nll_gaussian(output, target, 5e-5)

        loss_kl = kl_categorical_uniform(prob, self.batch_size, 2)

        loss = loss_nll + loss_kl
        loss.backward()
        self.nri_optimizer.step()
        self.nri_scheduler.step()
        return loss_nll.item(), loss_kl.item() 

    def nriLoss(self, emb, x, temperature=0.05):
        B = emb.shape[0]
        C = emb.shape[2]

        x = x.transpose(1,2).transpose(2,3).transpose(0,1)
        emb = emb.transpose(1,2).transpose(0,1).squeeze(-1)
        emb = F.normalize(emb)
        if self.shuffle > 1:
            perm = torch.randperm(B*C)
            x = x.reshape(B*C, self.window_size, -1)
            emb = emb.reshape(B*C, -1)
            B=int(B/self.shuffle)
            C=C*self.shuffle
            x = x[perm,:,:].reshape(C,B,self.window_size, -1)
            emb = emb[perm,:].reshape(C,B,-1)

        with torch.no_grad():
            logits = self.encoder(x, self.rel_rec, self.rel_send)
            edges = gumbel_softmax(logits, tau=0.5, hard=True)

        contrastiveGraph1 = edges[:,:,0].reshape(C,B, -1)
        contrastiveGraph2 = edges[:,:,1].reshape(C,B, -1)
        
        similarity = torch.matmul(emb, emb.transpose(1,2))
        max1 = torch.max(contrastiveGraph1, dim=2, keepdim=True)[0]
        max2 = torch.max(contrastiveGraph2, dim=2, keepdim=True)[0]

        off_diag_idx = np.ravel_multi_index(
            np.where(np.ones((B, B)) - np.eye(B)),
            [B, B])
        similarity = similarity.reshape(C, -1)
        similarity = similarity[:, off_diag_idx].reshape(C,B, -1)
        sim_max = torch.max(similarity, dim=2, keepdim=True)[0].detach()
        similarity = similarity-sim_max
        
        positives1 = (contrastiveGraph1.ge(max1)/contrastiveGraph1.ge(max1).sum(-1).unsqueeze(2))*similarity #positive torch.Size([10, 300, 1])
        positives2 = (contrastiveGraph2.ge(max2)/contrastiveGraph2.ge(max2).sum(-1).unsqueeze(2))*similarity #positive torch.Size([10, 300, 1])


        nominator1 = torch.exp(positives1 / temperature).sum(-1)
        nominator2 = torch.exp(positives2 / temperature).sum(-1)


        denominator = torch.exp(similarity / temperature).sum(-1) #


        contrastive = -torch.log(nominator1 / denominator) -torch.log(nominator2 / denominator)

        loss = torch.sum(contrastive)

        nll, kl = self.train_nri(x)
        return loss / (B*C*2), nll, kl



### FILE: policies/NRI/__init__.py
----------------------------------------


### FILE: policies/NRI/modules.py
----------------------------------------
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

from torch.autograd import Variable
from policies.NRI.utils import my_softmax, get_offdiag_indices, gumbel_softmax

_EPS = 1e-10


class MLP(nn.Module):
    """Two-layer fully-connected ELU net with batch norm."""

    def __init__(self, n_in, n_hid, n_out, do_prob=0.):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(n_in, n_hid)
        self.fc2 = nn.Linear(n_hid, n_out)
        self.bn = nn.BatchNorm1d(n_out)
        self.dropout_prob = do_prob

        self.init_weights()

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_normal(m.weight.data)
                m.bias.data.fill_(0.1)
            elif isinstance(m, nn.BatchNorm1d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

    def batch_norm(self, inputs):
        x = inputs.view(inputs.size(0) * inputs.size(1), -1)
        x = self.bn(x)
        return x.view(inputs.size(0), inputs.size(1), -1)

    def forward(self, inputs):
        # Input shape: [num_sims, num_things, num_features]
        x = F.elu(self.fc1(inputs))
        x = F.dropout(x, self.dropout_prob, training=self.training)
        x = F.elu(self.fc2(x))
        return self.batch_norm(x)


class CNN(nn.Module):
    def __init__(self, n_in, n_hid, n_out, do_prob=0.):
        super(CNN, self).__init__()
        self.pool = nn.MaxPool1d(kernel_size=2, stride=None, padding=0,
                                 dilation=1, return_indices=False,
                                 ceil_mode=False)

        self.conv1 = nn.Conv1d(n_in, n_hid, kernel_size=5, stride=1, padding=0)
        self.bn1 = nn.BatchNorm1d(n_hid)
        self.conv2 = nn.Conv1d(n_hid, n_hid, kernel_size=5, stride=1, padding=0)
        self.bn2 = nn.BatchNorm1d(n_hid)
        self.conv_predict = nn.Conv1d(n_hid, n_out, kernel_size=1)
        self.conv_attention = nn.Conv1d(n_hid, 1, kernel_size=1)
        self.dropout_prob = do_prob

        self.init_weights()

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                n = m.kernel_size[0] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                m.bias.data.fill_(0.1)
            elif isinstance(m, nn.BatchNorm1d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

    def forward(self, inputs):
        # Input shape: [num_sims * num_edges, num_dims, num_timesteps]

        x = F.relu(self.conv1(inputs))
        x = self.bn1(x)
        x = F.dropout(x, self.dropout_prob, training=self.training)
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.bn2(x)
        pred = self.conv_predict(x)
        attention = my_softmax(self.conv_attention(x), axis=2)

        edge_prob = (pred * attention).mean(dim=2)
        return edge_prob


class MLPEncoder(nn.Module):
    def __init__(self, n_in, n_hid, n_out, do_prob=0., factor=True):
        super(MLPEncoder, self).__init__()

        self.factor = factor

        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)
        self.mlp2 = MLP(n_hid * 2, n_hid, n_hid, do_prob)
        self.mlp3 = MLP(n_hid, n_hid, n_hid, do_prob)
        if self.factor:
            self.mlp4 = MLP(n_hid * 3, n_hid, n_hid, do_prob)
            print("Using factor graph MLP encoder.")
        else:
            self.mlp4 = MLP(n_hid * 2, n_hid, n_hid, do_prob)
            print("Using MLP encoder.")
        self.fc_out = nn.Linear(n_hid, n_out)
        self.init_weights()

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_normal(m.weight.data)
                m.bias.data.fill_(0.1)

    def edge2node(self, x, rel_rec, rel_send):
        # NOTE: Assumes that we have the same graph across all samples.
        incoming = torch.matmul(rel_rec.t(), x)
        return incoming / incoming.size(1)

    def node2edge(self, x, rel_rec, rel_send):
        # NOTE: Assumes that we have the same graph across all samples.
        # NOTE: print("node2edge","x.shape, rel_rec.shape",x.shape, rel_rec.shape)
        # NOTE: node2edge x.shape, rel_rec.shape torch.Size([1, 3000, 256]) torch.Size([89700, 300])

        receivers = torch.matmul(rel_rec, x)
        senders = torch.matmul(rel_send, x)
        edges = torch.cat([senders, receivers], dim=2)
        return edges

    def forward(self, inputs, rel_rec, rel_send):
        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]
        #x = inputs.view(inputs.size(0), inputs.size(1), -1)
        x = inputs.reshape(inputs.size(0), inputs.size(1), -1)
        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]

        x = self.mlp1(x)  # 2-layer ELU net per node
        rel_rec = rel_rec.to(inputs.device)
        rel_send = rel_send.to(inputs.device)

        x = self.node2edge(x, rel_rec, rel_send)
        x = self.mlp2(x)
        x_skip = x

        if self.factor:
            x = self.edge2node(x, rel_rec, rel_send)
            x = self.mlp3(x)
            x = self.node2edge(x, rel_rec, rel_send)
            x = torch.cat((x, x_skip), dim=2)  # Skip connection
            x = self.mlp4(x)
        else:
            x = self.mlp3(x)
            x = torch.cat((x, x_skip), dim=2)  # Skip connection
            x = self.mlp4(x)

        return self.fc_out(x)


class CNNEncoder(nn.Module):
    def __init__(self, n_in, n_hid, n_out, do_prob=0., factor=True):
        super(CNNEncoder, self).__init__()
        self.dropout_prob = do_prob

        self.factor = factor

        self.cnn = CNN(n_in * 2, n_hid, n_hid, do_prob)
        self.mlp1 = MLP(n_hid, n_hid, n_hid, do_prob)
        self.mlp2 = MLP(n_hid, n_hid, n_hid, do_prob)
        self.mlp3 = MLP(n_hid * 3, n_hid, n_hid, do_prob)
        self.fc_out = nn.Linear(n_hid, n_out)

        if self.factor:
            print("Using factor graph CNN encoder.")
        else:
            print("Using CNN encoder.")

        self.init_weights()

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_normal(m.weight.data)
                m.bias.data.fill_(0.1)

    def node2edge_temporal(self, inputs, rel_rec, rel_send):
        # NOTE: Assumes that we have the same graph across all samples.

        x = inputs.view(inputs.size(0), inputs.size(1), -1)

        receivers = torch.matmul(rel_rec, x)
        receivers = receivers.view(inputs.size(0) * receivers.size(1),
                                   inputs.size(2), inputs.size(3))
        receivers = receivers.transpose(2, 1)

        senders = torch.matmul(rel_send, x)
        senders = senders.view(inputs.size(0) * senders.size(1),
                               inputs.size(2),
                               inputs.size(3))
        senders = senders.transpose(2, 1)

        # receivers and senders have shape:
        # [num_sims * num_edges, num_dims, num_timesteps]
        edges = torch.cat([senders, receivers], dim=1)
        return edges

    def edge2node(self, x, rel_rec, rel_send):
        # NOTE: Assumes that we have the same graph across all samples.
        incoming = torch.matmul(rel_rec.t(), x)
        return incoming / incoming.size(1)

    def node2edge(self, x, rel_rec, rel_send):
        # NOTE: Assumes that we have the same graph across all samples.
        receivers = torch.matmul(rel_rec, x)
        senders = torch.matmul(rel_send, x)
        edges = torch.cat([senders, receivers], dim=2)
        return edges

    def forward(self, inputs, rel_rec, rel_send):

        # Input has shape: [num_sims, num_atoms, num_timesteps, num_dims]
        edges = self.node2edge_temporal(inputs, rel_rec, rel_send)
        x = self.cnn(edges)
        x = x.view(inputs.size(0), (inputs.size(1) - 1) * inputs.size(1), -1)
        x = self.mlp1(x)
        x_skip = x

        if self.factor:
            x = self.edge2node(x, rel_rec, rel_send)
            x = self.mlp2(x)

            x = self.node2edge(x, rel_rec, rel_send)
            x = torch.cat((x, x_skip), dim=2)  # Skip connection
            x = self.mlp3(x)

        return self.fc_out(x)


class SimulationDecoder(nn.Module):
    """Simulation-based decoder."""

    def __init__(self, loc_max, loc_min, vel_max, vel_min, suffix):
        super(SimulationDecoder, self).__init__()

        self.loc_max = loc_max
        self.loc_min = loc_min
        self.vel_max = vel_max
        self.vel_min = vel_min

        self.interaction_type = suffix

        if '_springs' in self.interaction_type:
            print('Using spring simulation decoder.')
            self.interaction_strength = .1
            self.sample_freq = 1
            self._delta_T = 0.1
            self.box_size = 5.
        elif '_charged' in self.interaction_type:
            print('Using charged particle simulation decoder.')
            self.interaction_strength = 1.
            self.sample_freq = 100
            self._delta_T = 0.001
            self.box_size = 5.
        elif '_charged_short' in self.interaction_type:
            print('Using charged particle simulation decoder.')
            self.interaction_strength = .1
            self.sample_freq = 10
            self._delta_T = 0.001
            self.box_size = 1.
        else:
            print("Simulation type could not be inferred from suffix.")

        self.out = None

        # NOTE: For exact reproduction, choose sample_freq=100, delta_T=0.001

        self._max_F = 0.1 / self._delta_T

    def unnormalize(self, loc, vel):
        loc = 0.5 * (loc + 1) * (self.loc_max - self.loc_min) + self.loc_min
        vel = 0.5 * (vel + 1) * (self.vel_max - self.vel_min) + self.vel_min
        return loc, vel

    def renormalize(self, loc, vel):
        loc = 2 * (loc - self.loc_min) / (self.loc_max - self.loc_min) - 1
        vel = 2 * (vel - self.vel_min) / (self.vel_max - self.vel_min) - 1
        return loc, vel

    def clamp(self, loc, vel):
        over = loc > self.box_size
        loc[over] = 2 * self.box_size - loc[over]
        vel[over] = -torch.abs(vel[over])

        under = loc < -self.box_size
        loc[under] = -2 * self.box_size - loc[under]
        vel[under] = torch.abs(vel[under])

        return loc, vel

    def set_diag_to_zero(self, x):
        """Hack to set diagonal of a tensor to zero."""
        mask = torch.diag(torch.ones(x.size(1))).unsqueeze(0).expand_as(x)
        inverse_mask = torch.ones(x.size(1), x.size(1)) - mask
        if x.is_cuda:
            inverse_mask = inverse_mask.cuda()
        inverse_mask = Variable(inverse_mask)
        return inverse_mask * x

    def set_diag_to_one(self, x):
        """Hack to set diagonal of a tensor to one."""
        mask = torch.diag(torch.ones(x.size(1))).unsqueeze(0).expand_as(x)
        inverse_mask = torch.ones(x.size(1), x.size(1)) - mask
        if x.is_cuda:
            mask, inverse_mask = mask.cuda(), inverse_mask.cuda()
        mask, inverse_mask = Variable(mask), Variable(inverse_mask)
        return mask + inverse_mask * x

    def pairwise_sq_dist(self, x):
        xx = torch.bmm(x, x.transpose(1, 2))
        rx = (x ** 2).sum(2).unsqueeze(-1).expand_as(xx)
        return torch.abs(rx.transpose(1, 2) + rx - 2 * xx)

    def forward(self, inputs, relations, rel_rec, rel_send, pred_steps=1):
        # Input has shape: [num_sims, num_things, num_timesteps, num_dims]
        # Relation mx shape: [num_sims, num_things*num_things]

        # Only keep single dimension of softmax output
        relations = relations[:, :, 1]

        loc = inputs[:, :, :-1, :2].contiguous()
        vel = inputs[:, :, :-1, 2:].contiguous()

        # Broadcasting/shape tricks for parallel processing of time steps
        loc = loc.permute(0, 2, 1, 3).contiguous()
        vel = vel.permute(0, 2, 1, 3).contiguous()
        loc = loc.view(inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2)
        vel = vel.view(inputs.size(0) * (inputs.size(2) - 1), inputs.size(1), 2)

        loc, vel = self.unnormalize(loc, vel)

        offdiag_indices = get_offdiag_indices(inputs.size(1))
        edges = Variable(torch.zeros(relations.size(0), inputs.size(1) *
                                     inputs.size(1)))
        if inputs.is_cuda:
            edges = edges.cuda()
            offdiag_indices = offdiag_indices.cuda()

        edges[:, offdiag_indices] = relations.float()

        edges = edges.view(relations.size(0), inputs.size(1),
                           inputs.size(1))

        self.out = []

        for _ in range(0, self.sample_freq):
            x = loc[:, :, 0].unsqueeze(-1)
            y = loc[:, :, 1].unsqueeze(-1)

            xx = x.expand(x.size(0), x.size(1), x.size(1))
            yy = y.expand(y.size(0), y.size(1), y.size(1))
            dist_x = xx - xx.transpose(1, 2)
            dist_y = yy - yy.transpose(1, 2)

            if '_springs' in self.interaction_type:
                forces_size = -self.interaction_strength * edges
                pair_dist = torch.cat(
                    (dist_x.unsqueeze(-1), dist_y.unsqueeze(-1)),
                    -1)

                # Tricks for parallel processing of time steps
                pair_dist = pair_dist.view(inputs.size(0), (inputs.size(2) - 1),
                                           inputs.size(1), inputs.size(1), 2)
                forces = (
                        forces_size.unsqueeze(-1).unsqueeze(1) * pair_dist).sum(
                    3)
            else:  # charged particle sim
                e = (-1) * (edges * 2 - 1)
                forces_size = -self.interaction_strength * e

                l2_dist_power3 = torch.pow(self.pairwise_sq_dist(loc), 3. / 2.)
                l2_dist_power3 = self.set_diag_to_one(l2_dist_power3)

                l2_dist_power3 = l2_dist_power3.view(inputs.size(0),
                                                     (inputs.size(2) - 1),
                                                     inputs.size(1),
                                                     inputs.size(1))
                forces_size = forces_size.unsqueeze(1) / (l2_dist_power3 + _EPS)

                pair_dist = torch.cat(
                    (dist_x.unsqueeze(-1), dist_y.unsqueeze(-1)),
                    -1)
                pair_dist = pair_dist.view(inputs.size(0), (inputs.size(2) - 1),
                                           inputs.size(1), inputs.size(1), 2)
                forces = (forces_size.unsqueeze(-1) * pair_dist).sum(3)

            forces = forces.view(inputs.size(0) * (inputs.size(2) - 1),
                                 inputs.size(1), 2)

            if '_charged' in self.interaction_type:  # charged particle sim
                # Clip forces
                forces[forces > self._max_F] = self._max_F
                forces[forces < -self._max_F] = -self._max_F

            # Leapfrog integration step
            vel = vel + self._delta_T * forces
            loc = loc + self._delta_T * vel

            # Handle box boundaries
            loc, vel = self.clamp(loc, vel)

        loc, vel = self.renormalize(loc, vel)

        loc = loc.view(inputs.size(0), (inputs.size(2) - 1), inputs.size(1), 2)
        vel = vel.view(inputs.size(0), (inputs.size(2) - 1), inputs.size(1), 2)

        loc = loc.permute(0, 2, 1, 3)
        vel = vel.permute(0, 2, 1, 3)

        out = torch.cat((loc, vel), dim=-1)
        # Output has shape: [num_sims, num_things, num_timesteps-1, num_dims]

        return out


class MLPDecoder(nn.Module):
    """MLP decoder module."""

    def __init__(self, n_in_node, edge_types, msg_hid, msg_out, n_hid,
                 do_prob=0., skip_first=False):
        super(MLPDecoder, self).__init__()
        self.msg_fc1 = nn.ModuleList(
            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)])
        self.msg_fc2 = nn.ModuleList(
            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])
        self.msg_out_shape = msg_out
        self.skip_first_edge_type = skip_first

        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)
        self.out_fc2 = nn.Linear(n_hid, n_hid)
        self.out_fc3 = nn.Linear(n_hid, n_in_node)

        print('Using learned interaction net decoder.')

        self.dropout_prob = do_prob

    def single_step_forward(self, single_timestep_inputs, rel_rec, rel_send,
                            single_timestep_rel_type):

        # single_timestep_inputs has shape
        # [batch_size, num_timesteps, num_atoms, num_dims]

        # single_timestep_rel_type has shape:
        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]

        # Node2edge
        receivers = torch.matmul(rel_rec, single_timestep_inputs)
        #print("single_step", "rel_rec.shape",rel_rec.shape, "single_timestep_inputs", single_timestep_inputs.shape, "receivers", receivers.shape)
        senders = torch.matmul(rel_send, single_timestep_inputs)
        pre_msg = torch.cat([senders, receivers], dim=-1)

        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),
                                        pre_msg.size(2), self.msg_out_shape))
        if single_timestep_inputs.is_cuda:
            all_msgs = all_msgs.cuda()

        if self.skip_first_edge_type:
            start_idx = 1
        else:
            start_idx = 0

        # Run separate MLP for every edge type
        # NOTE: To exlude one edge type, simply offset range by 1
        for i in range(start_idx, len(self.msg_fc2)):
            msg = F.relu(self.msg_fc1[i](pre_msg))
            msg = F.dropout(msg, p=self.dropout_prob)
            msg = F.relu(self.msg_fc2[i](msg))
            msg = msg * single_timestep_rel_type[:, :, :, i:i + 1]
            all_msgs += msg

        # Aggregate all msgs to receiver
        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)
        agg_msgs = agg_msgs.contiguous()

        # Skip connection
        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)

        # Output MLP
        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)
        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)
        pred = self.out_fc3(pred)

        # Predict position/velocity difference
        return single_timestep_inputs + pred

    def forward(self, inputs, rel_type, rel_rec, rel_send, pred_steps=1):
        # NOTE: Assumes that we have the same graph across all samples.
        # inputs [num_sims, num_atoms, num_timesteps, num_dims]
        #print("decoder","inputs",inputs.shape,"rel_type",rel_type.shape)
        #decoder inputs torch.Size([128, 5, 49, 4]) rel_type torch.Size([128, 20, 2])

        inputs = inputs.transpose(1, 2).contiguous()

        # inputs [num_sims, num_timesteps, num_atoms, num_dims]


        sizes = [rel_type.size(0), inputs.size(1), rel_type.size(1),
                 rel_type.size(2)]
        #print("decoder","sizes", sizes)
        #decoder sizes [128, 49, 20, 2]

        #print("decoder","rel_type.unsqueeze(1)",rel_type.unsqueeze(1).shape)
        #decoder rel_type.unsqueeze(1) torch.Size([128, 1, 20, 2])

        rel_type = rel_type.unsqueeze(1).expand(sizes)
        #print("decoder","rel_type.unsqueeze(1).expand(sizes)",rel_type.shape)
        #decoder rel_type.unsqueeze(1).expand(sizes) torch.Size([128, 49, 20, 2])


        time_steps = inputs.size(1)
        assert (pred_steps <= time_steps)
        preds = []

        # Only take n-th timesteps as starting points (n: pred_steps)
        #print("decoder","inputs[:, 0::1, :, :]",inputs[:, 0::1, :, :].shape,"inputs[:, 0::2, :, :]",inputs[:, 0::2, :, :].shape)
        #decoder inputs[:, 0::1, :, :] torch.Size([128, 49, 5, 4]) inputs[:, 0::2, :, :] torch.Size([128, 25, 5, 4])

        last_pred = inputs[:, 0::pred_steps, :, :]
        curr_rel_type = rel_type[:, 0::pred_steps, :, :]
        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).

        # Run n prediction steps
        for step in range(0, pred_steps):
            last_pred = self.single_step_forward(last_pred, rel_rec, rel_send,
                                                 curr_rel_type)
            preds.append(last_pred)

        sizes = [preds[0].size(0), preds[0].size(1) * pred_steps,
                 preds[0].size(2), preds[0].size(3)]

        output = Variable(torch.zeros(sizes))
        if inputs.is_cuda:
            output = output.cuda()

        # Re-assemble correct timeline
        for i in range(len(preds)):
            output[:, i::pred_steps, :, :] = preds[i]

        pred_all = output[:, :(inputs.size(1) - 1), :, :]

        return pred_all.transpose(1, 2).contiguous()


class RNNDecoder(nn.Module):
    """Recurrent decoder module."""

    def __init__(self, n_in_node, edge_types, n_hid,
                 do_prob=0., skip_first=False):
        super(RNNDecoder, self).__init__()
        self.msg_fc1 = nn.ModuleList(
            [nn.Linear(2 * n_hid, n_hid) for _ in range(edge_types)])
        self.msg_fc2 = nn.ModuleList(
            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)])
        self.msg_out_shape = n_hid
        self.skip_first_edge_type = skip_first

        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)
        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)
        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)

        self.input_r = nn.Linear(n_in_node, n_hid, bias=True)
        self.input_i = nn.Linear(n_in_node, n_hid, bias=True)
        self.input_n = nn.Linear(n_in_node, n_hid, bias=True)

        self.out_fc1 = nn.Linear(n_hid, n_hid)
        self.out_fc2 = nn.Linear(n_hid, n_hid)
        self.out_fc3 = nn.Linear(n_hid, n_in_node)

        print('Using learned recurrent interaction net decoder.')

        self.dropout_prob = do_prob

    def single_step_forward(self, inputs, rel_rec, rel_send,
                            rel_type, hidden):

        # node2edge
        receivers = torch.matmul(rel_rec, hidden)
        senders = torch.matmul(rel_send, hidden)
        pre_msg = torch.cat([senders, receivers], dim=-1)

        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),
                                        self.msg_out_shape))
        if inputs.is_cuda:
            all_msgs = all_msgs.cuda()

        if self.skip_first_edge_type:
            start_idx = 1
            norm = float(len(self.msg_fc2)) - 1.
        else:
            start_idx = 0
            norm = float(len(self.msg_fc2))

        # Run separate MLP for every edge type
        # NOTE: To exlude one edge type, simply offset range by 1
        for i in range(start_idx, len(self.msg_fc2)):
            msg = F.tanh(self.msg_fc1[i](pre_msg))
            msg = F.dropout(msg, p=self.dropout_prob)
            msg = F.tanh(self.msg_fc2[i](msg))
            msg = msg * rel_type[:, :, i:i + 1]
            all_msgs += msg / norm

        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2,
                                                                        -1)
        agg_msgs = agg_msgs.contiguous() / inputs.size(2)  # Average

        # GRU-style gated aggregation
        r = F.sigmoid(self.input_r(inputs) + self.hidden_r(agg_msgs))
        i = F.sigmoid(self.input_i(inputs) + self.hidden_i(agg_msgs))
        n = F.tanh(self.input_n(inputs) + r * self.hidden_h(agg_msgs))
        hidden = (1 - i) * n + i * hidden

        # Output MLP
        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=self.dropout_prob)
        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)
        pred = self.out_fc3(pred)

        # Predict position/velocity difference
        pred = inputs + pred

        return pred, hidden

    def forward(self, data, rel_type, rel_rec, rel_send, pred_steps=1,
                burn_in=False, burn_in_steps=1, dynamic_graph=False,
                encoder=None, temp=None):

        inputs = data.transpose(1, 2).contiguous()

        time_steps = inputs.size(1)

        # inputs has shape
        # [batch_size, num_timesteps, num_atoms, num_dims]

        # rel_type has shape:
        # [batch_size, num_atoms*(num_atoms-1), num_edge_types]

        hidden = Variable(
            torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape))
        if inputs.is_cuda:
            hidden = hidden.cuda()

        pred_all = []

        for step in range(0, inputs.size(1) - 1):

            if burn_in:
                if step <= burn_in_steps:
                    ins = inputs[:, step, :, :]
                else:
                    ins = pred_all[step - 1]
            else:
                assert (pred_steps <= time_steps)
                # Use ground truth trajectory input vs. last prediction
                if not step % pred_steps:
                    ins = inputs[:, step, :, :]
                else:
                    ins = pred_all[step - 1]

            if dynamic_graph and step >= burn_in_steps:
                # NOTE: Assumes burn_in_steps = args.timesteps
                logits = encoder(
                    data[:, :, step - burn_in_steps:step, :].contiguous(),
                    rel_rec, rel_send)
                rel_type = gumbel_softmax(logits, tau=temp, hard=True)

            pred, hidden = self.single_step_forward(ins, rel_rec, rel_send,
                                                    rel_type, hidden)
            pred_all.append(pred)

        preds = torch.stack(pred_all, dim=1)

        return preds.transpose(1, 2).contiguous()


### FILE: policies/NRI/utils.py
----------------------------------------
import numpy as np
import torch
from torch.utils.data.dataset import TensorDataset
from torch.utils.data import DataLoader
import torch.nn.functional as F
from torch.autograd import Variable


def my_softmax(input, axis=1):
    trans_input = input.transpose(axis, 0).contiguous()
    soft_max_1d = F.softmax(trans_input)
    return soft_max_1d.transpose(axis, 0)


def binary_concrete(logits, tau=1, hard=False, eps=1e-10):
    y_soft = binary_concrete_sample(logits, tau=tau, eps=eps)
    if hard:
        y_hard = (y_soft > 0.5).float()
        y = Variable(y_hard.data - y_soft.data) + y_soft
    else:
        y = y_soft
    return y


def binary_concrete_sample(logits, tau=1, eps=1e-10):
    logistic_noise = sample_logistic(logits.size(), eps=eps)
    if logits.is_cuda:
        logistic_noise = logistic_noise.cuda()
    y = logits + Variable(logistic_noise)
    return F.sigmoid(y / tau)


def sample_logistic(shape, eps=1e-10):
    uniform = torch.rand(shape).float()
    return torch.log(uniform + eps) - torch.log(1 - uniform + eps)


def sample_gumbel(shape, eps=1e-10):
    """
    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3

    Sample from Gumbel(0, 1)

    based on
    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,
    (MIT license)
    """
    U = torch.rand(shape).float()
    return - torch.log(eps - torch.log(U + eps))


def gumbel_softmax_sample(logits, tau=1, eps=1e-10):
    """
    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3

    Draw a sample from the Gumbel-Softmax distribution

    based on
    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb
    (MIT license)
    """
    gumbel_noise = sample_gumbel(logits.size(), eps=eps)
    if logits.is_cuda:
        gumbel_noise = gumbel_noise.cuda()
    y = logits + Variable(gumbel_noise)
    return my_softmax(y / tau, axis=-1)


def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):
    """
    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3

    Sample from the Gumbel-Softmax distribution and optionally discretize.
    Args:
      logits: [batch_size, n_class] unnormalized log-probs
      tau: non-negative scalar temperature
      hard: if True, take argmax, but differentiate w.r.t. soft sample y
    Returns:
      [batch_size, n_class] sample from the Gumbel-Softmax distribution.
      If hard=True, then the returned sample will be one-hot, otherwise it will
      be a probability distribution that sums to 1 across classes

    Constraints:
    - this implementation only works on batch_size x num_features tensor for now

    based on
    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,
    (MIT license)
    """
    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)
    if hard:
        shape = logits.size()
        _, k = y_soft.data.max(-1)
        # this bit is based on
        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5
        y_hard = torch.zeros(*shape)
        if y_soft.is_cuda:
            y_hard = y_hard.cuda()
        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)
        # this cool bit of code achieves two things:
        # - makes the output value exactly one-hot (since we add then
        #   subtract y_soft value)
        # - makes the gradient equal to y_soft gradient (since we strip
        #   all other gradients)
        y = Variable(y_hard - y_soft.data) + y_soft
    else:
        y = y_soft
    return y


def binary_accuracy(output, labels):
    preds = output > 0.5
    correct = preds.type_as(labels).eq(labels).double()
    correct = correct.sum()
    return correct / len(labels)


def load_data(batch_size=1, suffix=''):
    loc_train = np.load('data/loc_train' + suffix + '.npy')
    vel_train = np.load('data/vel_train' + suffix + '.npy')
    edges_train = np.load('data/edges_train' + suffix + '.npy')

    loc_valid = np.load('data/loc_valid' + suffix + '.npy')
    vel_valid = np.load('data/vel_valid' + suffix + '.npy')
    edges_valid = np.load('data/edges_valid' + suffix + '.npy')

    loc_test = np.load('data/loc_test' + suffix + '.npy')
    vel_test = np.load('data/vel_test' + suffix + '.npy')
    edges_test = np.load('data/edges_test' + suffix + '.npy')

    # [num_samples, num_timesteps, num_dims, num_atoms]
    num_atoms = loc_train.shape[3]

    loc_max = loc_train.max()
    loc_min = loc_train.min()
    vel_max = vel_train.max()
    vel_min = vel_train.min()

    # Normalize to [-1, 1]
    loc_train = (loc_train - loc_min) * 2 / (loc_max - loc_min) - 1
    vel_train = (vel_train - vel_min) * 2 / (vel_max - vel_min) - 1

    loc_valid = (loc_valid - loc_min) * 2 / (loc_max - loc_min) - 1
    vel_valid = (vel_valid - vel_min) * 2 / (vel_max - vel_min) - 1

    loc_test = (loc_test - loc_min) * 2 / (loc_max - loc_min) - 1
    vel_test = (vel_test - vel_min) * 2 / (vel_max - vel_min) - 1

    # Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]
    loc_train = np.transpose(loc_train, [0, 3, 1, 2])
    vel_train = np.transpose(vel_train, [0, 3, 1, 2])
    feat_train = np.concatenate([loc_train, vel_train], axis=3)
    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])
    edges_train = np.array((edges_train + 1) / 2, dtype=np.int64)

    loc_valid = np.transpose(loc_valid, [0, 3, 1, 2])
    vel_valid = np.transpose(vel_valid, [0, 3, 1, 2])
    feat_valid = np.concatenate([loc_valid, vel_valid], axis=3)
    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])
    edges_valid = np.array((edges_valid + 1) / 2, dtype=np.int64)

    loc_test = np.transpose(loc_test, [0, 3, 1, 2])
    vel_test = np.transpose(vel_test, [0, 3, 1, 2])
    feat_test = np.concatenate([loc_test, vel_test], axis=3)
    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])
    edges_test = np.array((edges_test + 1) / 2, dtype=np.int64)

    feat_train = torch.FloatTensor(feat_train)
    edges_train = torch.LongTensor(edges_train)
    feat_valid = torch.FloatTensor(feat_valid)
    edges_valid = torch.LongTensor(edges_valid)
    feat_test = torch.FloatTensor(feat_test)
    edges_test = torch.LongTensor(edges_test)

    # Exclude self edges
    off_diag_idx = np.ravel_multi_index(
        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),
        [num_atoms, num_atoms])
    edges_train = edges_train[:, off_diag_idx]
    edges_valid = edges_valid[:, off_diag_idx]
    edges_test = edges_test[:, off_diag_idx]

    train_data = TensorDataset(feat_train, edges_train)
    valid_data = TensorDataset(feat_valid, edges_valid)
    test_data = TensorDataset(feat_test, edges_test)

    train_data_loader = DataLoader(train_data, batch_size=batch_size)
    valid_data_loader = DataLoader(valid_data, batch_size=batch_size)
    test_data_loader = DataLoader(test_data, batch_size=batch_size)

    return train_data_loader, valid_data_loader, test_data_loader, loc_max, loc_min, vel_max, vel_min


def load_kuramoto_data(batch_size=1, suffix=''):
    feat_train = np.load('data/feat_train' + suffix + '.npy')
    edges_train = np.load('data/edges_train' + suffix + '.npy')
    feat_valid = np.load('data/feat_valid' + suffix + '.npy')
    edges_valid = np.load('data/edges_valid' + suffix + '.npy')
    feat_test = np.load('data/feat_test' + suffix + '.npy')
    edges_test = np.load('data/edges_test' + suffix + '.npy')

    # [num_sims, num_atoms, num_timesteps, num_dims]
    num_atoms = feat_train.shape[1]

    # Normalize each feature dim. individually
    feat_max = feat_train.max(0).max(0).max(0)
    feat_min = feat_train.min(0).min(0).min(0)

    feat_max = np.expand_dims(np.expand_dims(np.expand_dims(feat_max, 0), 0), 0)
    feat_min = np.expand_dims(np.expand_dims(np.expand_dims(feat_min, 0), 0), 0)

    # Normalize to [-1, 1]
    feat_train = (feat_train - feat_min) * 2 / (feat_max - feat_min) - 1
    feat_valid = (feat_valid - feat_min) * 2 / (feat_max - feat_min) - 1
    feat_test = (feat_test - feat_min) * 2 / (feat_max - feat_min) - 1

    # Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]
    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])
    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])
    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])

    feat_train = torch.FloatTensor(feat_train)
    edges_train = torch.LongTensor(edges_train)
    feat_valid = torch.FloatTensor(feat_valid)
    edges_valid = torch.LongTensor(edges_valid)
    feat_test = torch.FloatTensor(feat_test)
    edges_test = torch.LongTensor(edges_test)

    # Exclude self edges
    off_diag_idx = np.ravel_multi_index(
        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),
        [num_atoms, num_atoms])
    edges_train = edges_train[:, off_diag_idx]
    edges_valid = edges_valid[:, off_diag_idx]
    edges_test = edges_test[:, off_diag_idx]

    train_data = TensorDataset(feat_train, edges_train)
    valid_data = TensorDataset(feat_valid, edges_valid)
    test_data = TensorDataset(feat_test, edges_test)

    train_data_loader = DataLoader(train_data, batch_size=batch_size)
    valid_data_loader = DataLoader(valid_data, batch_size=batch_size)
    test_data_loader = DataLoader(test_data, batch_size=batch_size)

    return train_data_loader, valid_data_loader, test_data_loader


def load_kuramoto_data_old(batch_size=1, suffix=''):
    feat_train = np.load('data/old_kuramoto/feat_train' + suffix + '.npy')
    edges_train = np.load('data/old_kuramoto/edges_train' + suffix + '.npy')
    feat_valid = np.load('data/old_kuramoto/feat_valid' + suffix + '.npy')
    edges_valid = np.load('data/old_kuramoto/edges_valid' + suffix + '.npy')
    feat_test = np.load('data/old_kuramoto/feat_test' + suffix + '.npy')
    edges_test = np.load('data/old_kuramoto/edges_test' + suffix + '.npy')

    # [num_sims, num_atoms, num_timesteps, num_dims]
    num_atoms = feat_train.shape[1]

    # Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]
    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])
    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])
    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])

    feat_train = torch.FloatTensor(feat_train)
    edges_train = torch.LongTensor(edges_train)
    feat_valid = torch.FloatTensor(feat_valid)
    edges_valid = torch.LongTensor(edges_valid)
    feat_test = torch.FloatTensor(feat_test)
    edges_test = torch.LongTensor(edges_test)

    # Exclude self edges
    off_diag_idx = np.ravel_multi_index(
        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),
        [num_atoms, num_atoms])
    edges_train = edges_train[:, off_diag_idx]
    edges_valid = edges_valid[:, off_diag_idx]
    edges_test = edges_test[:, off_diag_idx]

    train_data = TensorDataset(feat_train, edges_train)
    valid_data = TensorDataset(feat_valid, edges_valid)
    test_data = TensorDataset(feat_test, edges_test)

    train_data_loader = DataLoader(train_data, batch_size=batch_size)
    valid_data_loader = DataLoader(valid_data, batch_size=batch_size)
    test_data_loader = DataLoader(test_data, batch_size=batch_size)

    return train_data_loader, valid_data_loader, test_data_loader


def load_motion_data(batch_size=1, suffix=''):
    feat_train = np.load('data/motion_train' + suffix + '.npy')
    feat_valid = np.load('data/motion_valid' + suffix + '.npy')
    feat_test = np.load('data/motion_test' + suffix + '.npy')
    adj = np.load('data/motion_adj' + suffix + '.npy')

    # NOTE: Already normalized

    # [num_samples, num_nodes, num_timesteps, num_dims]
    num_nodes = feat_train.shape[1]

    edges_train = np.repeat(np.expand_dims(adj.flatten(), 0),
                            feat_train.shape[0], axis=0)
    edges_valid = np.repeat(np.expand_dims(adj.flatten(), 0),
                            feat_valid.shape[0], axis=0)
    edges_test = np.repeat(np.expand_dims(adj.flatten(), 0),
                           feat_test.shape[0], axis=0)

    feat_train = torch.FloatTensor(feat_train)
    edges_train = torch.LongTensor(np.array(edges_train, dtype=np.int64))
    feat_valid = torch.FloatTensor(feat_valid)
    edges_valid = torch.LongTensor(np.array(edges_valid, dtype=np.int64))
    feat_test = torch.FloatTensor(feat_test)
    edges_test = torch.LongTensor(np.array(edges_test, dtype=np.int64))

    # Exclude self edges
    off_diag_idx = np.ravel_multi_index(
        np.where(np.ones((num_nodes, num_nodes)) - np.eye(num_nodes)),
        [num_nodes, num_nodes])
    edges_train = edges_train[:, off_diag_idx]
    edges_valid = edges_valid[:, off_diag_idx]
    edges_test = edges_test[:, off_diag_idx]

    train_data = TensorDataset(feat_train, edges_train)
    valid_data = TensorDataset(feat_valid, edges_valid)
    test_data = TensorDataset(feat_test, edges_test)

    train_data_loader = DataLoader(train_data, batch_size=batch_size)
    valid_data_loader = DataLoader(valid_data, batch_size=batch_size)
    test_data_loader = DataLoader(test_data, batch_size=batch_size)

    return train_data_loader, valid_data_loader, test_data_loader


def to_2d_idx(idx, num_cols):
    idx = np.array(idx, dtype=np.int64)
    y_idx = np.array(np.floor(idx / float(num_cols)), dtype=np.int64)
    x_idx = idx % num_cols
    return x_idx, y_idx


def encode_onehot(labels):
    classes = set(labels)
    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in
                    enumerate(classes)}
    labels_onehot = np.array(list(map(classes_dict.get, labels)),
                             dtype=np.int32)
    return labels_onehot


def get_triu_indices(num_nodes):
    """Linear triu (upper triangular) indices."""
    ones = torch.ones(num_nodes, num_nodes)
    eye = torch.eye(num_nodes, num_nodes)
    triu_indices = (ones.triu() - eye).nonzero().t()
    triu_indices = triu_indices[0] * num_nodes + triu_indices[1]
    return triu_indices


def get_tril_indices(num_nodes):
    """Linear tril (lower triangular) indices."""
    ones = torch.ones(num_nodes, num_nodes)
    eye = torch.eye(num_nodes, num_nodes)
    tril_indices = (ones.tril() - eye).nonzero().t()
    tril_indices = tril_indices[0] * num_nodes + tril_indices[1]
    return tril_indices


def get_offdiag_indices(num_nodes):
    """Linear off-diagonal indices."""
    ones = torch.ones(num_nodes, num_nodes)
    eye = torch.eye(num_nodes, num_nodes)
    offdiag_indices = (ones - eye).nonzero().t()
    offdiag_indices = offdiag_indices[0] * num_nodes + offdiag_indices[1]
    return offdiag_indices


def get_triu_offdiag_indices(num_nodes):
    """Linear triu (upper) indices w.r.t. vector of off-diagonal elements."""
    triu_idx = torch.zeros(num_nodes * num_nodes)
    triu_idx[get_triu_indices(num_nodes)] = 1.
    triu_idx = triu_idx[get_offdiag_indices(num_nodes)]
    return triu_idx.nonzero()


def get_tril_offdiag_indices(num_nodes):
    """Linear tril (lower) indices w.r.t. vector of off-diagonal elements."""
    tril_idx = torch.zeros(num_nodes * num_nodes)
    tril_idx[get_tril_indices(num_nodes)] = 1.
    tril_idx = tril_idx[get_offdiag_indices(num_nodes)]
    return tril_idx.nonzero()


def get_minimum_distance(data):
    data = data[:, :, :, :2].transpose(1, 2)
    data_norm = (data ** 2).sum(-1, keepdim=True)
    dist = data_norm + \
           data_norm.transpose(2, 3) - \
           2 * torch.matmul(data, data.transpose(2, 3))
    min_dist, _ = dist.min(1)
    return min_dist.view(min_dist.size(0), -1)


def get_buckets(dist, num_buckets):
    dist = dist.cpu().data.numpy()

    min_dist = np.min(dist)
    max_dist = np.max(dist)
    bucket_size = (max_dist - min_dist) / num_buckets
    thresholds = bucket_size * np.arange(num_buckets)

    bucket_idx = []
    for i in range(num_buckets):
        if i < num_buckets - 1:
            idx = np.where(np.all(np.vstack((dist > thresholds[i],
                                             dist <= thresholds[i + 1])), 0))[0]
        else:
            idx = np.where(dist > thresholds[i])[0]
        bucket_idx.append(idx)

    return bucket_idx, thresholds


def get_correct_per_bucket(bucket_idx, pred, target):
    pred = pred.cpu().numpy()[:, 0]
    target = target.cpu().data.numpy()

    correct_per_bucket = []
    for i in range(len(bucket_idx)):
        preds_bucket = pred[bucket_idx[i]]
        target_bucket = target[bucket_idx[i]]
        correct_bucket = np.sum(preds_bucket == target_bucket)
        correct_per_bucket.append(correct_bucket)

    return correct_per_bucket


def get_correct_per_bucket_(bucket_idx, pred, target):
    pred = pred.cpu().numpy()
    target = target.cpu().data.numpy()

    correct_per_bucket = []
    for i in range(len(bucket_idx)):
        preds_bucket = pred[bucket_idx[i]]
        target_bucket = target[bucket_idx[i]]
        correct_bucket = np.sum(preds_bucket == target_bucket)
        correct_per_bucket.append(correct_bucket)

    return correct_per_bucket


def kl_categorical(preds, log_prior, num_atoms, eps=1e-16):
    kl_div = preds * (torch.log(preds + eps) - log_prior)
    return kl_div.sum() / (num_atoms * preds.size(0))


def kl_categorical_uniform(preds, num_atoms, num_edge_types, add_const=False,
                           eps=1e-16):
    kl_div = preds * torch.log(preds + eps)
    if add_const:
        const = np.log(num_edge_types)
        kl_div += const
    return kl_div.sum() / (num_atoms * preds.size(0))


def nll_gaussian(preds, target, variance, add_const=False):
    neg_log_p = ((preds - target) ** 2 / (2 * variance))
    if add_const:
        const = 0.5 * np.log(2 * np.pi * variance)
        neg_log_p += const
    return neg_log_p.sum() / (target.size(0) * target.size(1))


def edge_accuracy(preds, target):
    _, preds = preds.max(-1)
    correct = preds.float().data.eq(
        target.float().data.view_as(preds)).cpu().sum()
    return np.float(correct) / (target.size(0) * target.size(1))


### FILE: policies/policy.py
----------------------------------------
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.distributions import Categorical
import math

from policies.utils import *
from policies.networks import *

import numpy as np

class CNN_Policy(nn.Module):
    def __init__(self, num_inputs, num_action, args, device=None):
        super(CNN_Policy, self).__init__()
        if 'sarl' in args.model_name:
            n = 2
            self.sarl_net = SARL_net(num_inputs, num_action).to(device)
        else:
            n = 1
        self.net = CNN(num_inputs, num_action, n).to(device)


    def train_net(self,x, y, last_w, setw, y_cont, args, device):
        x, y, last_w, y_cont = get_tensor(x, y, last_w, y_cont, device)
        self.net.optimizer.zero_grad()
        if 'sarl' in args.model_name :
            pred, _ = self.sarl_net(x)
            prob, _ = self.net(x, last_w,  pred.detach().argmax(dim=1))
        else:
            prob, _ = self.net(x, last_w)
        pv_vector, baseline, _ = cal_pv(y, prob)
        loss = -torch.mean(torch.log(pv_vector))
        loss.backward()
        self.net.optimizer.step()
        setw(prob[:, 1:].detach().cpu().numpy())
        portfolio_value = torch.prod(pv_vector)
        return portfolio_value.detach().cpu().numpy(), loss.detach().cpu().numpy(), _, _, _, _, _


class Conv4_Policy(nn.Module):
    def __init__(self, num_inputs, action_n, lr=0.001, n_episode_batch=5, nri_d=32, cnn_d=10, shuffle=1, shift=True, nri_lr=0.0005, cnn_d2=15, args=None, device=None):
        super(Conv4_Policy, self).__init__()
        if 'sarl' in args.model_name:
            n = 2
            self.sarl_net = SARL_net_conv4(num_inputs, action_n).to(device)
        else:
            n = 1

        if args.stocks == 0:
            self.net=CNN_conv4_stock(num_inputs, action_n, lr, n_episode_batch, nri_d, cnn_d, shuffle, False, nri_lr, cnn_d2, n).to(device)
        else:
            if args.model_name == 'ours':
                self.net=CNN_conv4(num_inputs, action_n, lr, n_episode_batch, nri_d, cnn_d, shuffle, True, nri_lr, cnn_d2, n).to(device)
            else:
                self.net=CNN_conv4(num_inputs, action_n, lr, n_episode_batch, nri_d, cnn_d, shuffle, False, nri_lr, cnn_d2, n).to(device)
        self.nri_net = NRI_net(num_inputs, action_n, lr, n_episode_batch, nri_d, cnn_d, shuffle, shift, nri_lr, cnn_d2).to(device)
        

    def train_net(self, x, y, last_w, setw, y_cont, device, args=None):
        x, y, last_w, y_cont = get_tensor(x, y, last_w, y_cont, device)
        L2= torch.tensor(0)
        nll= torch.tensor(0)
        kl= torch.tensor(0)

        self.net.optimizer.zero_grad()
        if 'sarl' in args.model_name :
            pred, _ = self.sarl_net(x)
            prob, _ = self.net(x, last_w,  pred.detach().argmax(dim=1))
        else:
            prob, re = self.net(x, last_w)
        

        pv_vector, baseline, _ = cal_pv(y, prob)
        c_profit = torch.bmm(prob[:,1:].unsqueeze(1), 0.2*(y_cont[:,0,:,:]-1)).squeeze(1).sum(axis=1)
        
        if args.L2_w > 0:
            L2, nll, kl = self.nri_net.nriLoss(re, x)

        if args.L1_baseline:
            L1 = -torch.mean(torch.log(pv_vector) - torch.log(baseline))
        else:
            L1 = -torch.mean(torch.log(pv_vector))

        L3 =  - (c_profit).mean()

        if args.L1_w:
            L1_w = args.L1_w
        else:
            L1_w = 2

        if args.L3_w_const:
            L3_w = args.L3_w
        else:
            L3_w = args.L3_w*torch.exp(L1.detach())
        loss = L1_w * L1 + L3_w * L3 + args.L2_w * L2

        loss.backward()
        self.net.optimizer.step()
        torch.nn.utils.clip_grad_norm_(self.parameters(), 0.1)
        setw(prob[:, 1:].detach().cpu().numpy())

        portfolio_value = torch.prod(pv_vector)
        return portfolio_value.detach().cpu().numpy(), L1.detach().cpu().numpy(), L2.detach().cpu().numpy(), L3.detach().cpu().numpy(), nll, kl, L3_w.detach().cpu().numpy()



### FILE: policies/utils.py
----------------------------------------
import torch

def cal_pv(y, prob):
    ones = torch.ones(y.shape[0], 1).to(y.device)
    future_price = torch.clamp(torch.cat([ones, y[:, 0, :]], 1), min=0, max=1.5)

    pure_pc = future_price * prob
    pure_pc = pure_pc / pure_pc.sum(-1, keepdim=True)

    w_t = pure_pc[:y.shape[0] - 1]
    w_t1 = prob[1:y.shape[0]]
    mu = 1 - torch.sum(torch.abs(w_t1[:, 1:] - w_t[:, 1:]), 1) * 0.0025

    ones = torch.ones(1).to(y.device)

    pv_vector = torch.sum(prob * future_price, 1) * torch.cat([ones, mu], 0)
    baseline = torch.sum((torch.ones_like(prob)/prob.shape[1]) * future_price, 1)
    return pv_vector, baseline, 1-mu

def get_tensor(x, y, last_w, y_cont, device):
    x = x.to(device).float()
    y = y.to(device).float()
    last_w = last_w.to(device).float()
    y_cont = y_cont.to(device).float()
    return x, y, last_w, y_cont


### FILE: train.sh
----------------------------------------
#!/bin/bash
for dataset in 1; do
    for lrs in 0.00015; do
        for (( i=0; i <= 1; i++ )); do
            for num in 0 1 2 3; do
                seedtmp=$((num + 1))
                seedm=$((i * 4))
                seedfor=$((seedm + seedtmp))
                #CUDA_VISIBLE_DEVICES=1 python train_nri_warmup_result.py --start_steps 20000 --n_episode 50 --lr $lrs --num_steps 18000 --rolling_steps 50 --nri_d 32 --seed $((i + num)) --stocks 0 --smoothing_days 5 --cnn_d 50 --nri_shuffle 20 --nri_lr 0.00015 --cnn_d2 25 --L2_w 0 --L3_w 0 &
                #specific dataset

                CUDA_VISIBLE_DEVICES=$num python main.py  --model_name dpm_v2 --n_episode 50 --lr $lrs --num_steps 18000 --rolling_steps 50 --nri_d 32 --seed $seedfor --stocks $dataset --smoothing_days 5 --cnn_d 50 --nri_shuffle 20 --nri_lr 0.00015 --cnn_d2 25 --L2_w 0 --L3_w 0 & 



            done
            wait
        done
    done
done

#for dataset in 0 --L3_w 0; do
#    for lrs in 0.00012; do
#        for (( i=0; i <= 1; i++ )); do
#            for num in 0 1 2 3; do
#                seedtmp=$((num + 1))
#               seedm=$((i * 4))
#                seedfor=$((seedm + seedtmp))
#                #CUDA_VISIBLE_DEVICES=1 python train_nri_warmup_result.py --start_steps 20000 --n_episode 50 --lr $lrs --num_steps 18000 --rolling_steps 50 --nri_d 32 --seed $((i + num)) --stocks 0 --smoothing_days 5 --cnn_d 50 --nri_shuffle 20 --nri_lr 0.00015 --cnn_d2 25 --L2_w 0 --L3_w 0 &
#                #specific dataset
#                CUDA_VISIBLE_DEVICES=$num python  train_nri_no_val.py  --n_episode 20 --lr $lrs --num_steps 18000 --rolling_steps 30 --nri_d 32 --seed $seedfor --stocks $dataset --smoothing_days 5 --cnn_d 20 --nri_shuffle 10 --nri_lr 0.00012 --cnn_d2 10 --L3_w 1.5 & 
#
#            done
#            wait
#        done
#    done
#done

#for s_day in 5; do
#    for lrs in 0.00015; do
#        for (( i=3; i <= 3; i++ )); do
#            for num in 0; do
#                seedtmp=$((num + 1))
#                seedm=$((i * 1))
#                seedfor=$((seedm + seedtmp))
#                #other dataset
#                CUDA_VISIBLE_DEVICES=1 python train_nri_no_val.py  --n_episode 50 --lr $lrs --num_steps 18000 --rolling_steps 50 --nri_d 32 --seed $seedfor --stocks 3 --smoothing_days $s_day --cnn_d 50 --nri_shuffle 20 --nri_lr 0.00015 --cnn_d2 25 --L3_w 0&
#            done
#            wait
#        done
#
#    done
#done


### FILE: utils.py
----------------------------------------
def init_weight(m):
    if hasattr(m, 'weight') and m.weight.dim() > 1:
        nn.init.kaiming_uniform_(m.weight.data,a=0, mode='fan_in', nonlinearity='sigmoid')


def calculate_pv_after_commission(w1, w0, commission_rate):
    """
    @:param w1: target portfolio vector, first element is btc
    @:param w0: rebalanced last period portfolio vector, first element is btc
    @:param commission_rate: rate of commission fee, proportional to the transaction cost
    """
    mu0 = 1
    mu1 = 1 - 2*commission_rate + commission_rate ** 2
    while abs(mu1-mu0) > 1e-10:
        mu0 = mu1
        mu1 = (1 - commission_rate * w0[0] -
            (2 * commission_rate - commission_rate ** 2) *
            np.sum(np.maximum(w0[1:] - mu1*w1[1:], 0))) / \
            (1 - commission_rate * w1[0])

    return mu1
